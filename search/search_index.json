{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PyNotebookLM","text":"<p>Production-grade Python library for Google NotebookLM automation.</p> <p>PyNotebookLM allows you to programmatically interact with Google NotebookLM, providing access to over 30 internal tools including notebook management, source handling, research discovery, and multi-modal content generation.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd10 Secure Authentication - Browser-based Google login with cookie persistence</li> <li>\ud83d\udcd3 Notebook Management - Create, list, rename, and delete notebooks</li> <li>\ud83d\udcf0 Source Management - Add URLs, YouTube videos, Google Drive docs, and text</li> <li>\ud83d\udd0d Research &amp; Analysis - Query notebooks and discover related sources</li> <li>\ud83e\udde0 Mind Maps - Generate, save, list, and export mind maps (JSON/OPML/FreeMind)</li> <li>\ud83c\udf99\ufe0f Content Generation - Create audio overviews (podcasts), videos, infographics, and slides</li> <li>\ud83d\udcda Study Tools - Create flashcards, quizzes, and briefing documents</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<p>PyNotebookLM uses browser automation (Playwright) to interact with NotebookLM's internal APIs. It handles the complexity of authentication, session management, and the internal RPC protocol, giving you a clean Pythonic interface.</p> <p>Note</p> <p>This is an unofficial library. It uses NotebookLM's internal APIs which may change without notice.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Check out the Quickstart guide to get up and running in minutes.</p>"},{"location":"advanced_usage/","title":"Advanced Usage Guide","text":"<p>This guide covers advanced features and patterns for production use of PyNotebookLM.</p>"},{"location":"advanced_usage/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Retry Strategies &amp; Error Handling</li> <li>Persistent Sessions for Performance</li> <li>Batch Operations</li> <li>Custom Logging &amp; Debugging</li> <li>Production Deployment Patterns</li> </ol>"},{"location":"advanced_usage/#retry-strategies-error-handling","title":"Retry Strategies &amp; Error Handling","text":""},{"location":"advanced_usage/#automatic-retry-with-exponential-backoff","title":"Automatic Retry with Exponential Backoff","text":"<p>PyNotebookLM includes built-in retry logic for transient errors:</p> <pre><code>from pynotebooklm import NotebookLMClient\nfrom pynotebooklm.retry import RetryStrategy, with_retry\n\n# Default retry (3 attempts, 1s base delay)\nasync with NotebookLMClient() as client:\n    notebooks = await client.notebooks.list()  # Auto-retries on failure\n</code></pre>"},{"location":"advanced_usage/#custom-retry-strategy","title":"Custom Retry Strategy","text":"<p>Configure retry behavior for specific operations:</p> <pre><code>from pynotebooklm.retry import RetryStrategy, with_retry\n\n# Aggressive retry for critical operations\naggressive_retry = RetryStrategy(\n    max_attempts=5,       # Try 5 times\n    base_delay=0.5,       # Start with 500ms\n    max_delay=30.0,       # Cap at 30 seconds\n    exponential_base=2.0, # Double each time\n    jitter=True          # Add randomness\n)\n\n@with_retry(aggressive_retry)\nasync def critical_operation():\n    async with NotebookLMClient() as client:\n        return await client.notebooks.create(\"Important Notebook\")\n\n# Use it\nresult = await critical_operation()\n</code></pre>"},{"location":"advanced_usage/#environment-based-configuration","title":"Environment-Based Configuration","text":"<p>Configure retry via environment variables:</p> <pre><code>export PYNOTEBOOKLM_MAX_RETRIES=5\nexport PYNOTEBOOKLM_BASE_DELAY=2.0\nexport PYNOTEBOOKLM_MAX_DELAY=60.0\n</code></pre> <pre><code>from pynotebooklm import NotebookLMClient\nfrom pynotebooklm.retry import RetryStrategy\n\n# Reads from environment\nstrategy = RetryStrategy()  # Uses env vars\n</code></pre>"},{"location":"advanced_usage/#error-classification","title":"Error Classification","text":"<p>PyNotebookLM categorizes errors for appropriate handling:</p> <p>Retryable Errors: - <code>RateLimitError</code> - Always retried - <code>APIError</code> with 5xx status codes (500, 502, 503, 504)</p> <p>Non-Retryable Errors: - <code>AuthenticationError</code> - Requires re-login - <code>NotebookNotFoundError</code> - Resource doesn't exist - <code>APIError</code> with 4xx status codes (400, 401, 403, 404)</p>"},{"location":"advanced_usage/#comprehensive-error-handling-pattern","title":"Comprehensive Error Handling Pattern","text":"<pre><code>from pynotebooklm import NotebookLMClient\nfrom pynotebooklm.exceptions import (\n    AuthenticationError,\n    RateLimitError,\n    APIError,\n    NotebookNotFoundError,\n    GenerationTimeoutError,\n)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nasync def robust_notebook_operation(notebook_id: str):\n    \"\"\"Example of comprehensive error handling.\"\"\"\n    try:\n        async with NotebookLMClient() as client:\n            # Your operation\n            result = await client.chat.query(\n                notebook_id=notebook_id,\n                question=\"What are the key points?\"\n            )\n            return result\n\n    except AuthenticationError:\n        logger.error(\"Authentication failed. Re-login required.\")\n        # Trigger re-authentication flow\n        raise\n\n    except NotebookNotFoundError:\n        logger.error(f\"Notebook {notebook_id} not found\")\n        # Handle missing notebook\n        return None\n\n    except RateLimitError as e:\n        logger.warning(f\"Rate limited. Retry after {e.retry_after}s\")\n        # Could implement custom backoff here\n        raise\n\n    except GenerationTimeoutError as e:\n        logger.error(f\"Operation timed out after {e.timeout}s\")\n        # Implement timeout handling (e.g., poll separately)\n        raise\n\n    except APIError as e:\n        if e.status_code and 500 &lt;= e.status_code &lt; 600:\n            logger.error(f\"Server error {e.status_code}. Will retry automatically\")\n        else:\n            logger.error(f\"API error {e.status_code}: {e}\")\n        raise\n\n    except Exception as e:\n        logger.exception(\"Unexpected error in notebook operation\")\n        raise\n</code></pre>"},{"location":"advanced_usage/#automatic-cookie-refresh","title":"Automatic Cookie Refresh","text":"<p>Enable auto-refresh to re-login when cookies expire during a session:</p> <pre><code>from pynotebooklm import AuthManager, BrowserSession\n\nauth = AuthManager()\nasync with BrowserSession(auth, auto_refresh=True) as session:\n    result = await session.call_rpc(\"wXbhsf\", [None, 1])\n</code></pre>"},{"location":"advanced_usage/#persistent-sessions-for-performance","title":"Persistent Sessions for Performance","text":""},{"location":"advanced_usage/#problem-browser-startup-overhead","title":"Problem: Browser Startup Overhead","text":"<p>Each <code>async with NotebookLMClient()</code> launches a new browser (~3-5s overhead).</p>"},{"location":"advanced_usage/#solution-reuse-client-context","title":"Solution: Reuse Client Context","text":"<p>\u274c Slow (multiple browser launches): <pre><code># Bad: Launches browser 3 times\nawait get_notebooks()\nawait create_notebook(\"Test\")\nawait add_source(notebook_id, url)\n</code></pre></p> <p>\u2705 Fast (single browser session): <pre><code>async with NotebookLMClient() as client:\n    # Single browser launch for all operations\n    notebooks = await client.notebooks.list()\n    new_nb = await client.notebooks.create(\"Test\")\n    source = await client.sources.add_url(new_nb.id, \"https://example.com\")\n</code></pre></p>"},{"location":"advanced_usage/#persistentbrowsersession-shared-browser","title":"PersistentBrowserSession (Shared Browser)","text":"<p>Reuse a shared browser instance across client sessions:</p> <pre><code>from pynotebooklm import NotebookLMClient, PersistentBrowserSession\n\nasync with NotebookLMClient(session_class=PersistentBrowserSession) as client:\n    notebooks = await client.notebooks.list()\n    await client.sources.add_url(notebooks[0].id, \"https://example.com\")\n\n# Optional: shutdown shared browser when the app exits\nawait PersistentBrowserSession.shutdown_pool()\n</code></pre>"},{"location":"advanced_usage/#long-running-service-pattern","title":"Long-Running Service Pattern","text":"<p>For services that handle multiple requests:</p> <pre><code>import asyncio\nfrom contextlib import asynccontextmanager\nfrom pynotebooklm import NotebookLMClient\n\nclass NotebookLMService:\n    \"\"\"Service wrapper for long-running applications.\"\"\"\n\n    def __init__(self):\n        self.client: NotebookLMClient | None = None\n\n    async def start(self):\n        \"\"\"Initialize service and create client.\"\"\"\n        self.client = NotebookLMClient()\n        await self.client.__aenter__()\n\n    async def stop(self):\n        \"\"\"Cleanup service and close browser.\"\"\"\n        if self.client:\n            await self.client.__aexit__(None, None, None)\n\n    async def create_notebook(self, name: str):\n        \"\"\"Create notebook using persistent client.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Service not started\")\n        return await self.client.notebooks.create(name)\n\n    async def query_notebook(self, notebook_id: str, question: str):\n        \"\"\"Query notebook using persistent client.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Service not started\")\n        return await self.client.chat.query(notebook_id, question)\n\n# Usage\nservice = NotebookLMService()\nawait service.start()\n\ntry:\n    # Handle multiple requests without browser restarts\n    nb1 = await service.create_notebook(\"Notebook 1\")\n    nb2 = await service.create_notebook(\"Notebook 2\")\n    result = await service.query_notebook(nb1.id, \"Question\")\nfinally:\n    await service.stop()\n</code></pre>"},{"location":"advanced_usage/#fastapi-integration-example","title":"FastAPI Integration Example","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom contextlib import asynccontextmanager\nfrom pynotebooklm import NotebookLMClient\nfrom pynotebooklm.exceptions import PyNotebookLMError\n\n# Global client instance\nnotebooklm_client: NotebookLMClient | None = None\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Manage NotebookLM client lifecycle.\"\"\"\n    global notebooklm_client\n\n    # Startup\n    notebooklm_client = NotebookLMClient()\n    await notebooklm_client.__aenter__()\n\n    yield\n\n    # Shutdown\n    if notebooklm_client:\n        await notebooklm_client.__aexit__(None, None, None)\n\napp = FastAPI(lifespan=lifespan)\n\n@app.post(\"/notebooks/create\")\nasync def create_notebook(name: str):\n    \"\"\"Create a new notebook.\"\"\"\n    try:\n        if not notebooklm_client:\n            raise HTTPException(status_code=500, detail=\"Client not initialized\")\n\n        notebook = await notebooklm_client.notebooks.create(name)\n        return {\"id\": notebook.id, \"name\": notebook.name}\n\n    except PyNotebookLMError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/notebooks/{notebook_id}/query\")\nasync def query_notebook(notebook_id: str, question: str):\n    \"\"\"Query a notebook.\"\"\"\n    try:\n        if not notebooklm_client:\n            raise HTTPException(status_code=500, detail=\"Client not initialized\")\n\n        response = await notebooklm_client.chat.query(notebook_id, question)\n        return {\"answer\": response.text}\n\n    except PyNotebookLMError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"advanced_usage/#batch-operations","title":"Batch Operations","text":""},{"location":"advanced_usage/#concurrent-operations-with-asynciogather","title":"Concurrent Operations with asyncio.gather","text":"<p>Process multiple operations in parallel:</p> <pre><code>import asyncio\nfrom pynotebooklm import NotebookLMClient\n\nasync def batch_create_notebooks(names: list[str]):\n    \"\"\"Create multiple notebooks concurrently.\"\"\"\n    async with NotebookLMClient() as client:\n        # Create all notebooks in parallel\n        tasks = [\n            client.notebooks.create(name)\n            for name in names\n        ]\n        notebooks = await asyncio.gather(*tasks)\n        return notebooks\n\n# Usage\nnames = [\"Research 1\", \"Research 2\", \"Research 3\"]\nnotebooks = await batch_create_notebooks(names)\n</code></pre>"},{"location":"advanced_usage/#batch-source-addition","title":"Batch Source Addition","text":"<p>Add multiple URLs to a notebook:</p> <pre><code>async def batch_add_sources(notebook_id: str, urls: list[str]):\n    \"\"\"Add multiple URL sources concurrently.\"\"\"\n    async with NotebookLMClient() as client:\n        tasks = [\n            client.sources.add_url(notebook_id, url)\n            for url in urls\n        ]\n        sources = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Filter successful additions\n        successful = [s for s in sources if not isinstance(s, Exception)]\n        failed = [s for s in sources if isinstance(s, Exception)]\n\n        return successful, failed\n\n# Usage\nurls = [\n    \"https://example.com/article1\",\n    \"https://example.com/article2\",\n    \"https://example.com/article3\",\n]\nsuccessful, failed = await batch_add_sources(notebook_id, urls)\nprint(f\"Added {len(successful)} sources, {len(failed)} failed\")\n</code></pre>"},{"location":"advanced_usage/#built-in-batch-helpers","title":"Built-In Batch Helpers","text":"<p>Use the built-in batch helpers for common workflows:</p> <pre><code>async with NotebookLMClient() as client:\n    await client.sources.batch_add_urls(notebook_id, urls)\n    await client.notebooks.batch_delete(notebook_ids, confirm=True)\n</code></pre>"},{"location":"advanced_usage/#rate-limited-batch-processing","title":"Rate-Limited Batch Processing","text":"<p>Process large batches with rate limiting:</p> <pre><code>import asyncio\nfrom typing import TypeVar, Callable, Any\n\nT = TypeVar('T')\n\nasync def rate_limited_batch(\n    items: list[T],\n    async_func: Callable[[T], Any],\n    batch_size: int = 5,\n    delay: float = 1.0,\n):\n    \"\"\"Process items in batches with delay between batches.\"\"\"\n    results = []\n\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i + batch_size]\n\n        # Process batch concurrently\n        batch_results = await asyncio.gather(\n            *[async_func(item) for item in batch],\n            return_exceptions=True\n        )\n        results.extend(batch_results)\n\n        # Delay between batches\n        if i + batch_size &lt; len(items):\n            await asyncio.sleep(delay)\n\n    return results\n\n# Usage\nasync def process_url(url: str):\n    async with NotebookLMClient() as client:\n        notebook = await client.notebooks.create(f\"Analysis: {url}\")\n        await client.sources.add_url(notebook.id, url)\n        return notebook\n\nurls = [\"url1\", \"url2\", \"url3\", \"url4\", \"url5\", \"url6\", \"url7\"]\nresults = await rate_limited_batch(urls, process_url, batch_size=3, delay=2.0)\n</code></pre>"},{"location":"advanced_usage/#custom-logging-debugging","title":"Custom Logging &amp; Debugging","text":""},{"location":"advanced_usage/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>export PYNOTEBOOKLM_DEBUG=1\n</code></pre> <p>Or in code:</p> <pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Now all PyNotebookLM operations log detailed info\nasync with NotebookLMClient() as client:\n    await client.notebooks.list()  # Logs RPC calls, responses, etc.\n</code></pre>"},{"location":"advanced_usage/#custom-logger-configuration","title":"Custom Logger Configuration","text":"<pre><code>import logging\n\n# Create custom logger\nlogger = logging.getLogger('pynotebooklm')\nlogger.setLevel(logging.INFO)\n\n# Add custom handler (e.g., file logging)\nhandler = logging.FileHandler('notebooklm.log')\nhandler.setFormatter(\n    logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n)\nlogger.addHandler(handler)\n</code></pre>"},{"location":"advanced_usage/#requestresponse-logging","title":"Request/Response Logging","text":"<p>Log all RPC calls for debugging:</p> <pre><code>from pynotebooklm import NotebookLMClient\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\nasync with NotebookLMClient() as client:\n    # All RPC calls logged with DEBUG level\n    notebooks = await client.notebooks.list()\n</code></pre>"},{"location":"advanced_usage/#telemetry-logs","title":"Telemetry Logs","text":"<p>Enable structured telemetry logs for RPC timing and success rates:</p> <pre><code>export PYNOTEBOOKLM_TELEMETRY=1\n</code></pre>"},{"location":"advanced_usage/#production-deployment-patterns","title":"Production Deployment Patterns","text":""},{"location":"advanced_usage/#docker-deployment","title":"Docker Deployment","text":"<p>Dockerfile: <pre><code>FROM python:3.11-slim\n\n# Install Playwright dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    libnss3 libnspr4 libatk1.0-0 libatk-bridge2.0-0 \\\n    libcups2 libdrm2 libxkbcommon0 libxcomposite1 \\\n    libxdamage1 libxfixes3 libxrandr2 libgbm1 libasound2 \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install PyNotebookLM\nRUN pip install pynotebooklm playwright\nRUN playwright install chromium --with-deps\n\n# Copy application code\nWORKDIR /app\nCOPY . .\n\nCMD [\"python\", \"app.py\"]\n</code></pre></p> <p>Usage: <pre><code># Build\ndocker build -t pynotebooklm-app .\n\n# Run (mount auth file)\ndocker run -v ~/.pynotebooklm:/root/.pynotebooklm pynotebooklm-app\n</code></pre></p>"},{"location":"advanced_usage/#health-checks","title":"Health Checks","text":"<p>Implement health checks for services:</p> <pre><code>from pynotebooklm import NotebookLMClient\nfrom pynotebooklm.exceptions import AuthenticationError\n\nasync def health_check():\n    \"\"\"Check if NotebookLM service is healthy.\"\"\"\n    try:\n        async with NotebookLMClient() as client:\n            # Simple operation to verify connectivity\n            await client.notebooks.list()\n            return {\"status\": \"healthy\"}\n    except AuthenticationError:\n        return {\"status\": \"unhealthy\", \"reason\": \"authentication_failed\"}\n    except Exception as e:\n        return {\"status\": \"unhealthy\", \"reason\": str(e)}\n</code></pre>"},{"location":"advanced_usage/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>Handle shutdown signals properly:</p> <pre><code>import signal\nimport asyncio\n\nclass GracefulShutdown:\n    def __init__(self):\n        self.shutdown_event = asyncio.Event()\n\n    def signal_handler(self, signum, frame):\n        print(f\"Received signal {signum}, initiating shutdown...\")\n        self.shutdown_event.set()\n\ngraceful = GracefulShutdown()\nsignal.signal(signal.SIGINT, graceful.signal_handler)\nsignal.signal(signal.SIGTERM, graceful.signal_handler)\n\n# In async main\nasync def main():\n    service = NotebookLMService()\n    await service.start()\n\n    try:\n        # Wait for shutdown signal\n        await graceful.shutdown_event.wait()\n    finally:\n        await service.stop()\n</code></pre>"},{"location":"advanced_usage/#cookie-refresh-automation","title":"Cookie Refresh Automation","text":"<p>Automate cookie refresh to prevent expiration:</p> <pre><code>import asyncio\nfrom datetime import datetime, timedelta\nfrom pynotebooklm.auth import AuthManager\n\nasync def cookie_refresh_worker():\n    \"\"\"Background task to refresh cookies every 2 weeks.\"\"\"\n    auth = AuthManager()\n\n    while True:\n        # Wait 13 days (refresh before 14-day expiration)\n        await asyncio.sleep(13 * 24 * 60 * 60)\n\n        try:\n            print(\"Refreshing authentication cookies...\")\n            await auth.refresh()\n            print(\"Cookies refreshed successfully\")\n        except Exception as e:\n            print(f\"Failed to refresh cookies: {e}\")\n\n# Run as background task\nasyncio.create_task(cookie_refresh_worker())\n</code></pre>"},{"location":"advanced_usage/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Always use async context managers - Ensures proper cleanup</li> <li>Reuse client instances - Avoid repeated browser launches</li> <li>Implement retry logic - Handle transient errors gracefully</li> <li>Use batch operations - Process multiple items efficiently</li> <li>Enable logging - Debug issues with detailed logs</li> <li>Handle errors specifically - Catch appropriate exception types</li> <li>Monitor cookie expiration - Implement refresh automation</li> <li>Rate limit batch operations - Avoid overwhelming the API</li> <li>Implement health checks - Monitor service availability</li> <li>Test error scenarios - Ensure robust error handling</li> </ol> <p>See <code>examples/07_error_handling.py</code> for complete code examples.</p>"},{"location":"api_reference/","title":"API Reference","text":"<p>This page provides the complete API reference for the PyNotebookLM library, covering all modules from Phases 1-10.</p>"},{"location":"api_reference/#unified-client","title":"Unified Client","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient","title":"<code>pynotebooklm.client.NotebookLMClient</code>","text":"<p>Unified client for Google NotebookLM.</p> <p>This client provides a high-level async context manager interface to all NotebookLM functionality.</p> Example <p>async with NotebookLMClient() as client: ...     notebooks = await client.notebooks.list() ...     print(notebooks)</p> Source code in <code>src/pynotebooklm/client.py</code> <pre><code>class NotebookLMClient:\n    \"\"\"\n    Unified client for Google NotebookLM.\n\n    This client provides a high-level async context manager interface\n    to all NotebookLM functionality.\n\n    Example:\n        &gt;&gt;&gt; async with NotebookLMClient() as client:\n        ...     notebooks = await client.notebooks.list()\n        ...     print(notebooks)\n    \"\"\"\n\n    def __init__(\n        self,\n        auth: AuthManager | None = None,\n        session_class: type[BrowserSession] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the unified client.\n\n        Args:\n            auth: Optional AuthManager instance. If not provided,\n                  a default one will be created.\n            session_class: BrowserSession class to use (e.g. PersistentBrowserSession).\n        \"\"\"\n        self._auth = auth or AuthManager()\n        self._session_class = session_class or BrowserSession\n        self._session: BrowserSession | None = None\n\n        # Managers - initialized in __aenter__\n        self.notebooks: NotebookManager = None  # type: ignore\n        self.sources: SourceManager = None  # type: ignore\n        self.research: ResearchDiscovery = None  # type: ignore\n        self.mindmaps: MindMapGenerator = None  # type: ignore\n        self.content: ContentGenerator = None  # type: ignore\n        self.study: StudyManager = None  # type: ignore\n        self.chat: ChatSession = None  # type: ignore\n\n    async def __aenter__(self) -&gt; \"NotebookLMClient\":\n        \"\"\"\n        Start the browser session and initialize all managers.\n        \"\"\"\n        self._session = self._session_class(self._auth)\n        await self._session.__aenter__()\n\n        # Initialize managers with the active session\n        self.notebooks = NotebookManager(self._session)\n        self.sources = SourceManager(self._session)\n        self.research = ResearchDiscovery(self._session)\n        self.mindmaps = MindMapGenerator(self._session)\n        self.content = ContentGenerator(self._session)\n        self.study = StudyManager(self._session)\n        self.chat = ChatSession(self._session)\n\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n        \"\"\"\n        Close the browser session.\n        \"\"\"\n        if self._session:\n            await self._session.__aexit__(exc_type, exc_val, exc_tb)\n            self._session = None\n\n    @property\n    def is_authenticated(self) -&gt; bool:\n        \"\"\"Check if the client is authenticated.\"\"\"\n        return self._auth.is_authenticated()\n\n    async def login(self) -&gt; None:\n        \"\"\"Perform interactive login.\"\"\"\n        await self._auth.login()\n</code></pre>"},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.notebooks","title":"<code>notebooks = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.sources","title":"<code>sources = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.research","title":"<code>research = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.chat","title":"<code>chat = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.mindmaps","title":"<code>mindmaps = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.content","title":"<code>content = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.study","title":"<code>study = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.__init__","title":"<code>__init__(auth=None, session_class=None)</code>","text":"<p>Initialize the unified client.</p> <p>Parameters:</p> Name Type Description Default <code>auth</code> <code>AuthManager | None</code> <p>Optional AuthManager instance. If not provided,   a default one will be created.</p> <code>None</code> <code>session_class</code> <code>type[BrowserSession] | None</code> <p>BrowserSession class to use (e.g. PersistentBrowserSession).</p> <code>None</code> Source code in <code>src/pynotebooklm/client.py</code> <pre><code>def __init__(\n    self,\n    auth: AuthManager | None = None,\n    session_class: type[BrowserSession] | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the unified client.\n\n    Args:\n        auth: Optional AuthManager instance. If not provided,\n              a default one will be created.\n        session_class: BrowserSession class to use (e.g. PersistentBrowserSession).\n    \"\"\"\n    self._auth = auth or AuthManager()\n    self._session_class = session_class or BrowserSession\n    self._session: BrowserSession | None = None\n\n    # Managers - initialized in __aenter__\n    self.notebooks: NotebookManager = None  # type: ignore\n    self.sources: SourceManager = None  # type: ignore\n    self.research: ResearchDiscovery = None  # type: ignore\n    self.mindmaps: MindMapGenerator = None  # type: ignore\n    self.content: ContentGenerator = None  # type: ignore\n    self.study: StudyManager = None  # type: ignore\n    self.chat: ChatSession = None  # type: ignore\n</code></pre>"},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"<p>Start the browser session and initialize all managers.</p> Source code in <code>src/pynotebooklm/client.py</code> <pre><code>async def __aenter__(self) -&gt; \"NotebookLMClient\":\n    \"\"\"\n    Start the browser session and initialize all managers.\n    \"\"\"\n    self._session = self._session_class(self._auth)\n    await self._session.__aenter__()\n\n    # Initialize managers with the active session\n    self.notebooks = NotebookManager(self._session)\n    self.sources = SourceManager(self._session)\n    self.research = ResearchDiscovery(self._session)\n    self.mindmaps = MindMapGenerator(self._session)\n    self.content = ContentGenerator(self._session)\n    self.study = StudyManager(self._session)\n    self.chat = ChatSession(self._session)\n\n    return self\n</code></pre>"},{"location":"api_reference/#pynotebooklm.client.NotebookLMClient.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Close the browser session.</p> Source code in <code>src/pynotebooklm/client.py</code> <pre><code>async def __aexit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; None:\n    \"\"\"\n    Close the browser session.\n    \"\"\"\n    if self._session:\n        await self._session.__aexit__(exc_type, exc_val, exc_tb)\n        self._session = None\n</code></pre>"},{"location":"api_reference/#notebook-management","title":"Notebook Management","text":""},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager","title":"<code>pynotebooklm.notebooks.NotebookManager</code>","text":"<p>Manages NotebookLM notebooks.</p> <p>This class provides high-level methods for notebook CRUD operations with properly typed inputs and outputs.</p> Example <p>async with BrowserSession(auth) as session: ...     notebooks = NotebookManager(session) ...     all_notebooks = await notebooks.list() ...     new_notebook = await notebooks.create(\"My Research\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>class NotebookManager:\n    \"\"\"\n    Manages NotebookLM notebooks.\n\n    This class provides high-level methods for notebook CRUD operations\n    with properly typed inputs and outputs.\n\n    Example:\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     notebooks = NotebookManager(session)\n        ...     all_notebooks = await notebooks.list()\n        ...     new_notebook = await notebooks.create(\"My Research\")\n    \"\"\"\n\n    def __init__(self, session: BrowserSession) -&gt; None:\n        \"\"\"\n        Initialize the notebook manager.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n        self._api = NotebookLMAPI(session)\n\n    async def list(self) -&gt; list[Notebook]:\n        \"\"\"\n        List all notebooks in the account.\n\n        Returns:\n            List of Notebook objects.\n\n        Raises:\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; notebooks = await manager.list()\n            &gt;&gt;&gt; for nb in notebooks:\n            ...     print(f\"{nb.name} ({nb.id})\")\n        \"\"\"\n        logger.info(\"Listing all notebooks...\")\n\n        raw_notebooks = await self._api.list_notebooks()\n\n        notebooks: list[Notebook] = []\n        for raw in raw_notebooks:\n            try:\n                notebook = parse_notebook_response(raw)\n                notebooks.append(notebook)\n            except Exception as e:\n                logger.warning(\"Failed to parse notebook: %s\", e)\n                continue\n\n        logger.info(\"Found %d notebooks\", len(notebooks))\n        return notebooks\n\n    async def create(self, name: str) -&gt; Notebook:\n        \"\"\"\n        Create a new notebook.\n\n        Args:\n            name: Name for the new notebook (1-200 characters).\n\n        Returns:\n            The created Notebook object.\n\n        Raises:\n            ValueError: If name is invalid.\n            APIError: If creation fails.\n\n        Example:\n            &gt;&gt;&gt; notebook = await manager.create(\"My Research Project\")\n            &gt;&gt;&gt; print(f\"Created: {notebook.id}\")\n        \"\"\"\n        # Validate name\n        if not name or not name.strip():\n            raise ValueError(\"Notebook name cannot be empty\")\n\n        name = name.strip()\n        if len(name) &gt; 200:\n            raise ValueError(\"Notebook name cannot exceed 200 characters\")\n\n        logger.info(\"Creating notebook: %s\", name)\n\n        raw_result = await self._api.create_notebook(name)\n\n        # Parse the response\n        notebook = parse_notebook_response(raw_result)\n\n        logger.info(\"Created notebook: %s (%s)\", notebook.name, notebook.id)\n        return notebook\n\n    async def get(self, notebook_id: str) -&gt; Notebook:\n        \"\"\"\n        Get a notebook by ID with its sources.\n\n        Args:\n            notebook_id: The notebook ID.\n\n        Returns:\n            The Notebook object with sources populated.\n\n        Raises:\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; notebook = await manager.get(\"abc123\")\n            &gt;&gt;&gt; print(f\"Sources: {len(notebook.sources)}\")\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        logger.info(\"Getting notebook: %s\", notebook_id)\n\n        raw_result = await self._api.get_notebook(notebook_id)\n\n        notebook = parse_notebook_response(raw_result)\n\n        logger.info(\n            \"Retrieved notebook: %s with %d sources\",\n            notebook.name,\n            notebook.source_count,\n        )\n        return notebook\n\n    async def rename(self, notebook_id: str, new_name: str) -&gt; Notebook:\n        \"\"\"\n        Rename an existing notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            new_name: The new name for the notebook.\n\n        Returns:\n            The updated Notebook object.\n\n        Raises:\n            ValueError: If new_name is invalid.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; notebook = await manager.rename(\"abc123\", \"New Name\")\n            &gt;&gt;&gt; print(f\"Renamed to: {notebook.name}\")\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not new_name or not new_name.strip():\n            raise ValueError(\"New name cannot be empty\")\n\n        new_name = new_name.strip()\n        if len(new_name) &gt; 200:\n            raise ValueError(\"Notebook name cannot exceed 200 characters\")\n\n        logger.info(\"Renaming notebook %s to: %s\", notebook_id, new_name)\n\n        await self._api.rename_notebook(notebook_id, new_name)\n\n        # Fetch the updated notebook\n        notebook = await self.get(notebook_id)\n\n        logger.info(\"Renamed notebook to: %s\", notebook.name)\n        return notebook\n\n    async def delete(self, notebook_id: str, confirm: bool = False) -&gt; bool:\n        \"\"\"\n        Delete a notebook.\n\n        Args:\n            notebook_id: The notebook ID to delete.\n            confirm: Must be True to actually delete. Safety mechanism.\n\n        Returns:\n            True if deletion was successful.\n\n        Raises:\n            ValueError: If confirm is not True.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; # This will raise ValueError - safety mechanism\n            &gt;&gt;&gt; await manager.delete(\"abc123\")\n\n            &gt;&gt;&gt; # This will actually delete\n            &gt;&gt;&gt; await manager.delete(\"abc123\", confirm=True)\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not confirm:\n            raise ValueError(\n                \"Deletion not confirmed. Pass confirm=True to delete the notebook. \"\n                \"This action cannot be undone.\"\n            )\n\n        logger.warning(\"Deleting notebook: %s\", notebook_id)\n\n        result = await self._api.delete_notebook(notebook_id)\n\n        logger.info(\"Deleted notebook: %s\", notebook_id)\n        return result\n\n    async def batch_delete(\n        self, notebook_ids: Sequence[str], confirm: bool = False\n    ) -&gt; dict[str, bool]:\n        \"\"\"\n        Delete multiple notebooks concurrently.\n\n        Args:\n            notebook_ids: Sequence of notebook IDs to delete.\n            confirm: Must be True to proceed.\n\n        Returns:\n            Mapping of notebook ID to deletion success.\n        \"\"\"\n        if not confirm:\n            raise ValueError(\"confirm must be True to delete notebooks in batch\")\n        if not notebook_ids:\n            raise ValueError(\"Notebook IDs cannot be empty\")\n\n        async def _delete_single(nid: str) -&gt; tuple[str, bool]:\n            try:\n                result = await self.delete(nid, confirm=True)\n                return nid, bool(result)\n            except Exception:\n                return nid, False\n\n        results = await asyncio.gather(*(_delete_single(nid) for nid in notebook_ids))\n        return dict(results)\n\n    async def exists(self, notebook_id: str) -&gt; bool:\n        \"\"\"\n        Check if a notebook exists.\n\n        Args:\n            notebook_id: The notebook ID to check.\n\n        Returns:\n            True if the notebook exists, False otherwise.\n\n        Example:\n            &gt;&gt;&gt; if await manager.exists(\"abc123\"):\n            ...     print(\"Notebook exists!\")\n        \"\"\"\n        try:\n            await self.get(notebook_id)\n            return True\n        except NotebookNotFoundError:\n            return False\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.list","title":"<code>list()</code>  <code>async</code>","text":"<p>List all notebooks in the account.</p> <p>Returns:</p> Type Description <code>list[Notebook]</code> <p>List of Notebook objects.</p> <p>Raises:</p> Type Description <code>APIError</code> <p>If the API call fails.</p> Example <p>notebooks = await manager.list() for nb in notebooks: ...     print(f\"{nb.name} ({nb.id})\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def list(self) -&gt; list[Notebook]:\n    \"\"\"\n    List all notebooks in the account.\n\n    Returns:\n        List of Notebook objects.\n\n    Raises:\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; notebooks = await manager.list()\n        &gt;&gt;&gt; for nb in notebooks:\n        ...     print(f\"{nb.name} ({nb.id})\")\n    \"\"\"\n    logger.info(\"Listing all notebooks...\")\n\n    raw_notebooks = await self._api.list_notebooks()\n\n    notebooks: list[Notebook] = []\n    for raw in raw_notebooks:\n        try:\n            notebook = parse_notebook_response(raw)\n            notebooks.append(notebook)\n        except Exception as e:\n            logger.warning(\"Failed to parse notebook: %s\", e)\n            continue\n\n    logger.info(\"Found %d notebooks\", len(notebooks))\n    return notebooks\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.create","title":"<code>create(name)</code>  <code>async</code>","text":"<p>Create a new notebook.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for the new notebook (1-200 characters).</p> required <p>Returns:</p> Type Description <code>Notebook</code> <p>The created Notebook object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If name is invalid.</p> <code>APIError</code> <p>If creation fails.</p> Example <p>notebook = await manager.create(\"My Research Project\") print(f\"Created: {notebook.id}\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def create(self, name: str) -&gt; Notebook:\n    \"\"\"\n    Create a new notebook.\n\n    Args:\n        name: Name for the new notebook (1-200 characters).\n\n    Returns:\n        The created Notebook object.\n\n    Raises:\n        ValueError: If name is invalid.\n        APIError: If creation fails.\n\n    Example:\n        &gt;&gt;&gt; notebook = await manager.create(\"My Research Project\")\n        &gt;&gt;&gt; print(f\"Created: {notebook.id}\")\n    \"\"\"\n    # Validate name\n    if not name or not name.strip():\n        raise ValueError(\"Notebook name cannot be empty\")\n\n    name = name.strip()\n    if len(name) &gt; 200:\n        raise ValueError(\"Notebook name cannot exceed 200 characters\")\n\n    logger.info(\"Creating notebook: %s\", name)\n\n    raw_result = await self._api.create_notebook(name)\n\n    # Parse the response\n    notebook = parse_notebook_response(raw_result)\n\n    logger.info(\"Created notebook: %s (%s)\", notebook.name, notebook.id)\n    return notebook\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.get","title":"<code>get(notebook_id)</code>  <code>async</code>","text":"<p>Get a notebook by ID with its sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <p>Returns:</p> Type Description <code>Notebook</code> <p>The Notebook object with sources populated.</p> <p>Raises:</p> Type Description <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>notebook = await manager.get(\"abc123\") print(f\"Sources: {len(notebook.sources)}\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def get(self, notebook_id: str) -&gt; Notebook:\n    \"\"\"\n    Get a notebook by ID with its sources.\n\n    Args:\n        notebook_id: The notebook ID.\n\n    Returns:\n        The Notebook object with sources populated.\n\n    Raises:\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; notebook = await manager.get(\"abc123\")\n        &gt;&gt;&gt; print(f\"Sources: {len(notebook.sources)}\")\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    logger.info(\"Getting notebook: %s\", notebook_id)\n\n    raw_result = await self._api.get_notebook(notebook_id)\n\n    notebook = parse_notebook_response(raw_result)\n\n    logger.info(\n        \"Retrieved notebook: %s with %d sources\",\n        notebook.name,\n        notebook.source_count,\n    )\n    return notebook\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.delete","title":"<code>delete(notebook_id, confirm=False)</code>  <code>async</code>","text":"<p>Delete a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID to delete.</p> required <code>confirm</code> <code>bool</code> <p>Must be True to actually delete. Safety mechanism.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if deletion was successful.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If confirm is not True.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def delete(self, notebook_id: str, confirm: bool = False) -&gt; bool:\n    \"\"\"\n    Delete a notebook.\n\n    Args:\n        notebook_id: The notebook ID to delete.\n        confirm: Must be True to actually delete. Safety mechanism.\n\n    Returns:\n        True if deletion was successful.\n\n    Raises:\n        ValueError: If confirm is not True.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; # This will raise ValueError - safety mechanism\n        &gt;&gt;&gt; await manager.delete(\"abc123\")\n\n        &gt;&gt;&gt; # This will actually delete\n        &gt;&gt;&gt; await manager.delete(\"abc123\", confirm=True)\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not confirm:\n        raise ValueError(\n            \"Deletion not confirmed. Pass confirm=True to delete the notebook. \"\n            \"This action cannot be undone.\"\n        )\n\n    logger.warning(\"Deleting notebook: %s\", notebook_id)\n\n    result = await self._api.delete_notebook(notebook_id)\n\n    logger.info(\"Deleted notebook: %s\", notebook_id)\n    return result\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.delete--this-will-raise-valueerror-safety-mechanism","title":"This will raise ValueError - safety mechanism","text":"<p>await manager.delete(\"abc123\")</p>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.delete--this-will-actually-delete","title":"This will actually delete","text":"<p>await manager.delete(\"abc123\", confirm=True)</p>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.rename","title":"<code>rename(notebook_id, new_name)</code>  <code>async</code>","text":"<p>Rename an existing notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>new_name</code> <code>str</code> <p>The new name for the notebook.</p> required <p>Returns:</p> Type Description <code>Notebook</code> <p>The updated Notebook object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If new_name is invalid.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>notebook = await manager.rename(\"abc123\", \"New Name\") print(f\"Renamed to: {notebook.name}\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def rename(self, notebook_id: str, new_name: str) -&gt; Notebook:\n    \"\"\"\n    Rename an existing notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        new_name: The new name for the notebook.\n\n    Returns:\n        The updated Notebook object.\n\n    Raises:\n        ValueError: If new_name is invalid.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; notebook = await manager.rename(\"abc123\", \"New Name\")\n        &gt;&gt;&gt; print(f\"Renamed to: {notebook.name}\")\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not new_name or not new_name.strip():\n        raise ValueError(\"New name cannot be empty\")\n\n    new_name = new_name.strip()\n    if len(new_name) &gt; 200:\n        raise ValueError(\"Notebook name cannot exceed 200 characters\")\n\n    logger.info(\"Renaming notebook %s to: %s\", notebook_id, new_name)\n\n    await self._api.rename_notebook(notebook_id, new_name)\n\n    # Fetch the updated notebook\n    notebook = await self.get(notebook_id)\n\n    logger.info(\"Renamed notebook to: %s\", notebook.name)\n    return notebook\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.exists","title":"<code>exists(notebook_id)</code>  <code>async</code>","text":"<p>Check if a notebook exists.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the notebook exists, False otherwise.</p> Example <p>if await manager.exists(\"abc123\"): ...     print(\"Notebook exists!\")</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def exists(self, notebook_id: str) -&gt; bool:\n    \"\"\"\n    Check if a notebook exists.\n\n    Args:\n        notebook_id: The notebook ID to check.\n\n    Returns:\n        True if the notebook exists, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if await manager.exists(\"abc123\"):\n        ...     print(\"Notebook exists!\")\n    \"\"\"\n    try:\n        await self.get(notebook_id)\n        return True\n    except NotebookNotFoundError:\n        return False\n</code></pre>"},{"location":"api_reference/#pynotebooklm.notebooks.NotebookManager.batch_delete","title":"<code>batch_delete(notebook_ids, confirm=False)</code>  <code>async</code>","text":"<p>Delete multiple notebooks concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_ids</code> <code>Sequence[str]</code> <p>Sequence of notebook IDs to delete.</p> required <code>confirm</code> <code>bool</code> <p>Must be True to proceed.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, bool]</code> <p>Mapping of notebook ID to deletion success.</p> Source code in <code>src/pynotebooklm/notebooks.py</code> <pre><code>async def batch_delete(\n    self, notebook_ids: Sequence[str], confirm: bool = False\n) -&gt; dict[str, bool]:\n    \"\"\"\n    Delete multiple notebooks concurrently.\n\n    Args:\n        notebook_ids: Sequence of notebook IDs to delete.\n        confirm: Must be True to proceed.\n\n    Returns:\n        Mapping of notebook ID to deletion success.\n    \"\"\"\n    if not confirm:\n        raise ValueError(\"confirm must be True to delete notebooks in batch\")\n    if not notebook_ids:\n        raise ValueError(\"Notebook IDs cannot be empty\")\n\n    async def _delete_single(nid: str) -&gt; tuple[str, bool]:\n        try:\n            result = await self.delete(nid, confirm=True)\n            return nid, bool(result)\n        except Exception:\n            return nid, False\n\n    results = await asyncio.gather(*(_delete_single(nid) for nid in notebook_ids))\n    return dict(results)\n</code></pre>"},{"location":"api_reference/#source-management","title":"Source Management","text":""},{"location":"api_reference/#pynotebooklm.sources.SourceManager","title":"<code>pynotebooklm.sources.SourceManager</code>","text":"<p>Manages sources in NotebookLM notebooks.</p> <p>This class provides high-level methods for adding various types of sources (URLs, YouTube videos, Google Drive docs, text) to notebooks and managing them.</p> Example <p>async with BrowserSession(auth) as session: ...     sources = SourceManager(session) ...     source = await sources.add_url(notebook_id, \"https://example.com\")</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>class SourceManager:\n    \"\"\"\n    Manages sources in NotebookLM notebooks.\n\n    This class provides high-level methods for adding various types\n    of sources (URLs, YouTube videos, Google Drive docs, text) to\n    notebooks and managing them.\n\n    Example:\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     sources = SourceManager(session)\n        ...     source = await sources.add_url(notebook_id, \"https://example.com\")\n    \"\"\"\n\n    def __init__(self, session: \"BrowserSession\") -&gt; None:\n        \"\"\"\n        Initialize the source manager.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n        self._api = NotebookLMAPI(session)\n\n    async def add_url(self, notebook_id: str, url: str) -&gt; Source:\n        \"\"\"\n        Add a URL as a source to a notebook.\n\n        The URL will be fetched and its content extracted for use\n        in the notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            url: The URL to add (must be a valid HTTP/HTTPS URL).\n\n        Returns:\n            The created Source object.\n\n        Raises:\n            ValueError: If URL is invalid.\n            SourceError: If the URL cannot be added.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; source = await manager.add_url(\n            ...     \"notebook123\",\n            ...     \"https://en.wikipedia.org/wiki/Python\"\n            ... )\n            &gt;&gt;&gt; print(f\"Added: {source.title}\")\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not url:\n            raise ValueError(\"URL cannot be empty\")\n\n        # Basic URL validation\n        if not self._is_valid_url(url):\n            raise ValueError(f\"Invalid URL format: {url}\")\n\n        # Check if it's a YouTube URL\n        if self._is_youtube_url(url):\n            logger.info(\"URL detected as YouTube, using YouTube source type\")\n            return await self.add_youtube(notebook_id, url)\n\n        logger.info(\"Adding URL source to %s: %s\", notebook_id, url)\n\n        raw_result = await self._api.add_url_source(notebook_id, url)\n\n        source = parse_source_response(raw_result)\n\n        logger.info(\"Added URL source: %s (%s)\", source.title, source.id)\n        return source\n\n    async def add_youtube(self, notebook_id: str, url: str) -&gt; Source:\n        \"\"\"\n        Add a YouTube video as a source to a notebook.\n\n        The video's transcript will be extracted for use in the notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            url: The YouTube URL (various formats supported).\n\n        Returns:\n            The created Source object.\n\n        Raises:\n            ValueError: If URL is invalid or not a YouTube URL.\n            SourceError: If the video cannot be added.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; source = await manager.add_youtube(\n            ...     \"notebook123\",\n            ...     \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n            ... )\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not url:\n            raise ValueError(\"URL cannot be empty\")\n\n        if not self._is_youtube_url(url):\n            raise ValueError(f\"Not a valid YouTube URL: {url}\")\n\n        logger.info(\"Adding YouTube source to %s: %s\", notebook_id, url)\n\n        raw_result = await self._api.add_youtube_source(notebook_id, url)\n\n        source = parse_source_response(raw_result)\n        source.type = SourceType.YOUTUBE  # Ensure correct type\n\n        logger.info(\"Added YouTube source: %s (%s)\", source.title, source.id)\n        return source\n\n    async def add_text(\n        self,\n        notebook_id: str,\n        content: str,\n        title: str | None = None,\n    ) -&gt; Source:\n        \"\"\"\n        Add plain text as a source to a notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            content: The text content (must not be empty).\n            title: Optional title for the source (defaults to \"Untitled Text\").\n\n        Returns:\n            The created Source object.\n\n        Raises:\n            ValueError: If content is empty.\n            SourceError: If the text cannot be added.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; source = await manager.add_text(\n            ...     \"notebook123\",\n            ...     \"This is my research notes...\",\n            ...     title=\"Research Notes\"\n            ... )\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not content or not content.strip():\n            raise ValueError(\"Content cannot be empty\")\n\n        title = title.strip() if title else \"Untitled Text\"\n\n        logger.info(\"Adding text source to %s: %s\", notebook_id, title)\n\n        raw_result = await self._api.add_text_source(notebook_id, content, title)\n\n        source = parse_source_response(raw_result)\n        source.type = SourceType.TEXT  # Ensure correct type\n\n        logger.info(\"Added text source: %s (%s)\", source.title, source.id)\n        return source\n\n    async def add_drive(self, notebook_id: str, drive_doc_id: str) -&gt; Source:\n        \"\"\"\n        Add a Google Drive document as a source to a notebook.\n\n        The user must have access to the Drive document.\n\n        Args:\n            notebook_id: The notebook ID.\n            drive_doc_id: The Google Drive document ID.\n\n        Returns:\n            The created Source object.\n\n        Raises:\n            ValueError: If drive_doc_id is empty.\n            SourceError: If the document cannot be added.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; source = await manager.add_drive(\n            ...     \"notebook123\",\n            ...     \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\"\n            ... )\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not drive_doc_id or not drive_doc_id.strip():\n            raise ValueError(\"Drive document ID cannot be empty\")\n\n        drive_doc_id = drive_doc_id.strip()\n\n        logger.info(\"Adding Drive source to %s: %s\", notebook_id, drive_doc_id)\n\n        raw_result = await self._api.add_drive_source(notebook_id, drive_doc_id)\n\n        source = parse_source_response(raw_result)\n        source.type = SourceType.DRIVE  # Ensure correct type\n\n        logger.info(\"Added Drive source: %s (%s)\", source.title, source.id)\n        return source\n\n    async def batch_add_urls(self, notebook_id: str, urls: list[str]) -&gt; list[Source]:\n        \"\"\"\n        Add multiple URL sources concurrently.\n\n        Args:\n            notebook_id: The notebook ID.\n            urls: List of URLs to add.\n\n        Returns:\n            List of created Source objects.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n        if not urls:\n            raise ValueError(\"URLs list cannot be empty\")\n\n        results = await asyncio.gather(\n            *(self.add_url(notebook_id, url) for url in urls)\n        )\n        return list(results)\n\n    async def list_sources(\n        self, notebook_id: str, check_freshness: bool = False\n    ) -&gt; list[Source]:\n        \"\"\"\n        List all sources in a notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            check_freshness: If True, check freshness status for Drive sources.\n                            This makes additional API calls but provides accurate\n                            freshness information. Default is False for performance.\n\n        Returns:\n            List of Source objects with freshness status populated for Drive sources\n            (if check_freshness=True).\n\n        Raises:\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; sources = await manager.list_sources(\"notebook123\")\n            &gt;&gt;&gt; for src in sources:\n            ...     print(f\"{src.title} ({src.type})\")\n\n            &gt;&gt;&gt; # With freshness checking for Drive sources:\n            &gt;&gt;&gt; sources = await manager.list_sources(\"notebook123\", check_freshness=True)\n            &gt;&gt;&gt; for src in sources:\n            ...     if src.type == SourceType.DRIVE:\n            ...         status = \"fresh\" if src.is_fresh else \"stale\"\n            ...         print(f\"{src.title} - {status}\")\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        logger.info(\"Listing sources for notebook: %s\", notebook_id)\n\n        raw_notebook = await self._api.get_notebook(notebook_id)\n\n        try:\n            notebook = parse_notebook_response(raw_notebook)\n            sources = notebook.sources\n        except Exception as e:\n            logger.warning(\"Failed to parse notebook sources: %s\", e)\n            sources = []\n\n        # Check freshness for Drive sources if requested\n        if check_freshness and sources:\n            drive_sources = [s for s in sources if s.type == SourceType.DRIVE]\n            if drive_sources:\n                logger.info(\n                    \"Checking freshness for %d Drive sources\", len(drive_sources)\n                )\n                # Check freshness for each Drive source\n                for source in drive_sources:\n                    try:\n                        is_fresh = await self._api.check_source_freshness(source.id)\n                        source.is_fresh = is_fresh\n                    except Exception as e:\n                        logger.warning(\n                            \"Failed to check freshness for source %s: %s\",\n                            source.id,\n                            e,\n                        )\n                        source.is_fresh = None\n\n        logger.info(\"Found %d sources\", len(sources))\n        return sources\n\n    async def delete(self, notebook_id: str, source_id: str) -&gt; bool:\n        \"\"\"\n        Delete a source from a notebook.\n\n        Args:\n            notebook_id: The notebook ID.\n            source_id: The source ID to delete.\n\n        Returns:\n            True if deletion was successful.\n\n        Raises:\n            ValueError: If IDs are empty.\n            SourceError: If the source cannot be deleted.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; await manager.delete(\"notebook123\", \"source456\")\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        if not source_id:\n            raise ValueError(\"Source ID cannot be empty\")\n\n        logger.info(\"Deleting source %s from %s\", source_id, notebook_id)\n\n        result = await self._api.delete_source(notebook_id, source_id)\n\n        logger.info(\"Deleted source: %s\", source_id)\n        return result\n\n    async def list_drive(self) -&gt; list[dict[str, str]]:\n        \"\"\"\n        List available Google Drive documents.\n\n        Returns a list of Drive documents that can be added as sources.\n\n        Returns:\n            List of dictionaries with 'id' and 'title' keys.\n\n        Raises:\n            APIError: If the API call fails.\n\n        Example:\n            &gt;&gt;&gt; docs = await manager.list_drive()\n            &gt;&gt;&gt; for doc in docs:\n            ...     print(f\"{doc['title']} ({doc['id']})\")\n        \"\"\"\n        logger.info(\"Listing available Drive documents...\")\n\n        raw_docs = await self._api.list_drive_docs()\n\n        docs: list[dict[str, str]] = []\n        for raw in raw_docs:\n            if isinstance(raw, list) and len(raw) &gt;= 2:\n                docs.append(\n                    {\n                        \"id\": str(raw[0]) if raw[0] else \"\",\n                        \"title\": str(raw[1]) if raw[1] else \"Untitled\",\n                    }\n                )\n\n        logger.info(\"Found %d Drive documents\", len(docs))\n        return docs\n\n    # =========================================================================\n    # Helper Methods\n    # =========================================================================\n\n    def _is_valid_url(self, url: str) -&gt; bool:\n        \"\"\"Check if a string is a valid HTTP/HTTPS URL.\"\"\"\n        pattern = r\"^https?://[^\\s/$.?#].[^\\s]*$\"\n        return bool(re.match(pattern, url, re.IGNORECASE))\n\n    def _is_youtube_url(self, url: str) -&gt; bool:\n        \"\"\"Check if a URL is a YouTube URL.\"\"\"\n        youtube_patterns = [\n            r\"(?:youtube\\.com/watch\\?v=)\",\n            r\"(?:youtu\\.be/)\",\n            r\"(?:youtube\\.com/embed/)\",\n            r\"(?:youtube\\.com/v/)\",\n        ]\n        return any(re.search(p, url, re.IGNORECASE) for p in youtube_patterns)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.add_url","title":"<code>add_url(notebook_id, url)</code>  <code>async</code>","text":"<p>Add a URL as a source to a notebook.</p> <p>The URL will be fetched and its content extracted for use in the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>url</code> <code>str</code> <p>The URL to add (must be a valid HTTP/HTTPS URL).</p> required <p>Returns:</p> Type Description <code>Source</code> <p>The created Source object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If URL is invalid.</p> <code>SourceError</code> <p>If the URL cannot be added.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>source = await manager.add_url( ...     \"notebook123\", ...     \"https://en.wikipedia.org/wiki/Python\" ... ) print(f\"Added: {source.title}\")</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def add_url(self, notebook_id: str, url: str) -&gt; Source:\n    \"\"\"\n    Add a URL as a source to a notebook.\n\n    The URL will be fetched and its content extracted for use\n    in the notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        url: The URL to add (must be a valid HTTP/HTTPS URL).\n\n    Returns:\n        The created Source object.\n\n    Raises:\n        ValueError: If URL is invalid.\n        SourceError: If the URL cannot be added.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; source = await manager.add_url(\n        ...     \"notebook123\",\n        ...     \"https://en.wikipedia.org/wiki/Python\"\n        ... )\n        &gt;&gt;&gt; print(f\"Added: {source.title}\")\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not url:\n        raise ValueError(\"URL cannot be empty\")\n\n    # Basic URL validation\n    if not self._is_valid_url(url):\n        raise ValueError(f\"Invalid URL format: {url}\")\n\n    # Check if it's a YouTube URL\n    if self._is_youtube_url(url):\n        logger.info(\"URL detected as YouTube, using YouTube source type\")\n        return await self.add_youtube(notebook_id, url)\n\n    logger.info(\"Adding URL source to %s: %s\", notebook_id, url)\n\n    raw_result = await self._api.add_url_source(notebook_id, url)\n\n    source = parse_source_response(raw_result)\n\n    logger.info(\"Added URL source: %s (%s)\", source.title, source.id)\n    return source\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.add_youtube","title":"<code>add_youtube(notebook_id, url)</code>  <code>async</code>","text":"<p>Add a YouTube video as a source to a notebook.</p> <p>The video's transcript will be extracted for use in the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>url</code> <code>str</code> <p>The YouTube URL (various formats supported).</p> required <p>Returns:</p> Type Description <code>Source</code> <p>The created Source object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If URL is invalid or not a YouTube URL.</p> <code>SourceError</code> <p>If the video cannot be added.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>source = await manager.add_youtube( ...     \"notebook123\", ...     \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" ... )</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def add_youtube(self, notebook_id: str, url: str) -&gt; Source:\n    \"\"\"\n    Add a YouTube video as a source to a notebook.\n\n    The video's transcript will be extracted for use in the notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        url: The YouTube URL (various formats supported).\n\n    Returns:\n        The created Source object.\n\n    Raises:\n        ValueError: If URL is invalid or not a YouTube URL.\n        SourceError: If the video cannot be added.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; source = await manager.add_youtube(\n        ...     \"notebook123\",\n        ...     \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n        ... )\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not url:\n        raise ValueError(\"URL cannot be empty\")\n\n    if not self._is_youtube_url(url):\n        raise ValueError(f\"Not a valid YouTube URL: {url}\")\n\n    logger.info(\"Adding YouTube source to %s: %s\", notebook_id, url)\n\n    raw_result = await self._api.add_youtube_source(notebook_id, url)\n\n    source = parse_source_response(raw_result)\n    source.type = SourceType.YOUTUBE  # Ensure correct type\n\n    logger.info(\"Added YouTube source: %s (%s)\", source.title, source.id)\n    return source\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.add_text","title":"<code>add_text(notebook_id, content, title=None)</code>  <code>async</code>","text":"<p>Add plain text as a source to a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>content</code> <code>str</code> <p>The text content (must not be empty).</p> required <code>title</code> <code>str | None</code> <p>Optional title for the source (defaults to \"Untitled Text\").</p> <code>None</code> <p>Returns:</p> Type Description <code>Source</code> <p>The created Source object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If content is empty.</p> <code>SourceError</code> <p>If the text cannot be added.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>source = await manager.add_text( ...     \"notebook123\", ...     \"This is my research notes...\", ...     title=\"Research Notes\" ... )</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def add_text(\n    self,\n    notebook_id: str,\n    content: str,\n    title: str | None = None,\n) -&gt; Source:\n    \"\"\"\n    Add plain text as a source to a notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        content: The text content (must not be empty).\n        title: Optional title for the source (defaults to \"Untitled Text\").\n\n    Returns:\n        The created Source object.\n\n    Raises:\n        ValueError: If content is empty.\n        SourceError: If the text cannot be added.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; source = await manager.add_text(\n        ...     \"notebook123\",\n        ...     \"This is my research notes...\",\n        ...     title=\"Research Notes\"\n        ... )\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not content or not content.strip():\n        raise ValueError(\"Content cannot be empty\")\n\n    title = title.strip() if title else \"Untitled Text\"\n\n    logger.info(\"Adding text source to %s: %s\", notebook_id, title)\n\n    raw_result = await self._api.add_text_source(notebook_id, content, title)\n\n    source = parse_source_response(raw_result)\n    source.type = SourceType.TEXT  # Ensure correct type\n\n    logger.info(\"Added text source: %s (%s)\", source.title, source.id)\n    return source\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.add_drive","title":"<code>add_drive(notebook_id, drive_doc_id)</code>  <code>async</code>","text":"<p>Add a Google Drive document as a source to a notebook.</p> <p>The user must have access to the Drive document.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>drive_doc_id</code> <code>str</code> <p>The Google Drive document ID.</p> required <p>Returns:</p> Type Description <code>Source</code> <p>The created Source object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If drive_doc_id is empty.</p> <code>SourceError</code> <p>If the document cannot be added.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>source = await manager.add_drive( ...     \"notebook123\", ...     \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\" ... )</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def add_drive(self, notebook_id: str, drive_doc_id: str) -&gt; Source:\n    \"\"\"\n    Add a Google Drive document as a source to a notebook.\n\n    The user must have access to the Drive document.\n\n    Args:\n        notebook_id: The notebook ID.\n        drive_doc_id: The Google Drive document ID.\n\n    Returns:\n        The created Source object.\n\n    Raises:\n        ValueError: If drive_doc_id is empty.\n        SourceError: If the document cannot be added.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; source = await manager.add_drive(\n        ...     \"notebook123\",\n        ...     \"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\"\n        ... )\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not drive_doc_id or not drive_doc_id.strip():\n        raise ValueError(\"Drive document ID cannot be empty\")\n\n    drive_doc_id = drive_doc_id.strip()\n\n    logger.info(\"Adding Drive source to %s: %s\", notebook_id, drive_doc_id)\n\n    raw_result = await self._api.add_drive_source(notebook_id, drive_doc_id)\n\n    source = parse_source_response(raw_result)\n    source.type = SourceType.DRIVE  # Ensure correct type\n\n    logger.info(\"Added Drive source: %s (%s)\", source.title, source.id)\n    return source\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.batch_add_urls","title":"<code>batch_add_urls(notebook_id, urls)</code>  <code>async</code>","text":"<p>Add multiple URL sources concurrently.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>urls</code> <code>list[str]</code> <p>List of URLs to add.</p> required <p>Returns:</p> Type Description <code>list[Source]</code> <p>List of created Source objects.</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def batch_add_urls(self, notebook_id: str, urls: list[str]) -&gt; list[Source]:\n    \"\"\"\n    Add multiple URL sources concurrently.\n\n    Args:\n        notebook_id: The notebook ID.\n        urls: List of URLs to add.\n\n    Returns:\n        List of created Source objects.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n    if not urls:\n        raise ValueError(\"URLs list cannot be empty\")\n\n    results = await asyncio.gather(\n        *(self.add_url(notebook_id, url) for url in urls)\n    )\n    return list(results)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.list_sources","title":"<code>list_sources(notebook_id, check_freshness=False)</code>  <code>async</code>","text":"<p>List all sources in a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>check_freshness</code> <code>bool</code> <p>If True, check freshness status for Drive sources.             This makes additional API calls but provides accurate             freshness information. Default is False for performance.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Source]</code> <p>List of Source objects with freshness status populated for Drive sources</p> <code>list[Source]</code> <p>(if check_freshness=True).</p> <p>Raises:</p> Type Description <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>sources = await manager.list_sources(\"notebook123\") for src in sources: ...     print(f\"{src.title} ({src.type})\")</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def list_sources(\n    self, notebook_id: str, check_freshness: bool = False\n) -&gt; list[Source]:\n    \"\"\"\n    List all sources in a notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        check_freshness: If True, check freshness status for Drive sources.\n                        This makes additional API calls but provides accurate\n                        freshness information. Default is False for performance.\n\n    Returns:\n        List of Source objects with freshness status populated for Drive sources\n        (if check_freshness=True).\n\n    Raises:\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; sources = await manager.list_sources(\"notebook123\")\n        &gt;&gt;&gt; for src in sources:\n        ...     print(f\"{src.title} ({src.type})\")\n\n        &gt;&gt;&gt; # With freshness checking for Drive sources:\n        &gt;&gt;&gt; sources = await manager.list_sources(\"notebook123\", check_freshness=True)\n        &gt;&gt;&gt; for src in sources:\n        ...     if src.type == SourceType.DRIVE:\n        ...         status = \"fresh\" if src.is_fresh else \"stale\"\n        ...         print(f\"{src.title} - {status}\")\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    logger.info(\"Listing sources for notebook: %s\", notebook_id)\n\n    raw_notebook = await self._api.get_notebook(notebook_id)\n\n    try:\n        notebook = parse_notebook_response(raw_notebook)\n        sources = notebook.sources\n    except Exception as e:\n        logger.warning(\"Failed to parse notebook sources: %s\", e)\n        sources = []\n\n    # Check freshness for Drive sources if requested\n    if check_freshness and sources:\n        drive_sources = [s for s in sources if s.type == SourceType.DRIVE]\n        if drive_sources:\n            logger.info(\n                \"Checking freshness for %d Drive sources\", len(drive_sources)\n            )\n            # Check freshness for each Drive source\n            for source in drive_sources:\n                try:\n                    is_fresh = await self._api.check_source_freshness(source.id)\n                    source.is_fresh = is_fresh\n                except Exception as e:\n                    logger.warning(\n                        \"Failed to check freshness for source %s: %s\",\n                        source.id,\n                        e,\n                    )\n                    source.is_fresh = None\n\n    logger.info(\"Found %d sources\", len(sources))\n    return sources\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.list_sources--with-freshness-checking-for-drive-sources","title":"With freshness checking for Drive sources:","text":"<p>sources = await manager.list_sources(\"notebook123\", check_freshness=True) for src in sources: ...     if src.type == SourceType.DRIVE: ...         status = \"fresh\" if src.is_fresh else \"stale\" ...         print(f\"{src.title} - {status}\")</p>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.delete","title":"<code>delete(notebook_id, source_id)</code>  <code>async</code>","text":"<p>Delete a source from a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID.</p> required <code>source_id</code> <code>str</code> <p>The source ID to delete.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deletion was successful.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are empty.</p> <code>SourceError</code> <p>If the source cannot be deleted.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Example <p>await manager.delete(\"notebook123\", \"source456\")</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def delete(self, notebook_id: str, source_id: str) -&gt; bool:\n    \"\"\"\n    Delete a source from a notebook.\n\n    Args:\n        notebook_id: The notebook ID.\n        source_id: The source ID to delete.\n\n    Returns:\n        True if deletion was successful.\n\n    Raises:\n        ValueError: If IDs are empty.\n        SourceError: If the source cannot be deleted.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; await manager.delete(\"notebook123\", \"source456\")\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    if not source_id:\n        raise ValueError(\"Source ID cannot be empty\")\n\n    logger.info(\"Deleting source %s from %s\", source_id, notebook_id)\n\n    result = await self._api.delete_source(notebook_id, source_id)\n\n    logger.info(\"Deleted source: %s\", source_id)\n    return result\n</code></pre>"},{"location":"api_reference/#pynotebooklm.sources.SourceManager.list_drive","title":"<code>list_drive()</code>  <code>async</code>","text":"<p>List available Google Drive documents.</p> <p>Returns a list of Drive documents that can be added as sources.</p> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with 'id' and 'title' keys.</p> <p>Raises:</p> Type Description <code>APIError</code> <p>If the API call fails.</p> Example <p>docs = await manager.list_drive() for doc in docs: ...     print(f\"{doc['title']} ({doc['id']})\")</p> Source code in <code>src/pynotebooklm/sources.py</code> <pre><code>async def list_drive(self) -&gt; list[dict[str, str]]:\n    \"\"\"\n    List available Google Drive documents.\n\n    Returns a list of Drive documents that can be added as sources.\n\n    Returns:\n        List of dictionaries with 'id' and 'title' keys.\n\n    Raises:\n        APIError: If the API call fails.\n\n    Example:\n        &gt;&gt;&gt; docs = await manager.list_drive()\n        &gt;&gt;&gt; for doc in docs:\n        ...     print(f\"{doc['title']} ({doc['id']})\")\n    \"\"\"\n    logger.info(\"Listing available Drive documents...\")\n\n    raw_docs = await self._api.list_drive_docs()\n\n    docs: list[dict[str, str]] = []\n    for raw in raw_docs:\n        if isinstance(raw, list) and len(raw) &gt;= 2:\n            docs.append(\n                {\n                    \"id\": str(raw[0]) if raw[0] else \"\",\n                    \"title\": str(raw[1]) if raw[1] else \"Untitled\",\n                }\n            )\n\n    logger.info(\"Found %d Drive documents\", len(docs))\n    return docs\n</code></pre>"},{"location":"api_reference/#research-discovery","title":"Research &amp; Discovery","text":""},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery","title":"<code>pynotebooklm.research.ResearchDiscovery</code>","text":"<p>Performs web research and source discovery for NotebookLM.</p> <p>This class provides methods for starting research sessions, polling their status, and importing results into notebooks.</p> <p>Research is asynchronous - start_research returns a task_id, then call poll_research to check status and get results.</p> Example <p>async with BrowserSession(auth) as session: ...     research = ResearchDiscovery(session) ...     result = await research.start_research(\"notebook123\", \"AI trends\") ...     print(f\"Task ID: {result.task_id}\") ...     # Poll for results ...     status = await research.poll_research(\"notebook123\") ...     if status.status == \"completed\": ...         print(f\"Found {len(status.results)} sources\")</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>class ResearchDiscovery:\n    \"\"\"\n    Performs web research and source discovery for NotebookLM.\n\n    This class provides methods for starting research sessions,\n    polling their status, and importing results into notebooks.\n\n    Research is asynchronous - start_research returns a task_id,\n    then call poll_research to check status and get results.\n\n    Example:\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     research = ResearchDiscovery(session)\n        ...     result = await research.start_research(\"notebook123\", \"AI trends\")\n        ...     print(f\"Task ID: {result.task_id}\")\n        ...     # Poll for results\n        ...     status = await research.poll_research(\"notebook123\")\n        ...     if status.status == \"completed\":\n        ...         print(f\"Found {len(status.results)} sources\")\n    \"\"\"\n\n    def __init__(self, session: \"BrowserSession\") -&gt; None:\n        \"\"\"\n        Initialize the research discovery.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n\n    async def start_research(\n        self,\n        notebook_id: str,\n        query: str,\n        source: ResearchSource | str = ResearchSource.WEB,\n        mode: ResearchType | str = ResearchType.FAST,\n    ) -&gt; ResearchSession:\n        \"\"\"\n        Start a research session to discover sources.\n\n        Research is asynchronous. This method returns immediately with a task_id.\n        Use poll_research() to check status and get results.\n\n        Args:\n            notebook_id: The notebook ID to perform research in.\n            query: The research topic or query string.\n            source: Source type - \"web\" or \"drive\" (default: \"web\")\n            mode: Research mode - \"fast\" or \"deep\" (default: \"fast\")\n\n        Returns:\n            ResearchSession with task_id for polling.\n\n        Raises:\n            ValueError: If invalid source/mode combination.\n            APIError: If the research cannot be started.\n            NotebookNotFoundError: If notebook doesn't exist.\n        \"\"\"\n        if not notebook_id or not notebook_id.strip():\n            raise ValueError(\"Notebook ID cannot be empty\")\n        if not query or not query.strip():\n            raise ValueError(\"Research query cannot be empty\")\n\n        notebook_id = notebook_id.strip()\n        query = query.strip()\n\n        # Normalize source and mode\n        source_str = (\n            source.value if isinstance(source, ResearchSource) else source.lower()\n        )\n        mode_str = mode.value if isinstance(mode, ResearchType) else mode.lower()\n\n        if source_str not in (\"web\", \"drive\"):\n            raise ValueError(f\"Invalid source '{source_str}'. Use 'web' or 'drive'.\")\n\n        if mode_str not in (\"fast\", \"deep\"):\n            raise ValueError(f\"Invalid mode '{mode_str}'. Use 'fast' or 'deep'.\")\n\n        if mode_str == \"deep\" and source_str == \"drive\":\n            raise ValueError(\n                \"Deep Research only supports Web sources. Use mode='fast' for Drive.\"\n            )\n\n        # Map to internal constants\n        source_type = (\n            RESEARCH_SOURCE_WEB if source_str == \"web\" else RESEARCH_SOURCE_DRIVE\n        )\n\n        logger.info(\n            \"Starting %s research for query '%s' in notebook %s (source: %s)\",\n            mode_str,\n            query,\n            notebook_id,\n            source_str,\n        )\n\n        try:\n            if mode_str == \"fast\":\n                # Fast Research: Ljjv0c\n                # Payload: [[query, source_type], None, 1, notebook_id]\n                rpc_id = RPC_START_FAST_RESEARCH\n                params = [[query, source_type], None, RESEARCH_MODE_FAST, notebook_id]\n            else:\n                # Deep Research: QA9ei\n                # Payload: [None, [1], [query, source_type], 5, notebook_id]\n                rpc_id = RPC_START_DEEP_RESEARCH\n                params = [\n                    None,\n                    [1],\n                    [query, source_type],\n                    RESEARCH_MODE_DEEP,\n                    notebook_id,\n                ]\n\n            result = await self._session.call_rpc(rpc_id, params)\n\n            # Parse the response - should contain task_id and optionally report_id\n            task_id = None\n            report_id = None\n\n            if result and isinstance(result, list) and len(result) &gt; 0:\n                task_id = result[0]\n                report_id = result[1] if len(result) &gt; 1 else None\n\n            if not task_id:\n                raise APIError(\"Research started but no task_id returned\")\n\n            logger.info(\"Research started with task_id: %s\", task_id)\n\n            return ResearchSession(\n                task_id=str(task_id),\n                report_id=str(report_id) if report_id else None,\n                notebook_id=notebook_id,\n                query=query,\n                source=source_str,\n                mode=mode_str,\n                status=ResearchStatus.IN_PROGRESS,\n            )\n\n        except APIError as e:\n            if e.status_code == 404:\n                raise NotebookNotFoundError(notebook_id) from e\n            raise\n\n    async def poll_research(self, notebook_id: str) -&gt; ResearchSession:\n        \"\"\"\n        Poll for research results.\n\n        Call this repeatedly until status is \"completed\".\n\n        Args:\n            notebook_id: The notebook UUID.\n\n        Returns:\n            ResearchSession with current status and results.\n            When no research is found, status will be ResearchStatus.NO_RESEARCH.\n        \"\"\"\n        if not notebook_id or not notebook_id.strip():\n            raise ValueError(\"Notebook ID cannot be empty\")\n\n        notebook_id = notebook_id.strip()\n        logger.debug(\"Polling research for notebook: %s\", notebook_id)\n\n        try:\n            # Poll params: [null, null, \"notebook_id\"]\n            params = [None, None, notebook_id]\n            result = await self._session.call_rpc(RPC_POLL_RESEARCH, params)\n\n            if not result or not isinstance(result, list) or len(result) == 0:\n                return ResearchSession(\n                    task_id=\"\",\n                    notebook_id=notebook_id,\n                    query=\"\",\n                    status=ResearchStatus.NO_RESEARCH,\n                )\n\n            # Parse the research result\n            return self._parse_poll_response(result, notebook_id)\n\n        except APIError as e:\n            if e.status_code == 404:\n                raise NotebookNotFoundError(notebook_id) from e\n            raise\n\n    async def poll_with_backoff(\n        self,\n        notebook_id: str,\n        max_attempts: int = 10,\n        base_interval: float = 5.0,\n        max_interval: float = 60.0,\n    ) -&gt; ResearchSession:\n        \"\"\"\n        Poll research status with exponential backoff.\n\n        Args:\n            notebook_id: The notebook UUID.\n            max_attempts: Maximum number of polling attempts.\n            base_interval: Initial polling interval in seconds.\n            max_interval: Maximum polling interval in seconds.\n\n        Returns:\n            ResearchSession when completed or after max_attempts.\n        \"\"\"\n        interval = base_interval\n        last_result = ResearchSession(\n            task_id=\"\",\n            notebook_id=notebook_id,\n            query=\"\",\n            status=ResearchStatus.NO_RESEARCH,\n        )\n\n        for _ in range(max_attempts):\n            last_result = await self.poll_research(notebook_id)\n            if last_result.status != ResearchStatus.IN_PROGRESS:\n                return last_result\n            await asyncio.sleep(interval)\n            interval = min(max_interval, interval * 2)\n\n        return last_result\n\n    async def import_research_sources(\n        self,\n        notebook_id: str,\n        task_id: str,\n        sources: list[ResearchResult],\n    ) -&gt; list[ImportedSource]:\n        \"\"\"\n        Import research sources into the notebook.\n\n        Args:\n            notebook_id: The target notebook ID.\n            task_id: The research task ID.\n            sources: List of research results to import.\n\n        Returns:\n            List of imported sources with their IDs.\n\n        Raises:\n            ValueError: If inputs are empty.\n            NotebookNotFoundError: If notebook doesn't exist.\n            APIError: If import fails.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"Notebook ID cannot be empty\")\n        if not task_id:\n            raise ValueError(\"Task ID cannot be empty\")\n        if not sources:\n            raise ValueError(\"Sources list cannot be empty\")\n\n        logger.info(\n            \"Importing %d research sources to notebook %s (task: %s)\",\n            len(sources),\n            notebook_id,\n            task_id,\n        )\n\n        # Build source array for import\n        source_array: list[list[Any]] = []\n\n        for src in sources:\n            # Skip deep_report sources (type 5) - not importable\n            if src.result_type == RESULT_TYPE_DEEP_REPORT or not src.url:\n                continue\n\n            if src.result_type == RESULT_TYPE_WEB:\n                # Web source\n                source_data: list[Any] = [\n                    None,\n                    None,\n                    [src.url, src.title],\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    2,\n                ]\n            else:\n                # Drive source - extract document ID from URL\n                doc_id = None\n                if \"id=\" in src.url:\n                    doc_id = src.url.split(\"id=\")[-1].split(\"&amp;\")[0]\n                if not doc_id:\n                    match = re.search(r\"/d/([a-zA-Z0-9_-]+)\", src.url)\n                    if match:\n                        doc_id = match.group(1)\n\n                if doc_id:\n                    mime_types = {\n                        RESULT_TYPE_GOOGLE_DOC: \"application/vnd.google-apps.document\",\n                        RESULT_TYPE_GOOGLE_SLIDES: \"application/vnd.google-apps.presentation\",\n                        RESULT_TYPE_GOOGLE_SHEETS: \"application/vnd.google-apps.spreadsheet\",\n                    }\n                    mime_type = mime_types.get(\n                        src.result_type, \"application/vnd.google-apps.document\"\n                    )\n                    source_data = [\n                        [doc_id, mime_type, 1, src.title],\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        2,\n                    ]\n                else:\n                    # Fallback to web-style\n                    source_data = [\n                        None,\n                        None,\n                        [src.url, src.title],\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        None,\n                        2,\n                    ]\n\n            source_array.append(source_data)\n\n        if not source_array:\n            logger.warning(\"No importable sources found\")\n            return []\n\n        try:\n            # Import RPC: [null, [1], task_id, notebook_id, source_array]\n            params = [None, [1], task_id, notebook_id, source_array]\n            result = await self._session.call_rpc(RPC_IMPORT_RESEARCH, params)\n\n            # Parse imported sources\n            imported = self._parse_import_response(result)\n            logger.info(\"Successfully imported %d sources\", len(imported))\n            return imported\n\n        except APIError as e:\n            if e.status_code == 404:\n                raise NotebookNotFoundError(notebook_id) from e\n            raise\n\n    async def delete_research(self, notebook_id: str) -&gt; bool:\n        \"\"\"\n        Delete or clear research results for a notebook.\n\n        In NotebookLM, there is no direct RPC to \"delete\" a research task;\n        instead, starting a new research session implicitly cancels and\n        replaces the results of any previous session.\n\n        This method acts as a logical clear. Currently, it confirms that\n        no research is active or simply acknowledges the intent.\n\n        Args:\n            notebook_id: The notebook UUID.\n\n        Returns:\n            True if research results are \"cleared\" (logical).\n        \"\"\"\n        logger.info(\"Clearing research results for notebook %s\", notebook_id)\n        # Note: Future implementation could call an RPC if one is discovered.\n        # For now, we rely on the fact that research is transient.\n        return True\n\n    # =========================================================================\n    # Backward Compatibility - Legacy API\n    # =========================================================================\n\n    async def start_web_research(\n        self,\n        notebook_id: str,\n        topic: str,\n        research_type: ResearchType = ResearchType.FAST,\n    ) -&gt; ResearchSession:\n        \"\"\"\n        Start a web research session on a topic.\n        \"\"\"\n        return await self.start_research(\n            notebook_id=notebook_id,\n            query=topic,\n            source=ResearchSource.WEB,\n            mode=research_type,\n        )\n\n    # =========================================================================\n    # Response Parsing Helpers\n    # =========================================================================\n\n    def _parse_poll_response(\n        self,\n        result: list[Any],\n        notebook_id: str,\n    ) -&gt; ResearchSession:\n        \"\"\"Parse the poll_research response into ResearchSession.\"\"\"\n        if (\n            isinstance(result[0], list)\n            and len(result[0]) &gt; 0\n            and isinstance(result[0][0], list)\n        ):\n            result = result[0]\n\n        for task_data in result:\n            if not isinstance(task_data, list) or len(task_data) &lt; 2:\n                continue\n\n            task_id = task_data[0]\n            task_info = task_data[1] if len(task_data) &gt; 1 else None\n\n            if not isinstance(task_id, str):\n                continue\n\n            if not task_info or not isinstance(task_info, list):\n                continue\n\n            query_info = task_info[1] if len(task_info) &gt; 1 else None\n            research_mode = task_info[2] if len(task_info) &gt; 2 else None\n            sources_and_summary = task_info[3] if len(task_info) &gt; 3 else []\n            status_code = task_info[4] if len(task_info) &gt; 4 else None\n\n            query_text = query_info[0] if query_info and len(query_info) &gt; 0 else \"\"\n            source_type = query_info[1] if query_info and len(query_info) &gt; 1 else 1\n\n            sources_data = []\n            summary = \"\"\n            report = \"\"\n\n            if isinstance(sources_and_summary, list) and len(sources_and_summary) &gt;= 1:\n                sources_data = (\n                    sources_and_summary[0]\n                    if isinstance(sources_and_summary[0], list)\n                    else []\n                )\n                if len(sources_and_summary) &gt;= 2 and isinstance(\n                    sources_and_summary[1], str\n                ):\n                    summary = sources_and_summary[1]\n\n            results: list[ResearchResult] = []\n            for idx, src in enumerate(sources_data):\n                if not isinstance(src, list) or len(src) &lt; 2:\n                    continue\n\n                if src[0] is None and len(src) &gt; 1 and isinstance(src[1], str):\n                    title = src[1] if isinstance(src[1], str) else \"\"\n                    result_type = (\n                        src[3] if len(src) &gt; 3 and isinstance(src[3], int) else 5\n                    )\n                    if len(src) &gt; 6 and isinstance(src[6], list) and len(src[6]) &gt; 0:\n                        report = src[6][0] if isinstance(src[6][0], str) else \"\"\n\n                    results.append(\n                        ResearchResult(\n                            index=idx,\n                            url=\"\",\n                            title=title,\n                            description=\"\",\n                            result_type=result_type,\n                            result_type_name=self._get_result_type_name(result_type),\n                        )\n                    )\n                elif isinstance(src[0], str) or len(src) &gt;= 3:\n                    url = src[0] if isinstance(src[0], str) else \"\"\n                    title = src[1] if len(src) &gt; 1 and isinstance(src[1], str) else \"\"\n                    desc = src[2] if len(src) &gt; 2 and isinstance(src[2], str) else \"\"\n                    result_type = (\n                        src[3] if len(src) &gt; 3 and isinstance(src[3], int) else 1\n                    )\n\n                    results.append(\n                        ResearchResult(\n                            index=idx,\n                            url=url,\n                            title=title,\n                            description=desc,\n                            result_type=result_type,\n                            result_type_name=self._get_result_type_name(result_type),\n                        )\n                    )\n\n            status = (\n                ResearchStatus.COMPLETED\n                if status_code == 2\n                else ResearchStatus.IN_PROGRESS\n            )\n\n            return ResearchSession(\n                task_id=task_id,\n                notebook_id=notebook_id,\n                query=query_text,\n                source=\"web\" if source_type == 1 else \"drive\",\n                mode=\"deep\" if research_mode == 5 else \"fast\",\n                status=status,\n                results=results,\n                summary=summary,\n                report=report,\n                source_count=len(results),\n            )\n\n        return ResearchSession(\n            task_id=\"\",\n            notebook_id=notebook_id,\n            query=\"\",\n            status=ResearchStatus.NO_RESEARCH,\n        )\n\n    def _parse_import_response(self, result: Any) -&gt; list[ImportedSource]:\n        \"\"\"Parse import_research_sources response.\"\"\"\n        imported: list[ImportedSource] = []\n        if not result or not isinstance(result, list):\n            return imported\n\n        if (\n            len(result) &gt; 0\n            and isinstance(result[0], list)\n            and len(result[0]) &gt; 0\n            and isinstance(result[0][0], list)\n        ):\n            result = result[0]\n\n        for src_data in result:\n            if isinstance(src_data, list) and len(src_data) &gt;= 2:\n                src_id = (\n                    src_data[0][0]\n                    if src_data[0] and isinstance(src_data[0], list)\n                    else None\n                )\n                src_title = src_data[1] if len(src_data) &gt; 1 else \"Untitled\"\n                if src_id:\n                    imported.append(\n                        ImportedSource(id=str(src_id), title=str(src_title))\n                    )\n        return imported\n\n    @staticmethod\n    def _get_result_type_name(result_type: int) -&gt; str:\n        \"\"\"Convert result type code to human-readable name.\"\"\"\n        type_names = {\n            RESULT_TYPE_WEB: \"web\",\n            RESULT_TYPE_GOOGLE_DOC: \"google_doc\",\n            RESULT_TYPE_GOOGLE_SLIDES: \"google_slides\",\n            RESULT_TYPE_DEEP_REPORT: \"deep_report\",\n            RESULT_TYPE_GOOGLE_SHEETS: \"google_sheets\",\n        }\n        return type_names.get(result_type, \"unknown\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery.start_research","title":"<code>start_research(notebook_id, query, source=ResearchSource.WEB, mode=ResearchType.FAST)</code>  <code>async</code>","text":"<p>Start a research session to discover sources.</p> <p>Research is asynchronous. This method returns immediately with a task_id. Use poll_research() to check status and get results.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook ID to perform research in.</p> required <code>query</code> <code>str</code> <p>The research topic or query string.</p> required <code>source</code> <code>ResearchSource | str</code> <p>Source type - \"web\" or \"drive\" (default: \"web\")</p> <code>WEB</code> <code>mode</code> <code>ResearchType | str</code> <p>Research mode - \"fast\" or \"deep\" (default: \"fast\")</p> <code>FAST</code> <p>Returns:</p> Type Description <code>ResearchSession</code> <p>ResearchSession with task_id for polling.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid source/mode combination.</p> <code>APIError</code> <p>If the research cannot be started.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>async def start_research(\n    self,\n    notebook_id: str,\n    query: str,\n    source: ResearchSource | str = ResearchSource.WEB,\n    mode: ResearchType | str = ResearchType.FAST,\n) -&gt; ResearchSession:\n    \"\"\"\n    Start a research session to discover sources.\n\n    Research is asynchronous. This method returns immediately with a task_id.\n    Use poll_research() to check status and get results.\n\n    Args:\n        notebook_id: The notebook ID to perform research in.\n        query: The research topic or query string.\n        source: Source type - \"web\" or \"drive\" (default: \"web\")\n        mode: Research mode - \"fast\" or \"deep\" (default: \"fast\")\n\n    Returns:\n        ResearchSession with task_id for polling.\n\n    Raises:\n        ValueError: If invalid source/mode combination.\n        APIError: If the research cannot be started.\n        NotebookNotFoundError: If notebook doesn't exist.\n    \"\"\"\n    if not notebook_id or not notebook_id.strip():\n        raise ValueError(\"Notebook ID cannot be empty\")\n    if not query or not query.strip():\n        raise ValueError(\"Research query cannot be empty\")\n\n    notebook_id = notebook_id.strip()\n    query = query.strip()\n\n    # Normalize source and mode\n    source_str = (\n        source.value if isinstance(source, ResearchSource) else source.lower()\n    )\n    mode_str = mode.value if isinstance(mode, ResearchType) else mode.lower()\n\n    if source_str not in (\"web\", \"drive\"):\n        raise ValueError(f\"Invalid source '{source_str}'. Use 'web' or 'drive'.\")\n\n    if mode_str not in (\"fast\", \"deep\"):\n        raise ValueError(f\"Invalid mode '{mode_str}'. Use 'fast' or 'deep'.\")\n\n    if mode_str == \"deep\" and source_str == \"drive\":\n        raise ValueError(\n            \"Deep Research only supports Web sources. Use mode='fast' for Drive.\"\n        )\n\n    # Map to internal constants\n    source_type = (\n        RESEARCH_SOURCE_WEB if source_str == \"web\" else RESEARCH_SOURCE_DRIVE\n    )\n\n    logger.info(\n        \"Starting %s research for query '%s' in notebook %s (source: %s)\",\n        mode_str,\n        query,\n        notebook_id,\n        source_str,\n    )\n\n    try:\n        if mode_str == \"fast\":\n            # Fast Research: Ljjv0c\n            # Payload: [[query, source_type], None, 1, notebook_id]\n            rpc_id = RPC_START_FAST_RESEARCH\n            params = [[query, source_type], None, RESEARCH_MODE_FAST, notebook_id]\n        else:\n            # Deep Research: QA9ei\n            # Payload: [None, [1], [query, source_type], 5, notebook_id]\n            rpc_id = RPC_START_DEEP_RESEARCH\n            params = [\n                None,\n                [1],\n                [query, source_type],\n                RESEARCH_MODE_DEEP,\n                notebook_id,\n            ]\n\n        result = await self._session.call_rpc(rpc_id, params)\n\n        # Parse the response - should contain task_id and optionally report_id\n        task_id = None\n        report_id = None\n\n        if result and isinstance(result, list) and len(result) &gt; 0:\n            task_id = result[0]\n            report_id = result[1] if len(result) &gt; 1 else None\n\n        if not task_id:\n            raise APIError(\"Research started but no task_id returned\")\n\n        logger.info(\"Research started with task_id: %s\", task_id)\n\n        return ResearchSession(\n            task_id=str(task_id),\n            report_id=str(report_id) if report_id else None,\n            notebook_id=notebook_id,\n            query=query,\n            source=source_str,\n            mode=mode_str,\n            status=ResearchStatus.IN_PROGRESS,\n        )\n\n    except APIError as e:\n        if e.status_code == 404:\n            raise NotebookNotFoundError(notebook_id) from e\n        raise\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery.poll_research","title":"<code>poll_research(notebook_id)</code>  <code>async</code>","text":"<p>Poll for research results.</p> <p>Call this repeatedly until status is \"completed\".</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID.</p> required <p>Returns:</p> Type Description <code>ResearchSession</code> <p>ResearchSession with current status and results.</p> <code>ResearchSession</code> <p>When no research is found, status will be ResearchStatus.NO_RESEARCH.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>async def poll_research(self, notebook_id: str) -&gt; ResearchSession:\n    \"\"\"\n    Poll for research results.\n\n    Call this repeatedly until status is \"completed\".\n\n    Args:\n        notebook_id: The notebook UUID.\n\n    Returns:\n        ResearchSession with current status and results.\n        When no research is found, status will be ResearchStatus.NO_RESEARCH.\n    \"\"\"\n    if not notebook_id or not notebook_id.strip():\n        raise ValueError(\"Notebook ID cannot be empty\")\n\n    notebook_id = notebook_id.strip()\n    logger.debug(\"Polling research for notebook: %s\", notebook_id)\n\n    try:\n        # Poll params: [null, null, \"notebook_id\"]\n        params = [None, None, notebook_id]\n        result = await self._session.call_rpc(RPC_POLL_RESEARCH, params)\n\n        if not result or not isinstance(result, list) or len(result) == 0:\n            return ResearchSession(\n                task_id=\"\",\n                notebook_id=notebook_id,\n                query=\"\",\n                status=ResearchStatus.NO_RESEARCH,\n            )\n\n        # Parse the research result\n        return self._parse_poll_response(result, notebook_id)\n\n    except APIError as e:\n        if e.status_code == 404:\n            raise NotebookNotFoundError(notebook_id) from e\n        raise\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery.poll_with_backoff","title":"<code>poll_with_backoff(notebook_id, max_attempts=10, base_interval=5.0, max_interval=60.0)</code>  <code>async</code>","text":"<p>Poll research status with exponential backoff.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID.</p> required <code>max_attempts</code> <code>int</code> <p>Maximum number of polling attempts.</p> <code>10</code> <code>base_interval</code> <code>float</code> <p>Initial polling interval in seconds.</p> <code>5.0</code> <code>max_interval</code> <code>float</code> <p>Maximum polling interval in seconds.</p> <code>60.0</code> <p>Returns:</p> Type Description <code>ResearchSession</code> <p>ResearchSession when completed or after max_attempts.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>async def poll_with_backoff(\n    self,\n    notebook_id: str,\n    max_attempts: int = 10,\n    base_interval: float = 5.0,\n    max_interval: float = 60.0,\n) -&gt; ResearchSession:\n    \"\"\"\n    Poll research status with exponential backoff.\n\n    Args:\n        notebook_id: The notebook UUID.\n        max_attempts: Maximum number of polling attempts.\n        base_interval: Initial polling interval in seconds.\n        max_interval: Maximum polling interval in seconds.\n\n    Returns:\n        ResearchSession when completed or after max_attempts.\n    \"\"\"\n    interval = base_interval\n    last_result = ResearchSession(\n        task_id=\"\",\n        notebook_id=notebook_id,\n        query=\"\",\n        status=ResearchStatus.NO_RESEARCH,\n    )\n\n    for _ in range(max_attempts):\n        last_result = await self.poll_research(notebook_id)\n        if last_result.status != ResearchStatus.IN_PROGRESS:\n            return last_result\n        await asyncio.sleep(interval)\n        interval = min(max_interval, interval * 2)\n\n    return last_result\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery.import_research_sources","title":"<code>import_research_sources(notebook_id, task_id, sources)</code>  <code>async</code>","text":"<p>Import research sources into the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The target notebook ID.</p> required <code>task_id</code> <code>str</code> <p>The research task ID.</p> required <code>sources</code> <code>list[ResearchResult]</code> <p>List of research results to import.</p> required <p>Returns:</p> Type Description <code>list[ImportedSource]</code> <p>List of imported sources with their IDs.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If inputs are empty.</p> <code>NotebookNotFoundError</code> <p>If notebook doesn't exist.</p> <code>APIError</code> <p>If import fails.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>async def import_research_sources(\n    self,\n    notebook_id: str,\n    task_id: str,\n    sources: list[ResearchResult],\n) -&gt; list[ImportedSource]:\n    \"\"\"\n    Import research sources into the notebook.\n\n    Args:\n        notebook_id: The target notebook ID.\n        task_id: The research task ID.\n        sources: List of research results to import.\n\n    Returns:\n        List of imported sources with their IDs.\n\n    Raises:\n        ValueError: If inputs are empty.\n        NotebookNotFoundError: If notebook doesn't exist.\n        APIError: If import fails.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"Notebook ID cannot be empty\")\n    if not task_id:\n        raise ValueError(\"Task ID cannot be empty\")\n    if not sources:\n        raise ValueError(\"Sources list cannot be empty\")\n\n    logger.info(\n        \"Importing %d research sources to notebook %s (task: %s)\",\n        len(sources),\n        notebook_id,\n        task_id,\n    )\n\n    # Build source array for import\n    source_array: list[list[Any]] = []\n\n    for src in sources:\n        # Skip deep_report sources (type 5) - not importable\n        if src.result_type == RESULT_TYPE_DEEP_REPORT or not src.url:\n            continue\n\n        if src.result_type == RESULT_TYPE_WEB:\n            # Web source\n            source_data: list[Any] = [\n                None,\n                None,\n                [src.url, src.title],\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                2,\n            ]\n        else:\n            # Drive source - extract document ID from URL\n            doc_id = None\n            if \"id=\" in src.url:\n                doc_id = src.url.split(\"id=\")[-1].split(\"&amp;\")[0]\n            if not doc_id:\n                match = re.search(r\"/d/([a-zA-Z0-9_-]+)\", src.url)\n                if match:\n                    doc_id = match.group(1)\n\n            if doc_id:\n                mime_types = {\n                    RESULT_TYPE_GOOGLE_DOC: \"application/vnd.google-apps.document\",\n                    RESULT_TYPE_GOOGLE_SLIDES: \"application/vnd.google-apps.presentation\",\n                    RESULT_TYPE_GOOGLE_SHEETS: \"application/vnd.google-apps.spreadsheet\",\n                }\n                mime_type = mime_types.get(\n                    src.result_type, \"application/vnd.google-apps.document\"\n                )\n                source_data = [\n                    [doc_id, mime_type, 1, src.title],\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    2,\n                ]\n            else:\n                # Fallback to web-style\n                source_data = [\n                    None,\n                    None,\n                    [src.url, src.title],\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    None,\n                    2,\n                ]\n\n        source_array.append(source_data)\n\n    if not source_array:\n        logger.warning(\"No importable sources found\")\n        return []\n\n    try:\n        # Import RPC: [null, [1], task_id, notebook_id, source_array]\n        params = [None, [1], task_id, notebook_id, source_array]\n        result = await self._session.call_rpc(RPC_IMPORT_RESEARCH, params)\n\n        # Parse imported sources\n        imported = self._parse_import_response(result)\n        logger.info(\"Successfully imported %d sources\", len(imported))\n        return imported\n\n    except APIError as e:\n        if e.status_code == 404:\n            raise NotebookNotFoundError(notebook_id) from e\n        raise\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchDiscovery.start_web_research","title":"<code>start_web_research(notebook_id, topic, research_type=ResearchType.FAST)</code>  <code>async</code>","text":"<p>Start a web research session on a topic.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>async def start_web_research(\n    self,\n    notebook_id: str,\n    topic: str,\n    research_type: ResearchType = ResearchType.FAST,\n) -&gt; ResearchSession:\n    \"\"\"\n    Start a web research session on a topic.\n    \"\"\"\n    return await self.start_research(\n        notebook_id=notebook_id,\n        query=topic,\n        source=ResearchSource.WEB,\n        mode=research_type,\n    )\n</code></pre>"},{"location":"api_reference/#chat-query","title":"Chat &amp; Query","text":""},{"location":"api_reference/#pynotebooklm.chat.ChatSession","title":"<code>pynotebooklm.chat.ChatSession</code>","text":"<p>Manages chat conversation and content creation sessions.</p> Example <p>async with BrowserSession(auth) as session: ...     chat = ChatSession(session) ...     answer = await chat.query(nb_id, \"Summarize this\")</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>class ChatSession:\n    \"\"\"\n    Manages chat conversation and content creation sessions.\n\n    Example:\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     chat = ChatSession(session)\n        ...     answer = await chat.query(nb_id, \"Summarize this\")\n    \"\"\"\n\n    # Chat configuration constants\n    GOAL_DEFAULT = 1\n    GOAL_CUSTOM = 2\n    GOAL_LEARNING = 3\n\n    LENGTH_DEFAULT = 1\n    LENGTH_LONGER = 4\n    LENGTH_SHORTER = 5\n\n    def __init__(self, session: BrowserSession) -&gt; None:\n        \"\"\"\n        Initialize the chat session.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n        self._api = NotebookLMAPI(session)\n\n    async def _get_all_source_ids(self, notebook_id: str) -&gt; list[str]:\n        \"\"\"Helper to get all source IDs for a notebook.\"\"\"\n        try:\n            raw_data = await self._api.get_notebook(notebook_id)\n            if not raw_data:\n                return []\n\n            notebook = parse_notebook_response(raw_data)\n            return [s.id for s in notebook.sources if s.id]\n        except Exception as e:\n            logger.warning(\n                \"Failed to fetch sources for notebook %s: %s\", notebook_id, e\n            )\n            return []\n\n    async def query(\n        self,\n        notebook_id: str,\n        question: str,\n        source_ids: list[str] | None = None,\n        conversation_id: str | None = None,\n    ) -&gt; str:\n        \"\"\"\n        Ask a question to the notebook.\n\n        Args:\n            notebook_id: Notebook UUID.\n            question: The question text.\n            source_ids: Optional list of source IDs to limit scope.\n            conversation_id: Optional conversation ID for follow-up.\n\n        Returns:\n            The AI's answer text.\n        \"\"\"\n        logger.info(\"Querying notebook %s: %s\", notebook_id, question)\n\n        # If no sources provided, use all sources\n        if not source_ids:\n            source_ids = await self._get_all_source_ids(notebook_id)\n            logger.debug(\"Using all %d sources for query\", len(source_ids))\n\n        result = await self._api.query_notebook(\n            notebook_id,\n            question,\n            source_ids=source_ids,\n            conversation_id=conversation_id,\n        )\n\n        raw_response = result.get(\"raw_response\", \"\")\n        answer = self._parse_query_response(raw_response)\n\n        return answer\n\n    async def configure(\n        self,\n        notebook_id: str,\n        goal: str = \"default\",\n        custom_prompt: str | None = None,\n        length: str = \"default\",\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Configure chat settings (tone, style, length).\n\n        Args:\n            notebook_id: Notebook UUID.\n            goal: \"default\", \"learning\", \"custom\".\n            custom_prompt: Required if goal is \"custom\".\n            length: \"default\", \"longer\", \"shorter\".\n        \"\"\"\n        goal_map = {\n            \"default\": self.GOAL_DEFAULT,\n            \"learning\": self.GOAL_LEARNING,\n            \"custom\": self.GOAL_CUSTOM,\n        }\n        length_map = {\n            \"default\": self.LENGTH_DEFAULT,\n            \"longer\": self.LENGTH_LONGER,\n            \"shorter\": self.LENGTH_SHORTER,\n        }\n\n        goal_code = goal_map.get(goal.lower(), self.GOAL_DEFAULT)\n        length_code = length_map.get(length.lower(), self.LENGTH_DEFAULT)\n\n        if goal.lower() == \"custom\" and not custom_prompt:\n            raise ValueError(\"custom_prompt is required for 'custom' goal\")\n\n        logger.info(\"Configuring chat: goal=%s, length=%s\", goal, length)\n\n        return await self._api.configure_chat(\n            notebook_id,\n            goal=goal_code,\n            custom_prompt=custom_prompt,\n            length=length_code,\n        )\n\n    async def get_notebook_summary(self, notebook_id: str) -&gt; dict[str, Any]:\n        \"\"\"\n        Get AI summary and suggested topics for the notebook.\n\n        Returns dict with keys: 'summary', 'suggested_topics'\n        \"\"\"\n        raw = await self._api.get_notebook_summary(notebook_id)\n\n        # Parse result\n        summary = \"\"\n        suggested_topics: list[dict[str, str]] = []\n\n        if raw and isinstance(raw, list):\n            # Summary is at result[0][0]\n            if len(raw) &gt; 0 and isinstance(raw[0], list) and len(raw[0]) &gt; 0:\n                summary = raw[0][0]\n\n            # Suggested topics are at result[1][0]\n            if len(raw) &gt; 1 and raw[1]:\n                topics_data = (\n                    raw[1][0] if isinstance(raw[1], list) and len(raw[1]) &gt; 0 else []\n                )\n                for topic in topics_data:\n                    if isinstance(topic, list) and len(topic) &gt;= 2:\n                        suggested_topics.append(\n                            {\n                                \"question\": topic[0],\n                                \"prompt\": topic[1],\n                            }\n                        )\n\n        return {\n            \"summary\": summary,\n            \"suggested_topics\": suggested_topics,\n        }\n\n    async def get_source_summary(self, source_id: str) -&gt; dict[str, Any]:\n        \"\"\"\n        Get AI summary and keywords for a source.\n\n        Returns dict with keys: 'summary', 'keywords'\n        \"\"\"\n        raw = await self._api.get_source_guide(source_id)\n\n        summary = \"\"\n        keywords: list[str] = []\n\n        if raw and isinstance(raw, list):\n            if len(raw) &gt; 0 and isinstance(raw[0], list):\n                if len(raw[0]) &gt; 0 and isinstance(raw[0][0], list):\n                    inner = raw[0][0]\n\n                    if (\n                        len(inner) &gt; 1\n                        and isinstance(inner[1], list)\n                        and len(inner[1]) &gt; 0\n                    ):\n                        summary = inner[1][0]\n\n                    if (\n                        len(inner) &gt; 2\n                        and isinstance(inner[2], list)\n                        and len(inner[2]) &gt; 0\n                    ):\n                        keywords = inner[2][0] if isinstance(inner[2][0], list) else []\n\n        return {\n            \"summary\": summary,\n            \"keywords\": keywords,\n        }\n\n    async def create_report(\n        self,\n        notebook_id: str,\n        title: str,\n        description: str,\n        prompt: str,\n        source_ids: list[str] | None = None,\n        language: str = \"en\",\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Create a report (briefing doc, blog post, etc) artifact.\n        \"\"\"\n        # If no sources provided, use all sources\n        if not source_ids:\n            source_ids = await self._get_all_source_ids(notebook_id)\n            logger.debug(\"Using all %d sources for report\", len(source_ids))\n\n        # Build source IDs structure\n        sources_nested = [[[sid]] for sid in source_ids] if source_ids else []\n        sources_simple = [[sid] for sid in source_ids] if source_ids else []\n\n        # Options at position 7\n        report_options = [\n            None,\n            [title, description, None, sources_simple, language, prompt, None, True],\n        ]\n\n        # Outer content params\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_REPORT,\n            sources_nested,\n            None,\n            None,\n            None,\n            report_options,\n        ]\n\n        logger.info(\"Creating report '%s'...\", title)\n        result = await self._api.create_studio_artifact(\n            notebook_id, STUDIO_TYPE_REPORT, content\n        )\n\n        # Parse result for artifact_id\n        artifact_id = None\n        if result and isinstance(result, list) and len(result) &gt; 0:\n            artifact_data = result[0]\n            if isinstance(artifact_data, list) and len(artifact_data) &gt; 0:\n                first_item = artifact_data[0]\n                # It might be a string ID directly or wrapped in list\n                if isinstance(first_item, str):\n                    artifact_id = first_item\n                elif isinstance(first_item, list) and len(first_item) &gt; 0:\n                    artifact_id = first_item[0]\n\n        return {\n            \"artifact_id\": artifact_id,\n            \"status\": \"in_progress\",\n        }\n\n    async def create_briefing(\n        self, notebook_id: str, source_ids: list[str] | None = None\n    ) -&gt; dict[str, Any]:\n        \"\"\"Convenience method to create a Briefing Doc.\"\"\"\n        return await self.create_report(\n            notebook_id,\n            title=\"Briefing Doc\",\n            description=\"Key insights and quotes\",\n            prompt=\"Create a comprehensive briefing document...\",\n            source_ids=source_ids,\n        )\n\n    async def list_artifacts(self, notebook_id: str) -&gt; list[dict[str, Any]]:\n        \"\"\"List all studio artifacts and their statuses.\"\"\"\n        # Get studio artifacts (audio, video, reports)\n        artifacts = await self._api.list_studio_artifacts(notebook_id)\n\n        # Get mind maps\n        try:\n            mm_gen = MindMapGenerator(self._session)\n            mind_maps = await mm_gen.list(notebook_id)\n            for mm in mind_maps:\n                artifacts.append(\n                    {\n                        \"id\": mm.id,\n                        \"title\": mm.title,\n                        \"type\": \"Mind Map\",\n                        \"status\": \"completed\",\n                        \"created_at\": mm.created_at,\n                    }\n                )\n        except Exception as e:\n            logger.warning(\"Failed to list mind maps: %s\", e)\n\n        return artifacts\n\n    def _parse_query_response(self, response_text: str) -&gt; str:\n        \"\"\"\n        Parse streaming query response to extract the final answer.\n        \"\"\"\n        if not response_text:\n            return \"\"\n\n        longest_answer = \"\"\n        longest_thinking = \"\"\n        chunks = self._session.parse_streaming_response(response_text)\n        for chunk in chunks:\n            text, is_answer = self._extract_answer_from_chunk(chunk)\n            if text:\n                if is_answer and len(text) &gt; len(longest_answer):\n                    longest_answer = text\n                elif not is_answer and len(text) &gt; len(longest_thinking):\n                    longest_thinking = text\n\n        return longest_answer if longest_answer else longest_thinking\n\n    def _extract_answer_from_chunk(self, chunk: Any) -&gt; tuple[str | None, bool]:\n        \"\"\"Extract answer from a JSON query chunk.\"\"\"\n        data = chunk\n        if isinstance(chunk, str):\n            try:\n                data = json.loads(chunk)\n            except json.JSONDecodeError:\n                return None, False\n\n        if not isinstance(data, list) or len(data) == 0:\n            return None, False\n\n        for item in data:\n            if not isinstance(item, list) or len(item) &lt; 3:\n                continue\n            if item[0] != \"wrb.fr\":\n                continue\n\n            inner_json_str = item[2]\n            if not isinstance(inner_json_str, str):\n                continue\n\n            try:\n                inner_data = json.loads(inner_json_str)\n            except json.JSONDecodeError:\n                continue\n\n            # Type indicator is at inner_data[0][4][-1]: 1 = answer, 2 = thinking\n            if isinstance(inner_data, list) and len(inner_data) &gt; 0:\n                first_elem = inner_data[0]\n\n                # Case A: nested list (standard)\n                if isinstance(first_elem, list) and len(first_elem) &gt; 0:\n                    answer_text = first_elem[0]\n                    # REDUCED THRESHOLD: &gt; 0 chars (was 20)\n                    if isinstance(answer_text, str) and len(answer_text) &gt; 0:\n                        # Check type\n                        is_answer = False\n                        if (\n                            len(first_elem) &gt; 4\n                            and isinstance(first_elem[4], list)\n                            and len(first_elem[4]) &gt; 0\n                        ):\n                            # Check for type code safely\n                            val = first_elem[4][-1]\n                            if isinstance(val, int) and val == 1:\n                                is_answer = True\n\n                        return answer_text, is_answer\n\n                # Case B: direct string (fallback)\n                elif isinstance(first_elem, str) and len(first_elem) &gt; 0:\n                    return first_elem, False\n\n        return None, False\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.query","title":"<code>query(notebook_id, question, source_ids=None, conversation_id=None)</code>  <code>async</code>","text":"<p>Ask a question to the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>question</code> <code>str</code> <p>The question text.</p> required <code>source_ids</code> <code>list[str] | None</code> <p>Optional list of source IDs to limit scope.</p> <code>None</code> <code>conversation_id</code> <code>str | None</code> <p>Optional conversation ID for follow-up.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The AI's answer text.</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def query(\n    self,\n    notebook_id: str,\n    question: str,\n    source_ids: list[str] | None = None,\n    conversation_id: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Ask a question to the notebook.\n\n    Args:\n        notebook_id: Notebook UUID.\n        question: The question text.\n        source_ids: Optional list of source IDs to limit scope.\n        conversation_id: Optional conversation ID for follow-up.\n\n    Returns:\n        The AI's answer text.\n    \"\"\"\n    logger.info(\"Querying notebook %s: %s\", notebook_id, question)\n\n    # If no sources provided, use all sources\n    if not source_ids:\n        source_ids = await self._get_all_source_ids(notebook_id)\n        logger.debug(\"Using all %d sources for query\", len(source_ids))\n\n    result = await self._api.query_notebook(\n        notebook_id,\n        question,\n        source_ids=source_ids,\n        conversation_id=conversation_id,\n    )\n\n    raw_response = result.get(\"raw_response\", \"\")\n    answer = self._parse_query_response(raw_response)\n\n    return answer\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.configure","title":"<code>configure(notebook_id, goal='default', custom_prompt=None, length='default')</code>  <code>async</code>","text":"<p>Configure chat settings (tone, style, length).</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>goal</code> <code>str</code> <p>\"default\", \"learning\", \"custom\".</p> <code>'default'</code> <code>custom_prompt</code> <code>str | None</code> <p>Required if goal is \"custom\".</p> <code>None</code> <code>length</code> <code>str</code> <p>\"default\", \"longer\", \"shorter\".</p> <code>'default'</code> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def configure(\n    self,\n    notebook_id: str,\n    goal: str = \"default\",\n    custom_prompt: str | None = None,\n    length: str = \"default\",\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Configure chat settings (tone, style, length).\n\n    Args:\n        notebook_id: Notebook UUID.\n        goal: \"default\", \"learning\", \"custom\".\n        custom_prompt: Required if goal is \"custom\".\n        length: \"default\", \"longer\", \"shorter\".\n    \"\"\"\n    goal_map = {\n        \"default\": self.GOAL_DEFAULT,\n        \"learning\": self.GOAL_LEARNING,\n        \"custom\": self.GOAL_CUSTOM,\n    }\n    length_map = {\n        \"default\": self.LENGTH_DEFAULT,\n        \"longer\": self.LENGTH_LONGER,\n        \"shorter\": self.LENGTH_SHORTER,\n    }\n\n    goal_code = goal_map.get(goal.lower(), self.GOAL_DEFAULT)\n    length_code = length_map.get(length.lower(), self.LENGTH_DEFAULT)\n\n    if goal.lower() == \"custom\" and not custom_prompt:\n        raise ValueError(\"custom_prompt is required for 'custom' goal\")\n\n    logger.info(\"Configuring chat: goal=%s, length=%s\", goal, length)\n\n    return await self._api.configure_chat(\n        notebook_id,\n        goal=goal_code,\n        custom_prompt=custom_prompt,\n        length=length_code,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.get_notebook_summary","title":"<code>get_notebook_summary(notebook_id)</code>  <code>async</code>","text":"<p>Get AI summary and suggested topics for the notebook.</p> <p>Returns dict with keys: 'summary', 'suggested_topics'</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def get_notebook_summary(self, notebook_id: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get AI summary and suggested topics for the notebook.\n\n    Returns dict with keys: 'summary', 'suggested_topics'\n    \"\"\"\n    raw = await self._api.get_notebook_summary(notebook_id)\n\n    # Parse result\n    summary = \"\"\n    suggested_topics: list[dict[str, str]] = []\n\n    if raw and isinstance(raw, list):\n        # Summary is at result[0][0]\n        if len(raw) &gt; 0 and isinstance(raw[0], list) and len(raw[0]) &gt; 0:\n            summary = raw[0][0]\n\n        # Suggested topics are at result[1][0]\n        if len(raw) &gt; 1 and raw[1]:\n            topics_data = (\n                raw[1][0] if isinstance(raw[1], list) and len(raw[1]) &gt; 0 else []\n            )\n            for topic in topics_data:\n                if isinstance(topic, list) and len(topic) &gt;= 2:\n                    suggested_topics.append(\n                        {\n                            \"question\": topic[0],\n                            \"prompt\": topic[1],\n                        }\n                    )\n\n    return {\n        \"summary\": summary,\n        \"suggested_topics\": suggested_topics,\n    }\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.get_source_summary","title":"<code>get_source_summary(source_id)</code>  <code>async</code>","text":"<p>Get AI summary and keywords for a source.</p> <p>Returns dict with keys: 'summary', 'keywords'</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def get_source_summary(self, source_id: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get AI summary and keywords for a source.\n\n    Returns dict with keys: 'summary', 'keywords'\n    \"\"\"\n    raw = await self._api.get_source_guide(source_id)\n\n    summary = \"\"\n    keywords: list[str] = []\n\n    if raw and isinstance(raw, list):\n        if len(raw) &gt; 0 and isinstance(raw[0], list):\n            if len(raw[0]) &gt; 0 and isinstance(raw[0][0], list):\n                inner = raw[0][0]\n\n                if (\n                    len(inner) &gt; 1\n                    and isinstance(inner[1], list)\n                    and len(inner[1]) &gt; 0\n                ):\n                    summary = inner[1][0]\n\n                if (\n                    len(inner) &gt; 2\n                    and isinstance(inner[2], list)\n                    and len(inner[2]) &gt; 0\n                ):\n                    keywords = inner[2][0] if isinstance(inner[2][0], list) else []\n\n    return {\n        \"summary\": summary,\n        \"keywords\": keywords,\n    }\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.create_briefing","title":"<code>create_briefing(notebook_id, source_ids=None)</code>  <code>async</code>","text":"<p>Convenience method to create a Briefing Doc.</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def create_briefing(\n    self, notebook_id: str, source_ids: list[str] | None = None\n) -&gt; dict[str, Any]:\n    \"\"\"Convenience method to create a Briefing Doc.\"\"\"\n    return await self.create_report(\n        notebook_id,\n        title=\"Briefing Doc\",\n        description=\"Key insights and quotes\",\n        prompt=\"Create a comprehensive briefing document...\",\n        source_ids=source_ids,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.chat.ChatSession.list_artifacts","title":"<code>list_artifacts(notebook_id)</code>  <code>async</code>","text":"<p>List all studio artifacts and their statuses.</p> Source code in <code>src/pynotebooklm/chat.py</code> <pre><code>async def list_artifacts(self, notebook_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"List all studio artifacts and their statuses.\"\"\"\n    # Get studio artifacts (audio, video, reports)\n    artifacts = await self._api.list_studio_artifacts(notebook_id)\n\n    # Get mind maps\n    try:\n        mm_gen = MindMapGenerator(self._session)\n        mind_maps = await mm_gen.list(notebook_id)\n        for mm in mind_maps:\n            artifacts.append(\n                {\n                    \"id\": mm.id,\n                    \"title\": mm.title,\n                    \"type\": \"Mind Map\",\n                    \"status\": \"completed\",\n                    \"created_at\": mm.created_at,\n                }\n            )\n    except Exception as e:\n        logger.warning(\"Failed to list mind maps: %s\", e)\n\n    return artifacts\n</code></pre>"},{"location":"api_reference/#mind-maps","title":"Mind Maps","text":""},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator","title":"<code>pynotebooklm.mindmaps.MindMapGenerator</code>","text":"<p>Generates and manages mind maps for NotebookLM notebooks.</p> <p>This class provides methods for generating mind maps from sources, saving them to notebooks, listing existing maps, and exporting to various formats.</p> Example <p>async with BrowserSession(auth) as session: ...     generator = MindMapGenerator(session) ...     result = await generator.create(notebook_id, source_ids) ...     print(f\"Created mind map: {result.id}\")</p> <p>Attributes:</p> Name Type Description <code>session</code> <p>Active BrowserSession instance.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>class MindMapGenerator:\n    \"\"\"\n    Generates and manages mind maps for NotebookLM notebooks.\n\n    This class provides methods for generating mind maps from sources,\n    saving them to notebooks, listing existing maps, and exporting\n    to various formats.\n\n    Example:\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     generator = MindMapGenerator(session)\n        ...     result = await generator.create(notebook_id, source_ids)\n        ...     print(f\"Created mind map: {result.id}\")\n\n    Attributes:\n        session: Active BrowserSession instance.\n    \"\"\"\n\n    def __init__(self, session: \"BrowserSession\") -&gt; None:\n        \"\"\"\n        Initialize the mind map generator.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self.session = session\n\n    async def generate(self, source_ids: list[str]) -&gt; MindMapGenerateResult:\n        \"\"\"\n        Generate a mind map JSON structure from sources.\n\n        This is step 1 of the 2-step creation process. After generation,\n        use save() to persist the mind map to a notebook.\n\n        Args:\n            source_ids: List of source UUIDs to include in the mind map.\n\n        Returns:\n            MindMapGenerateResult with the JSON structure and generation ID.\n\n        Raises:\n            ValueError: If source_ids is empty.\n            SourceError: If generation fails.\n        \"\"\"\n        if not source_ids:\n            raise ValueError(\"source_ids cannot be empty\")\n\n        # Build source IDs in the nested format: [[[id1]], [[id2]], ...]\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        params = [\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            [\"interactive_mindmap\", [[\"[CONTEXT]\", \"\"]], \"\"],\n            None,\n            [2, None, [1]],\n        ]\n\n        logger.debug(\"Generating mind map from %d sources\", len(source_ids))\n\n        try:\n            result = await self.session.call_rpc(RPC_GENERATE_MIND_MAP, params)\n        except APIError as e:\n            logger.error(\"Failed to generate mind map: %s\", e)\n            raise SourceError(f\"Failed to generate mind map: {e}\") from e\n\n        # Parse response: [[json_string, null, [gen_ids]]]\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise SourceError(\"Mind map generation returned empty result\")\n\n        # Unwrap response - may be doubly nested\n        inner = result[0] if isinstance(result[0], list) else result\n\n        mind_map_json = (\n            inner[0] if len(inner) &gt; 0 and isinstance(inner[0], str) else None\n        )\n        if not mind_map_json:\n            raise SourceError(\"Mind map generation did not return JSON structure\")\n\n        generation_id = None\n        if len(inner) &gt; 2 and isinstance(inner[2], list) and len(inner[2]) &gt; 0:\n            generation_id = str(inner[2][0])\n\n        logger.info(\"Generated mind map (generation_id=%s)\", generation_id)\n\n        return MindMapGenerateResult(\n            mind_map_json=mind_map_json,\n            generation_id=generation_id,\n            source_ids=source_ids,\n        )\n\n    async def save(\n        self,\n        notebook_id: str,\n        mind_map_json: str,\n        source_ids: list[str],\n        title: str = \"Mind Map\",\n    ) -&gt; MindMap:\n        \"\"\"\n        Save a generated mind map to a notebook.\n\n        This is step 2 of the 2-step creation process. First use\n        generate() to create the JSON structure.\n\n        Args:\n            notebook_id: The notebook UUID to save to.\n            mind_map_json: The JSON string from generate().\n            source_ids: List of source UUIDs used to generate the map.\n            title: Display title for the mind map.\n\n        Returns:\n            MindMap with the saved mind map details.\n\n        Raises:\n            ValueError: If notebook_id or mind_map_json is empty.\n            NotebookNotFoundError: If the notebook doesn't exist.\n            APIError: If saving fails.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"notebook_id cannot be empty\")\n        if not mind_map_json:\n            raise ValueError(\"mind_map_json cannot be empty\")\n\n        # Build source IDs in simpler format: [[id1], [id2], ...]\n        sources_simple = [[sid] for sid in source_ids]\n\n        # Metadata structure: [2, None, None, 5, sources]\n        metadata = [2, None, None, 5, sources_simple]\n\n        params = [\n            notebook_id,\n            mind_map_json,\n            metadata,\n            None,\n            title,\n        ]\n\n        logger.debug(\"Saving mind map '%s' to notebook %s\", title, notebook_id)\n\n        try:\n            result = await self.session.call_rpc(RPC_SAVE_MIND_MAP, params)\n        except APIError as e:\n            if e.status_code == 404:\n                raise NotebookNotFoundError(f\"Notebook not found: {notebook_id}\") from e\n            logger.error(\"Failed to save mind map: %s\", e)\n            raise\n\n        # Parse response: [[mind_map_id, json, metadata, None, title]]\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise APIError(\"Mind map save returned empty result\")\n\n        inner = result[0] if isinstance(result[0], list) else result\n\n        mind_map_id = inner[0] if len(inner) &gt; 0 else None\n        saved_json = inner[1] if len(inner) &gt; 1 else mind_map_json\n        saved_title = inner[4] if len(inner) &gt; 4 else title\n\n        if not mind_map_id:\n            raise APIError(\"Mind map save did not return an ID\")\n\n        logger.info(\"Saved mind map '%s' (id=%s)\", saved_title, mind_map_id)\n\n        return MindMap(\n            id=mind_map_id,\n            notebook_id=notebook_id,\n            title=saved_title,\n            mind_map_json=saved_json,\n            source_ids=source_ids,\n            created_at=datetime.now(),\n        )\n\n    async def create(\n        self,\n        notebook_id: str,\n        source_ids: list[str] | None = None,\n        title: str = \"Mind Map\",\n    ) -&gt; MindMap:\n        \"\"\"\n        Create a mind map from sources and save it to a notebook.\n\n        This is a convenience method that combines generate() and save().\n        If source_ids is not provided, it will use all sources from the notebook.\n\n        Args:\n            notebook_id: The notebook UUID.\n            source_ids: Optional list of source UUIDs. If None, uses all sources.\n            title: Display title for the mind map.\n\n        Returns:\n            MindMap with the created mind map details.\n\n        Raises:\n            ValueError: If notebook_id is empty or no sources available.\n            NotebookNotFoundError: If the notebook doesn't exist.\n            SourceError: If generation fails.\n            APIError: If saving fails.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"notebook_id cannot be empty\")\n\n        # If no source_ids provided, get all sources from the notebook\n        if source_ids is None:\n            from .notebooks import NotebookManager\n\n            notebook_manager = NotebookManager(self.session)\n            notebook = await notebook_manager.get(notebook_id)\n            source_ids = [s.id for s in notebook.sources]\n\n        if not source_ids:\n            raise ValueError(\n                \"Cannot create mind map: notebook has no sources. \"\n                \"Add sources first, then create a mind map.\"\n            )\n\n        logger.info(\n            \"Creating mind map '%s' from %d sources in notebook %s\",\n            title,\n            len(source_ids),\n            notebook_id,\n        )\n\n        # Step 1: Generate\n        gen_result = await self.generate(source_ids)\n\n        # Step 2: Save\n        return await self.save(\n            notebook_id=notebook_id,\n            mind_map_json=gen_result.mind_map_json,\n            source_ids=source_ids,\n            title=title,\n        )\n\n    async def list(self, notebook_id: str) -&gt; list[MindMap]:\n        \"\"\"\n        List all mind maps in a notebook.\n\n        Args:\n            notebook_id: The notebook UUID.\n\n        Returns:\n            List of MindMap objects.\n\n        Raises:\n            ValueError: If notebook_id is empty.\n            NotebookNotFoundError: If the notebook doesn't exist.\n            APIError: If the API call fails.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"notebook_id cannot be empty\")\n\n        params = [notebook_id]\n\n        logger.debug(\"Listing mind maps for notebook %s\", notebook_id)\n\n        try:\n            result = await self.session.call_rpc(RPC_LIST_MIND_MAPS, params)\n        except APIError as e:\n            if e.status_code == 404:\n                raise NotebookNotFoundError(f\"Notebook not found: {notebook_id}\") from e\n            raise\n\n        mind_maps: list[MindMap] = []\n\n        if not result or not isinstance(result, list) or len(result) == 0:\n            return mind_maps\n\n        # Response: [[[mind_map_id, [id, json, metadata, None, title]], ...], [timestamp]]\n        mind_map_list = result[0] if isinstance(result[0], list) else []\n\n        for item in mind_map_list:\n            if not isinstance(item, list) or len(item) &lt; 2:\n                continue\n\n            mind_map_id = item[0]\n            details = item[1] if len(item) &gt; 1 else []\n\n            if not isinstance(details, list) or len(details) &lt; 5:\n                continue\n\n            # Details: [id, json, metadata, None, title]\n            mind_map_json = details[1] if len(details) &gt; 1 else None\n            title = details[4] if len(details) &gt; 4 else \"Mind Map\"\n            metadata = details[2] if len(details) &gt; 2 else []\n\n            # Extract timestamp from metadata [2, version_id, [timestamp, nanos], ...]\n            created_at = None\n            if isinstance(metadata, list) and len(metadata) &gt; 2:\n                ts = metadata[2]\n                created_at = self._parse_timestamp(ts)\n\n            # Extract source IDs from metadata\n            source_ids = []\n            if isinstance(metadata, list) and len(metadata) &gt; 4:\n                sources = metadata[4]\n                if isinstance(sources, list):\n                    for s in sources:\n                        if isinstance(s, list) and len(s) &gt; 0:\n                            source_ids.append(s[0])\n\n            mind_maps.append(\n                MindMap(\n                    id=mind_map_id,\n                    notebook_id=notebook_id,\n                    title=title,\n                    mind_map_json=mind_map_json,\n                    created_at=created_at,\n                    source_ids=source_ids,\n                )\n            )\n\n        logger.debug(\"Found %d mind maps\", len(mind_maps))\n        return mind_maps\n\n    async def get(self, notebook_id: str, mindmap_id: str) -&gt; MindMap | None:\n        \"\"\"\n        Get a specific mind map by ID.\n\n        Args:\n            notebook_id: The notebook UUID.\n            mindmap_id: The mind map UUID.\n\n        Returns:\n            MindMap if found, None otherwise.\n\n        Raises:\n            ValueError: If notebook_id or mindmap_id is empty.\n            NotebookNotFoundError: If the notebook doesn't exist.\n            APIError: If the API call fails.\n        \"\"\"\n        if not notebook_id:\n            raise ValueError(\"notebook_id cannot be empty\")\n        if not mindmap_id:\n            raise ValueError(\"mindmap_id cannot be empty\")\n\n        mind_maps = await self.list(notebook_id)\n        for mm in mind_maps:\n            if mm.id == mindmap_id:\n                return mm\n        return None\n\n    def _parse_timestamp(self, ts_data: Any) -&gt; datetime | None:\n        \"\"\"Parse timestamp from API response.\"\"\"\n        try:\n            if isinstance(ts_data, list) and len(ts_data) &gt;= 1:\n                # Format: [seconds, nanos] or just seconds\n                seconds = ts_data[0]\n                if isinstance(seconds, int | float):\n                    return datetime.fromtimestamp(seconds)\n            elif isinstance(ts_data, int | float):\n                # Could be seconds or milliseconds\n                if ts_data &gt; 1e11:  # milliseconds\n                    return datetime.fromtimestamp(ts_data / 1000)\n                return datetime.fromtimestamp(ts_data)\n        except (ValueError, OSError, OverflowError):\n            pass\n        return None\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator.generate","title":"<code>generate(source_ids)</code>  <code>async</code>","text":"<p>Generate a mind map JSON structure from sources.</p> <p>This is step 1 of the 2-step creation process. After generation, use save() to persist the mind map to a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>source_ids</code> <code>list[str]</code> <p>List of source UUIDs to include in the mind map.</p> required <p>Returns:</p> Type Description <code>MindMapGenerateResult</code> <p>MindMapGenerateResult with the JSON structure and generation ID.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If source_ids is empty.</p> <code>SourceError</code> <p>If generation fails.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>async def generate(self, source_ids: list[str]) -&gt; MindMapGenerateResult:\n    \"\"\"\n    Generate a mind map JSON structure from sources.\n\n    This is step 1 of the 2-step creation process. After generation,\n    use save() to persist the mind map to a notebook.\n\n    Args:\n        source_ids: List of source UUIDs to include in the mind map.\n\n    Returns:\n        MindMapGenerateResult with the JSON structure and generation ID.\n\n    Raises:\n        ValueError: If source_ids is empty.\n        SourceError: If generation fails.\n    \"\"\"\n    if not source_ids:\n        raise ValueError(\"source_ids cannot be empty\")\n\n    # Build source IDs in the nested format: [[[id1]], [[id2]], ...]\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    params = [\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        [\"interactive_mindmap\", [[\"[CONTEXT]\", \"\"]], \"\"],\n        None,\n        [2, None, [1]],\n    ]\n\n    logger.debug(\"Generating mind map from %d sources\", len(source_ids))\n\n    try:\n        result = await self.session.call_rpc(RPC_GENERATE_MIND_MAP, params)\n    except APIError as e:\n        logger.error(\"Failed to generate mind map: %s\", e)\n        raise SourceError(f\"Failed to generate mind map: {e}\") from e\n\n    # Parse response: [[json_string, null, [gen_ids]]]\n    if not result or not isinstance(result, list) or len(result) == 0:\n        raise SourceError(\"Mind map generation returned empty result\")\n\n    # Unwrap response - may be doubly nested\n    inner = result[0] if isinstance(result[0], list) else result\n\n    mind_map_json = (\n        inner[0] if len(inner) &gt; 0 and isinstance(inner[0], str) else None\n    )\n    if not mind_map_json:\n        raise SourceError(\"Mind map generation did not return JSON structure\")\n\n    generation_id = None\n    if len(inner) &gt; 2 and isinstance(inner[2], list) and len(inner[2]) &gt; 0:\n        generation_id = str(inner[2][0])\n\n    logger.info(\"Generated mind map (generation_id=%s)\", generation_id)\n\n    return MindMapGenerateResult(\n        mind_map_json=mind_map_json,\n        generation_id=generation_id,\n        source_ids=source_ids,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator.save","title":"<code>save(notebook_id, mind_map_json, source_ids, title='Mind Map')</code>  <code>async</code>","text":"<p>Save a generated mind map to a notebook.</p> <p>This is step 2 of the 2-step creation process. First use generate() to create the JSON structure.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID to save to.</p> required <code>mind_map_json</code> <code>str</code> <p>The JSON string from generate().</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source UUIDs used to generate the map.</p> required <code>title</code> <code>str</code> <p>Display title for the mind map.</p> <code>'Mind Map'</code> <p>Returns:</p> Type Description <code>MindMap</code> <p>MindMap with the saved mind map details.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If notebook_id or mind_map_json is empty.</p> <code>NotebookNotFoundError</code> <p>If the notebook doesn't exist.</p> <code>APIError</code> <p>If saving fails.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>async def save(\n    self,\n    notebook_id: str,\n    mind_map_json: str,\n    source_ids: list[str],\n    title: str = \"Mind Map\",\n) -&gt; MindMap:\n    \"\"\"\n    Save a generated mind map to a notebook.\n\n    This is step 2 of the 2-step creation process. First use\n    generate() to create the JSON structure.\n\n    Args:\n        notebook_id: The notebook UUID to save to.\n        mind_map_json: The JSON string from generate().\n        source_ids: List of source UUIDs used to generate the map.\n        title: Display title for the mind map.\n\n    Returns:\n        MindMap with the saved mind map details.\n\n    Raises:\n        ValueError: If notebook_id or mind_map_json is empty.\n        NotebookNotFoundError: If the notebook doesn't exist.\n        APIError: If saving fails.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"notebook_id cannot be empty\")\n    if not mind_map_json:\n        raise ValueError(\"mind_map_json cannot be empty\")\n\n    # Build source IDs in simpler format: [[id1], [id2], ...]\n    sources_simple = [[sid] for sid in source_ids]\n\n    # Metadata structure: [2, None, None, 5, sources]\n    metadata = [2, None, None, 5, sources_simple]\n\n    params = [\n        notebook_id,\n        mind_map_json,\n        metadata,\n        None,\n        title,\n    ]\n\n    logger.debug(\"Saving mind map '%s' to notebook %s\", title, notebook_id)\n\n    try:\n        result = await self.session.call_rpc(RPC_SAVE_MIND_MAP, params)\n    except APIError as e:\n        if e.status_code == 404:\n            raise NotebookNotFoundError(f\"Notebook not found: {notebook_id}\") from e\n        logger.error(\"Failed to save mind map: %s\", e)\n        raise\n\n    # Parse response: [[mind_map_id, json, metadata, None, title]]\n    if not result or not isinstance(result, list) or len(result) == 0:\n        raise APIError(\"Mind map save returned empty result\")\n\n    inner = result[0] if isinstance(result[0], list) else result\n\n    mind_map_id = inner[0] if len(inner) &gt; 0 else None\n    saved_json = inner[1] if len(inner) &gt; 1 else mind_map_json\n    saved_title = inner[4] if len(inner) &gt; 4 else title\n\n    if not mind_map_id:\n        raise APIError(\"Mind map save did not return an ID\")\n\n    logger.info(\"Saved mind map '%s' (id=%s)\", saved_title, mind_map_id)\n\n    return MindMap(\n        id=mind_map_id,\n        notebook_id=notebook_id,\n        title=saved_title,\n        mind_map_json=saved_json,\n        source_ids=source_ids,\n        created_at=datetime.now(),\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator.create","title":"<code>create(notebook_id, source_ids=None, title='Mind Map')</code>  <code>async</code>","text":"<p>Create a mind map from sources and save it to a notebook.</p> <p>This is a convenience method that combines generate() and save(). If source_ids is not provided, it will use all sources from the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID.</p> required <code>source_ids</code> <code>list[str] | None</code> <p>Optional list of source UUIDs. If None, uses all sources.</p> <code>None</code> <code>title</code> <code>str</code> <p>Display title for the mind map.</p> <code>'Mind Map'</code> <p>Returns:</p> Type Description <code>MindMap</code> <p>MindMap with the created mind map details.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If notebook_id is empty or no sources available.</p> <code>NotebookNotFoundError</code> <p>If the notebook doesn't exist.</p> <code>SourceError</code> <p>If generation fails.</p> <code>APIError</code> <p>If saving fails.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>async def create(\n    self,\n    notebook_id: str,\n    source_ids: list[str] | None = None,\n    title: str = \"Mind Map\",\n) -&gt; MindMap:\n    \"\"\"\n    Create a mind map from sources and save it to a notebook.\n\n    This is a convenience method that combines generate() and save().\n    If source_ids is not provided, it will use all sources from the notebook.\n\n    Args:\n        notebook_id: The notebook UUID.\n        source_ids: Optional list of source UUIDs. If None, uses all sources.\n        title: Display title for the mind map.\n\n    Returns:\n        MindMap with the created mind map details.\n\n    Raises:\n        ValueError: If notebook_id is empty or no sources available.\n        NotebookNotFoundError: If the notebook doesn't exist.\n        SourceError: If generation fails.\n        APIError: If saving fails.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"notebook_id cannot be empty\")\n\n    # If no source_ids provided, get all sources from the notebook\n    if source_ids is None:\n        from .notebooks import NotebookManager\n\n        notebook_manager = NotebookManager(self.session)\n        notebook = await notebook_manager.get(notebook_id)\n        source_ids = [s.id for s in notebook.sources]\n\n    if not source_ids:\n        raise ValueError(\n            \"Cannot create mind map: notebook has no sources. \"\n            \"Add sources first, then create a mind map.\"\n        )\n\n    logger.info(\n        \"Creating mind map '%s' from %d sources in notebook %s\",\n        title,\n        len(source_ids),\n        notebook_id,\n    )\n\n    # Step 1: Generate\n    gen_result = await self.generate(source_ids)\n\n    # Step 2: Save\n    return await self.save(\n        notebook_id=notebook_id,\n        mind_map_json=gen_result.mind_map_json,\n        source_ids=source_ids,\n        title=title,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator.list","title":"<code>list(notebook_id)</code>  <code>async</code>","text":"<p>List all mind maps in a notebook.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID.</p> required <p>Returns:</p> Type Description <code>list[MindMap]</code> <p>List of MindMap objects.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If notebook_id is empty.</p> <code>NotebookNotFoundError</code> <p>If the notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>async def list(self, notebook_id: str) -&gt; list[MindMap]:\n    \"\"\"\n    List all mind maps in a notebook.\n\n    Args:\n        notebook_id: The notebook UUID.\n\n    Returns:\n        List of MindMap objects.\n\n    Raises:\n        ValueError: If notebook_id is empty.\n        NotebookNotFoundError: If the notebook doesn't exist.\n        APIError: If the API call fails.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"notebook_id cannot be empty\")\n\n    params = [notebook_id]\n\n    logger.debug(\"Listing mind maps for notebook %s\", notebook_id)\n\n    try:\n        result = await self.session.call_rpc(RPC_LIST_MIND_MAPS, params)\n    except APIError as e:\n        if e.status_code == 404:\n            raise NotebookNotFoundError(f\"Notebook not found: {notebook_id}\") from e\n        raise\n\n    mind_maps: list[MindMap] = []\n\n    if not result or not isinstance(result, list) or len(result) == 0:\n        return mind_maps\n\n    # Response: [[[mind_map_id, [id, json, metadata, None, title]], ...], [timestamp]]\n    mind_map_list = result[0] if isinstance(result[0], list) else []\n\n    for item in mind_map_list:\n        if not isinstance(item, list) or len(item) &lt; 2:\n            continue\n\n        mind_map_id = item[0]\n        details = item[1] if len(item) &gt; 1 else []\n\n        if not isinstance(details, list) or len(details) &lt; 5:\n            continue\n\n        # Details: [id, json, metadata, None, title]\n        mind_map_json = details[1] if len(details) &gt; 1 else None\n        title = details[4] if len(details) &gt; 4 else \"Mind Map\"\n        metadata = details[2] if len(details) &gt; 2 else []\n\n        # Extract timestamp from metadata [2, version_id, [timestamp, nanos], ...]\n        created_at = None\n        if isinstance(metadata, list) and len(metadata) &gt; 2:\n            ts = metadata[2]\n            created_at = self._parse_timestamp(ts)\n\n        # Extract source IDs from metadata\n        source_ids = []\n        if isinstance(metadata, list) and len(metadata) &gt; 4:\n            sources = metadata[4]\n            if isinstance(sources, list):\n                for s in sources:\n                    if isinstance(s, list) and len(s) &gt; 0:\n                        source_ids.append(s[0])\n\n        mind_maps.append(\n            MindMap(\n                id=mind_map_id,\n                notebook_id=notebook_id,\n                title=title,\n                mind_map_json=mind_map_json,\n                created_at=created_at,\n                source_ids=source_ids,\n            )\n        )\n\n    logger.debug(\"Found %d mind maps\", len(mind_maps))\n    return mind_maps\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapGenerator.get","title":"<code>get(notebook_id, mindmap_id)</code>  <code>async</code>","text":"<p>Get a specific mind map by ID.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>The notebook UUID.</p> required <code>mindmap_id</code> <code>str</code> <p>The mind map UUID.</p> required <p>Returns:</p> Type Description <code>MindMap | None</code> <p>MindMap if found, None otherwise.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If notebook_id or mindmap_id is empty.</p> <code>NotebookNotFoundError</code> <p>If the notebook doesn't exist.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>async def get(self, notebook_id: str, mindmap_id: str) -&gt; MindMap | None:\n    \"\"\"\n    Get a specific mind map by ID.\n\n    Args:\n        notebook_id: The notebook UUID.\n        mindmap_id: The mind map UUID.\n\n    Returns:\n        MindMap if found, None otherwise.\n\n    Raises:\n        ValueError: If notebook_id or mindmap_id is empty.\n        NotebookNotFoundError: If the notebook doesn't exist.\n        APIError: If the API call fails.\n    \"\"\"\n    if not notebook_id:\n        raise ValueError(\"notebook_id cannot be empty\")\n    if not mindmap_id:\n        raise ValueError(\"mindmap_id cannot be empty\")\n\n    mind_maps = await self.list(notebook_id)\n    for mm in mind_maps:\n        if mm.id == mindmap_id:\n            return mm\n    return None\n</code></pre>"},{"location":"api_reference/#export-functions","title":"Export Functions","text":""},{"location":"api_reference/#pynotebooklm.mindmaps.export_to_opml","title":"<code>pynotebooklm.mindmaps.export_to_opml(mind_map_json, title='Mind Map')</code>","text":"<p>Convert mind map JSON to OPML 2.0 format.</p> <p>OPML (Outline Processor Markup Language) is widely supported by outliner applications and can be imported into tools like OmniOutliner, Workflowy, Dynalist, etc.</p> <p>Parameters:</p> Name Type Description Default <code>mind_map_json</code> <code>str</code> <p>The mind map JSON string (hierarchical structure).</p> required <code>title</code> <code>str</code> <p>Title for the OPML document.</p> <code>'Mind Map'</code> <p>Returns:</p> Type Description <code>str</code> <p>OPML XML string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the JSON is invalid.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>def export_to_opml(mind_map_json: str, title: str = \"Mind Map\") -&gt; str:\n    \"\"\"\n    Convert mind map JSON to OPML 2.0 format.\n\n    OPML (Outline Processor Markup Language) is widely supported by\n    outliner applications and can be imported into tools like OmniOutliner,\n    Workflowy, Dynalist, etc.\n\n    Args:\n        mind_map_json: The mind map JSON string (hierarchical structure).\n        title: Title for the OPML document.\n\n    Returns:\n        OPML XML string.\n\n    Raises:\n        ValueError: If the JSON is invalid.\n    \"\"\"\n    try:\n        data = json.loads(mind_map_json)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid mind map JSON: {e}\") from e\n\n    # Create OPML structure\n    opml = ET.Element(\"opml\", version=\"2.0\")\n\n    # Head section\n    head = ET.SubElement(opml, \"head\")\n    title_elem = ET.SubElement(head, \"title\")\n    title_elem.text = title\n    date_elem = ET.SubElement(head, \"dateCreated\")\n    date_elem.text = datetime.now().strftime(\"%a, %d %b %Y %H:%M:%S %z\")\n\n    # Body section\n    body = ET.SubElement(opml, \"body\")\n\n    def add_outline(parent: ET.Element, node: dict[str, Any]) -&gt; None:\n        \"\"\"Recursively add outline elements.\"\"\"\n        outline = ET.SubElement(parent, \"outline\", text=node.get(\"name\", \"\"))\n        for child in node.get(\"children\", []):\n            add_outline(outline, child)\n\n    # Add root node and its children\n    add_outline(body, data)\n\n    # Generate XML string with proper declaration\n    ET.indent(opml, space=\"  \")\n    xml_str = ET.tostring(opml, encoding=\"unicode\", xml_declaration=True)\n    return xml_str\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.export_to_freemind","title":"<code>pynotebooklm.mindmaps.export_to_freemind(mind_map_json, title='Mind Map')</code>","text":"<p>Convert mind map JSON to FreeMind (.mm) format.</p> <p>FreeMind is a popular open-source mind mapping application. This format is also compatible with Freeplane and many other mind mapping tools.</p> <p>Parameters:</p> Name Type Description Default <code>mind_map_json</code> <code>str</code> <p>The mind map JSON string (hierarchical structure).</p> required <code>title</code> <code>str</code> <p>Title for the FreeMind map (used for root node if empty).</p> <code>'Mind Map'</code> <p>Returns:</p> Type Description <code>str</code> <p>FreeMind XML string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the JSON is invalid.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>def export_to_freemind(mind_map_json: str, title: str = \"Mind Map\") -&gt; str:\n    \"\"\"\n    Convert mind map JSON to FreeMind (.mm) format.\n\n    FreeMind is a popular open-source mind mapping application.\n    This format is also compatible with Freeplane and many other\n    mind mapping tools.\n\n    Args:\n        mind_map_json: The mind map JSON string (hierarchical structure).\n        title: Title for the FreeMind map (used for root node if empty).\n\n    Returns:\n        FreeMind XML string.\n\n    Raises:\n        ValueError: If the JSON is invalid.\n    \"\"\"\n    try:\n        data = json.loads(mind_map_json)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid mind map JSON: {e}\") from e\n\n    # Create FreeMind map structure\n    map_elem = ET.Element(\"map\", version=\"1.0.1\")\n\n    def add_node(\n        parent: ET.Element, node_data: dict[str, Any], position: str = \"\"\n    ) -&gt; None:\n        \"\"\"Recursively add node elements.\"\"\"\n        attribs = {\"TEXT\": node_data.get(\"name\", \"\")}\n        if position:\n            attribs[\"POSITION\"] = position\n\n        node = ET.SubElement(parent, \"node\", **attribs)\n\n        # Alternate position for first-level children (left/right)\n        children = node_data.get(\"children\", [])\n        for i, child in enumerate(children):\n            # FreeMind convention: alternate left/right for visual balance\n            child_position = \"right\" if i % 2 == 0 else \"left\"\n            add_node(node, child, child_position if parent.tag == \"map\" else \"\")\n\n    # Add root node\n    add_node(map_elem, data)\n\n    # Generate XML string\n    ET.indent(map_elem, space=\"  \")\n    xml_str = ET.tostring(map_elem, encoding=\"unicode\", xml_declaration=True)\n    return xml_str\n</code></pre>"},{"location":"api_reference/#content-generation-phase-6","title":"Content Generation (Phase 6)","text":""},{"location":"api_reference/#pynotebooklm.content.ContentGenerator","title":"<code>pynotebooklm.content.ContentGenerator</code>","text":"<p>Generator for multi-modal content from notebook sources.</p> <p>This class provides methods to create audio overviews (podcasts), video overviews, infographics, and slide decks from notebook sources.</p> Example <pre><code>async with BrowserSession(auth) as session:\n    generator = ContentGenerator(session)\n\n    # Create an audio overview\n    result = await generator.create_audio(\n        notebook_id=\"abc-123\",\n        source_ids=[\"src-1\", \"src-2\"],\n        format=AudioFormat.DEEP_DIVE,\n        length=AudioLength.DEFAULT,\n    )\n\n    # Poll for status\n    artifacts = await generator.poll_status(notebook_id)\n    for artifact in artifacts:\n        print(f\"{artifact.title}: {artifact.status}\")\n</code></pre> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>class ContentGenerator:\n    \"\"\"\n    Generator for multi-modal content from notebook sources.\n\n    This class provides methods to create audio overviews (podcasts),\n    video overviews, infographics, and slide decks from notebook sources.\n\n    Example:\n        ```python\n        async with BrowserSession(auth) as session:\n            generator = ContentGenerator(session)\n\n            # Create an audio overview\n            result = await generator.create_audio(\n                notebook_id=\"abc-123\",\n                source_ids=[\"src-1\", \"src-2\"],\n                format=AudioFormat.DEEP_DIVE,\n                length=AudioLength.DEFAULT,\n            )\n\n            # Poll for status\n            artifacts = await generator.poll_status(notebook_id)\n            for artifact in artifacts:\n                print(f\"{artifact.title}: {artifact.status}\")\n        ```\n    \"\"\"\n\n    def __init__(self, session: BrowserSession):\n        \"\"\"\n        Initialize the ContentGenerator.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n\n    async def create_audio(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        format: AudioFormat = AudioFormat.DEEP_DIVE,\n        length: AudioLength = AudioLength.DEFAULT,\n        language: str = \"en\",\n        focus_prompt: str = \"\",\n    ) -&gt; CreateContentResult:\n        \"\"\"\n        Create an audio overview (podcast) from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            format: Audio format (deep_dive, brief, critique, debate).\n            length: Audio length (short, default, long).\n            language: BCP-47 language code (e.g., \"en\", \"es\").\n            focus_prompt: Optional focus instructions for the AI.\n\n        Returns:\n            CreateContentResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If audio creation fails.\n            APIError: If the API call fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        format_code = _audio_format_to_code(format)\n        length_code = _audio_length_to_code(length)\n\n        # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n        sources_nested = [[[sid]] for sid in source_ids]\n        # Build source IDs in simple format: [[id1], [id2], ...]\n        sources_simple = [[sid] for sid in source_ids]\n\n        # Audio options structure\n        audio_options = [\n            None,\n            [\n                focus_prompt,\n                length_code,\n                None,\n                sources_simple,\n                language,\n                None,\n                format_code,\n            ],\n        ]\n\n        params = [\n            [2],\n            notebook_id,\n            [\n                None,\n                None,\n                STUDIO_TYPE_AUDIO,\n                sources_nested,\n                None,\n                None,\n                audio_options,\n            ],\n        ]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create audio overview: {e}\") from e\n\n        return self._parse_create_result(\n            result,\n            notebook_id,\n            \"audio\",\n            format=format.value,\n            length=length.value,\n            language=language,\n        )\n\n    async def create_video(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        format: VideoFormat = VideoFormat.EXPLAINER,\n        style: VideoStyle = VideoStyle.AUTO_SELECT,\n        language: str = \"en\",\n        focus_prompt: str = \"\",\n    ) -&gt; CreateContentResult:\n        \"\"\"\n        Create a video overview from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            format: Video format (explainer, brief).\n            style: Visual style (auto_select, classic, whiteboard, etc.).\n            language: BCP-47 language code.\n            focus_prompt: Optional focus instructions for the AI.\n\n        Returns:\n            CreateContentResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If video creation fails.\n            APIError: If the API call fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        format_code = _video_format_to_code(format)\n        style_code = _video_style_to_code(style)\n\n        # Build source IDs\n        sources_nested = [[[sid]] for sid in source_ids]\n        sources_simple = [[sid] for sid in source_ids]\n\n        # Video options structure\n        video_options = [\n            None,\n            None,\n            [\n                sources_simple,\n                language,\n                focus_prompt,\n                None,\n                format_code,\n                style_code,\n            ],\n        ]\n\n        params = [\n            [2],\n            notebook_id,\n            [\n                None,\n                None,\n                STUDIO_TYPE_VIDEO,\n                sources_nested,\n                None,\n                None,\n                None,\n                None,\n                video_options,\n            ],\n        ]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create video overview: {e}\") from e\n\n        return self._parse_create_result(\n            result,\n            notebook_id,\n            \"video\",\n            format=format.value,\n            style=style.value,\n            language=language,\n        )\n\n    async def create_infographic(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        orientation: InfographicOrientation = InfographicOrientation.LANDSCAPE,\n        detail_level: InfographicDetailLevel = InfographicDetailLevel.STANDARD,\n        language: str = \"en\",\n        focus_prompt: str = \"\",\n    ) -&gt; CreateContentResult:\n        \"\"\"\n        Create an infographic from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            orientation: Infographic orientation (landscape, portrait, square).\n            detail_level: Detail level (concise, standard, detailed).\n            language: BCP-47 language code.\n            focus_prompt: Optional focus instructions for the AI.\n\n        Returns:\n            CreateContentResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If infographic creation fails.\n            APIError: If the API call fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        orientation_code = _infographic_orientation_to_code(orientation)\n        detail_code = _infographic_detail_to_code(detail_level)\n\n        # Build source IDs\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        # Infographic options at position 14\n        infographic_options = [\n            [focus_prompt or None, language, None, orientation_code, detail_code]\n        ]\n\n        # Build content array with 10 nulls before options\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_INFOGRAPHIC,\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,  # positions 4-13\n            infographic_options,  # position 14\n        ]\n\n        params = [[2], notebook_id, content]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create infographic: {e}\") from e\n\n        return self._parse_create_result(\n            result,\n            notebook_id,\n            \"infographic\",\n            orientation=orientation.value,\n            detail_level=detail_level.value,\n            language=language,\n        )\n\n    async def create_slides(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        format: SlideDeckFormat = SlideDeckFormat.DETAILED_DECK,\n        length: SlideDeckLength = SlideDeckLength.DEFAULT,\n        language: str = \"en\",\n        focus_prompt: str = \"\",\n    ) -&gt; CreateContentResult:\n        \"\"\"\n        Create a slide deck from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            format: Slide deck format (detailed_deck, presenter_slides).\n            length: Slide deck length (short, default).\n            language: BCP-47 language code.\n            focus_prompt: Optional focus instructions for the AI.\n\n        Returns:\n            CreateContentResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If slide deck creation fails.\n            APIError: If the API call fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        format_code = _slide_format_to_code(format)\n        length_code = _slide_length_to_code(length)\n\n        # Build source IDs\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        # Slide deck options at position 16\n        slide_deck_options = [\n            [focus_prompt or None, language, format_code, length_code]\n        ]\n\n        # Build content array with 12 nulls before options\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_SLIDE_DECK,\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,  # positions 4-15\n            slide_deck_options,  # position 16\n        ]\n\n        params = [[2], notebook_id, content]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create slide deck: {e}\") from e\n\n        return self._parse_create_result(\n            result,\n            notebook_id,\n            \"slide_deck\",\n            format=format.value,\n            length=length.value,\n            language=language,\n        )\n\n    async def poll_status(self, notebook_id: str) -&gt; list[StudioArtifact]:\n        \"\"\"\n        Poll for studio content status.\n\n        Returns all artifacts in the notebook with their current status\n        and download URLs if completed.\n\n        Args:\n            notebook_id: Notebook UUID.\n\n        Returns:\n            List of StudioArtifact objects with current status.\n\n        Raises:\n            APIError: If the API call fails.\n        \"\"\"\n        params = [[2], notebook_id, 'NOT artifact.status = \"ARTIFACT_STATUS_SUGGESTED\"']\n\n        try:\n            result = await self._session.call_rpc(RPC_POLL_STUDIO, params)\n        except Exception as e:\n            raise APIError(f\"Failed to poll studio status: {e}\") from e\n\n        return self._parse_poll_result(result, notebook_id)\n\n    async def delete(self, artifact_id: str) -&gt; bool:\n        \"\"\"\n        Delete a studio artifact.\n\n        WARNING: This action is IRREVERSIBLE.\n\n        Args:\n            artifact_id: Artifact UUID to delete.\n\n        Returns:\n            True if deletion was successful.\n\n        Raises:\n            APIError: If the deletion fails.\n        \"\"\"\n        params = [[2], artifact_id]\n\n        try:\n            result = await self._session.call_rpc(RPC_DELETE_STUDIO, params)\n            return result is not None\n        except Exception as e:\n            raise APIError(f\"Failed to delete artifact: {e}\") from e\n\n    def _parse_create_result(\n        self,\n        result: Any,\n        notebook_id: str,\n        content_type: str,\n        **kwargs: Any,\n    ) -&gt; CreateContentResult:\n        \"\"\"Parse the result from a create content RPC call.\"\"\"\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise GenerationError(f\"Invalid response when creating {content_type}\")\n\n        artifact_data = result[0]\n        if not isinstance(artifact_data, list) or len(artifact_data) == 0:\n            raise GenerationError(f\"Invalid artifact data when creating {content_type}\")\n\n        artifact_id = artifact_data[0]\n        status_code = artifact_data[4] if len(artifact_data) &gt; 4 else None\n\n        if status_code == STATUS_IN_PROGRESS:\n            status = \"in_progress\"\n        elif status_code == STATUS_COMPLETED:\n            status = \"completed\"\n        else:\n            status = \"unknown\"\n\n        return CreateContentResult(\n            artifact_id=artifact_id,\n            notebook_id=notebook_id,\n            content_type=content_type,\n            status=status,\n            **kwargs,\n        )\n\n    def _parse_poll_result(self, result: Any, notebook_id: str) -&gt; list[StudioArtifact]:\n        \"\"\"Parse the result from a poll status RPC call.\"\"\"\n        artifacts: list[StudioArtifact] = []\n\n        if not result or not isinstance(result, list) or len(result) == 0:\n            return artifacts\n\n        # Response is an array of artifacts, possibly wrapped\n        artifact_list = result[0] if isinstance(result[0], list) else result\n\n        for artifact_data in artifact_list:\n            if not isinstance(artifact_data, list) or len(artifact_data) &lt; 5:\n                continue\n\n            artifact_id = artifact_data[0]\n            title = artifact_data[1] if len(artifact_data) &gt; 1 else \"\"\n            type_code: int = artifact_data[2] if len(artifact_data) &gt; 2 else 0\n            status_code: int = artifact_data[4] if len(artifact_data) &gt; 4 else 0\n\n            artifact_type = _type_code_to_artifact_type(type_code)\n            status = _status_code_to_status(status_code)\n\n            # Extract type-specific URLs\n            audio_url = None\n            video_url = None\n            infographic_url = None\n            slide_deck_url = None\n            duration_seconds = None\n            report_content = None\n            flashcard_count = None\n            created_at = None\n\n            # Audio artifacts have URLs at position 6\n            if type_code == STUDIO_TYPE_AUDIO and len(artifact_data) &gt; 6:\n                audio_options = artifact_data[6]\n                if isinstance(audio_options, list) and len(audio_options) &gt; 3:\n                    audio_url = (\n                        audio_options[3] if isinstance(audio_options[3], str) else None\n                    )\n                    if len(audio_options) &gt; 9 and isinstance(audio_options[9], list):\n                        duration_seconds = (\n                            audio_options[9][0] if audio_options[9] else None\n                        )\n\n            # Video artifacts have URLs at position 8\n            if type_code == STUDIO_TYPE_VIDEO and len(artifact_data) &gt; 8:\n                video_options = artifact_data[8]\n                if isinstance(video_options, list) and len(video_options) &gt; 3:\n                    video_url = (\n                        video_options[3] if isinstance(video_options[3], str) else None\n                    )\n\n            # Infographic artifacts have image URL at position 14\n            if type_code == STUDIO_TYPE_INFOGRAPHIC and len(artifact_data) &gt; 14:\n                infographic_options = artifact_data[14]\n                if (\n                    isinstance(infographic_options, list)\n                    and len(infographic_options) &gt; 2\n                ):\n                    image_data = infographic_options[2]\n                    if isinstance(image_data, list) and len(image_data) &gt; 0:\n                        first_image = image_data[0]\n                        if isinstance(first_image, list) and len(first_image) &gt; 1:\n                            image_details = first_image[1]\n                            if (\n                                isinstance(image_details, list)\n                                and len(image_details) &gt; 0\n                            ):\n                                url = image_details[0]\n                                if isinstance(url, str) and url.startswith(\"http\"):\n                                    infographic_url = url\n\n            # Slide deck artifacts have download URL at position 16\n            if type_code == STUDIO_TYPE_SLIDE_DECK and len(artifact_data) &gt; 16:\n                slide_deck_options = artifact_data[16]\n                if isinstance(slide_deck_options, list) and len(slide_deck_options) &gt; 0:\n                    if isinstance(slide_deck_options[0], str) and slide_deck_options[\n                        0\n                    ].startswith(\"http\"):\n                        slide_deck_url = slide_deck_options[0]\n                    elif len(slide_deck_options) &gt; 3 and isinstance(\n                        slide_deck_options[3], str\n                    ):\n                        slide_deck_url = slide_deck_options[3]\n\n            # Extract created_at timestamp from common positions\n            for ts_pos in [10, 15, 17]:\n                if len(artifact_data) &gt; ts_pos:\n                    ts_candidate = artifact_data[ts_pos]\n                    if isinstance(ts_candidate, list) and len(ts_candidate) &gt;= 2:\n                        if (\n                            isinstance(ts_candidate[0], int | float)\n                            and ts_candidate[0] &gt; 1700000000\n                        ):\n                            from datetime import datetime, timezone\n\n                            dt = datetime.fromtimestamp(\n                                ts_candidate[0], tz=timezone.utc\n                            )\n                            created_at = dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n                            break\n\n            artifacts.append(\n                StudioArtifact(\n                    artifact_id=artifact_id,\n                    notebook_id=notebook_id,\n                    title=title,\n                    artifact_type=artifact_type,\n                    status=status,\n                    created_at=created_at,\n                    audio_url=audio_url,\n                    video_url=video_url,\n                    infographic_url=infographic_url,\n                    slide_deck_url=slide_deck_url,\n                    duration_seconds=duration_seconds,\n                    report_content=report_content,\n                    flashcard_count=flashcard_count,\n                )\n            )\n\n        return artifacts\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.create_audio","title":"<code>create_audio(notebook_id, source_ids, format=AudioFormat.DEEP_DIVE, length=AudioLength.DEFAULT, language='en', focus_prompt='')</code>  <code>async</code>","text":"<p>Create an audio overview (podcast) from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>format</code> <code>AudioFormat</code> <p>Audio format (deep_dive, brief, critique, debate).</p> <code>DEEP_DIVE</code> <code>length</code> <code>AudioLength</code> <p>Audio length (short, default, long).</p> <code>DEFAULT</code> <code>language</code> <code>str</code> <p>BCP-47 language code (e.g., \"en\", \"es\").</p> <code>'en'</code> <code>focus_prompt</code> <code>str</code> <p>Optional focus instructions for the AI.</p> <code>''</code> <p>Returns:</p> Type Description <code>CreateContentResult</code> <p>CreateContentResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If audio creation fails.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def create_audio(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    format: AudioFormat = AudioFormat.DEEP_DIVE,\n    length: AudioLength = AudioLength.DEFAULT,\n    language: str = \"en\",\n    focus_prompt: str = \"\",\n) -&gt; CreateContentResult:\n    \"\"\"\n    Create an audio overview (podcast) from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        format: Audio format (deep_dive, brief, critique, debate).\n        length: Audio length (short, default, long).\n        language: BCP-47 language code (e.g., \"en\", \"es\").\n        focus_prompt: Optional focus instructions for the AI.\n\n    Returns:\n        CreateContentResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If audio creation fails.\n        APIError: If the API call fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    format_code = _audio_format_to_code(format)\n    length_code = _audio_length_to_code(length)\n\n    # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n    sources_nested = [[[sid]] for sid in source_ids]\n    # Build source IDs in simple format: [[id1], [id2], ...]\n    sources_simple = [[sid] for sid in source_ids]\n\n    # Audio options structure\n    audio_options = [\n        None,\n        [\n            focus_prompt,\n            length_code,\n            None,\n            sources_simple,\n            language,\n            None,\n            format_code,\n        ],\n    ]\n\n    params = [\n        [2],\n        notebook_id,\n        [\n            None,\n            None,\n            STUDIO_TYPE_AUDIO,\n            sources_nested,\n            None,\n            None,\n            audio_options,\n        ],\n    ]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create audio overview: {e}\") from e\n\n    return self._parse_create_result(\n        result,\n        notebook_id,\n        \"audio\",\n        format=format.value,\n        length=length.value,\n        language=language,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.create_video","title":"<code>create_video(notebook_id, source_ids, format=VideoFormat.EXPLAINER, style=VideoStyle.AUTO_SELECT, language='en', focus_prompt='')</code>  <code>async</code>","text":"<p>Create a video overview from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>format</code> <code>VideoFormat</code> <p>Video format (explainer, brief).</p> <code>EXPLAINER</code> <code>style</code> <code>VideoStyle</code> <p>Visual style (auto_select, classic, whiteboard, etc.).</p> <code>AUTO_SELECT</code> <code>language</code> <code>str</code> <p>BCP-47 language code.</p> <code>'en'</code> <code>focus_prompt</code> <code>str</code> <p>Optional focus instructions for the AI.</p> <code>''</code> <p>Returns:</p> Type Description <code>CreateContentResult</code> <p>CreateContentResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If video creation fails.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def create_video(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    format: VideoFormat = VideoFormat.EXPLAINER,\n    style: VideoStyle = VideoStyle.AUTO_SELECT,\n    language: str = \"en\",\n    focus_prompt: str = \"\",\n) -&gt; CreateContentResult:\n    \"\"\"\n    Create a video overview from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        format: Video format (explainer, brief).\n        style: Visual style (auto_select, classic, whiteboard, etc.).\n        language: BCP-47 language code.\n        focus_prompt: Optional focus instructions for the AI.\n\n    Returns:\n        CreateContentResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If video creation fails.\n        APIError: If the API call fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    format_code = _video_format_to_code(format)\n    style_code = _video_style_to_code(style)\n\n    # Build source IDs\n    sources_nested = [[[sid]] for sid in source_ids]\n    sources_simple = [[sid] for sid in source_ids]\n\n    # Video options structure\n    video_options = [\n        None,\n        None,\n        [\n            sources_simple,\n            language,\n            focus_prompt,\n            None,\n            format_code,\n            style_code,\n        ],\n    ]\n\n    params = [\n        [2],\n        notebook_id,\n        [\n            None,\n            None,\n            STUDIO_TYPE_VIDEO,\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            video_options,\n        ],\n    ]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create video overview: {e}\") from e\n\n    return self._parse_create_result(\n        result,\n        notebook_id,\n        \"video\",\n        format=format.value,\n        style=style.value,\n        language=language,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.create_infographic","title":"<code>create_infographic(notebook_id, source_ids, orientation=InfographicOrientation.LANDSCAPE, detail_level=InfographicDetailLevel.STANDARD, language='en', focus_prompt='')</code>  <code>async</code>","text":"<p>Create an infographic from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>orientation</code> <code>InfographicOrientation</code> <p>Infographic orientation (landscape, portrait, square).</p> <code>LANDSCAPE</code> <code>detail_level</code> <code>InfographicDetailLevel</code> <p>Detail level (concise, standard, detailed).</p> <code>STANDARD</code> <code>language</code> <code>str</code> <p>BCP-47 language code.</p> <code>'en'</code> <code>focus_prompt</code> <code>str</code> <p>Optional focus instructions for the AI.</p> <code>''</code> <p>Returns:</p> Type Description <code>CreateContentResult</code> <p>CreateContentResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If infographic creation fails.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def create_infographic(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    orientation: InfographicOrientation = InfographicOrientation.LANDSCAPE,\n    detail_level: InfographicDetailLevel = InfographicDetailLevel.STANDARD,\n    language: str = \"en\",\n    focus_prompt: str = \"\",\n) -&gt; CreateContentResult:\n    \"\"\"\n    Create an infographic from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        orientation: Infographic orientation (landscape, portrait, square).\n        detail_level: Detail level (concise, standard, detailed).\n        language: BCP-47 language code.\n        focus_prompt: Optional focus instructions for the AI.\n\n    Returns:\n        CreateContentResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If infographic creation fails.\n        APIError: If the API call fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    orientation_code = _infographic_orientation_to_code(orientation)\n    detail_code = _infographic_detail_to_code(detail_level)\n\n    # Build source IDs\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    # Infographic options at position 14\n    infographic_options = [\n        [focus_prompt or None, language, None, orientation_code, detail_code]\n    ]\n\n    # Build content array with 10 nulls before options\n    content = [\n        None,\n        None,\n        STUDIO_TYPE_INFOGRAPHIC,\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,  # positions 4-13\n        infographic_options,  # position 14\n    ]\n\n    params = [[2], notebook_id, content]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create infographic: {e}\") from e\n\n    return self._parse_create_result(\n        result,\n        notebook_id,\n        \"infographic\",\n        orientation=orientation.value,\n        detail_level=detail_level.value,\n        language=language,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.create_slides","title":"<code>create_slides(notebook_id, source_ids, format=SlideDeckFormat.DETAILED_DECK, length=SlideDeckLength.DEFAULT, language='en', focus_prompt='')</code>  <code>async</code>","text":"<p>Create a slide deck from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>format</code> <code>SlideDeckFormat</code> <p>Slide deck format (detailed_deck, presenter_slides).</p> <code>DETAILED_DECK</code> <code>length</code> <code>SlideDeckLength</code> <p>Slide deck length (short, default).</p> <code>DEFAULT</code> <code>language</code> <code>str</code> <p>BCP-47 language code.</p> <code>'en'</code> <code>focus_prompt</code> <code>str</code> <p>Optional focus instructions for the AI.</p> <code>''</code> <p>Returns:</p> Type Description <code>CreateContentResult</code> <p>CreateContentResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If slide deck creation fails.</p> <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def create_slides(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    format: SlideDeckFormat = SlideDeckFormat.DETAILED_DECK,\n    length: SlideDeckLength = SlideDeckLength.DEFAULT,\n    language: str = \"en\",\n    focus_prompt: str = \"\",\n) -&gt; CreateContentResult:\n    \"\"\"\n    Create a slide deck from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        format: Slide deck format (detailed_deck, presenter_slides).\n        length: Slide deck length (short, default).\n        language: BCP-47 language code.\n        focus_prompt: Optional focus instructions for the AI.\n\n    Returns:\n        CreateContentResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If slide deck creation fails.\n        APIError: If the API call fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    format_code = _slide_format_to_code(format)\n    length_code = _slide_length_to_code(length)\n\n    # Build source IDs\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    # Slide deck options at position 16\n    slide_deck_options = [\n        [focus_prompt or None, language, format_code, length_code]\n    ]\n\n    # Build content array with 12 nulls before options\n    content = [\n        None,\n        None,\n        STUDIO_TYPE_SLIDE_DECK,\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,  # positions 4-15\n        slide_deck_options,  # position 16\n    ]\n\n    params = [[2], notebook_id, content]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create slide deck: {e}\") from e\n\n    return self._parse_create_result(\n        result,\n        notebook_id,\n        \"slide_deck\",\n        format=format.value,\n        length=length.value,\n        language=language,\n    )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.poll_status","title":"<code>poll_status(notebook_id)</code>  <code>async</code>","text":"<p>Poll for studio content status.</p> <p>Returns all artifacts in the notebook with their current status and download URLs if completed.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <p>Returns:</p> Type Description <code>list[StudioArtifact]</code> <p>List of StudioArtifact objects with current status.</p> <p>Raises:</p> Type Description <code>APIError</code> <p>If the API call fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def poll_status(self, notebook_id: str) -&gt; list[StudioArtifact]:\n    \"\"\"\n    Poll for studio content status.\n\n    Returns all artifacts in the notebook with their current status\n    and download URLs if completed.\n\n    Args:\n        notebook_id: Notebook UUID.\n\n    Returns:\n        List of StudioArtifact objects with current status.\n\n    Raises:\n        APIError: If the API call fails.\n    \"\"\"\n    params = [[2], notebook_id, 'NOT artifact.status = \"ARTIFACT_STATUS_SUGGESTED\"']\n\n    try:\n        result = await self._session.call_rpc(RPC_POLL_STUDIO, params)\n    except Exception as e:\n        raise APIError(f\"Failed to poll studio status: {e}\") from e\n\n    return self._parse_poll_result(result, notebook_id)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.ContentGenerator.delete","title":"<code>delete(artifact_id)</code>  <code>async</code>","text":"<p>Delete a studio artifact.</p> <p>WARNING: This action is IRREVERSIBLE.</p> <p>Parameters:</p> Name Type Description Default <code>artifact_id</code> <code>str</code> <p>Artifact UUID to delete.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if deletion was successful.</p> <p>Raises:</p> Type Description <code>APIError</code> <p>If the deletion fails.</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>async def delete(self, artifact_id: str) -&gt; bool:\n    \"\"\"\n    Delete a studio artifact.\n\n    WARNING: This action is IRREVERSIBLE.\n\n    Args:\n        artifact_id: Artifact UUID to delete.\n\n    Returns:\n        True if deletion was successful.\n\n    Raises:\n        APIError: If the deletion fails.\n    \"\"\"\n    params = [[2], artifact_id]\n\n    try:\n        result = await self._session.call_rpc(RPC_DELETE_STUDIO, params)\n        return result is not None\n    except Exception as e:\n        raise APIError(f\"Failed to delete artifact: {e}\") from e\n</code></pre>"},{"location":"api_reference/#content-types-and-options","title":"Content Types and Options","text":"<p>Available formats and options for content generation:</p> <p>Audio Formats: - <code>deep_dive</code> - Conversational podcast (default) - <code>brief</code> - Short summary - <code>critique</code> - Critical analysis - <code>debate</code> - Multiple perspectives</p> <p>Video Styles: - <code>auto_select</code> - Let AI choose - <code>classic</code> - Clean professional style - <code>whiteboard</code> - Hand-drawn style - <code>kawaii</code> - Cute Japanese style - <code>anime</code> - Anime-inspired - <code>watercolor</code> - Watercolor painting - <code>retro_print</code> - Vintage poster style - <code>heritage</code> - Classical art style - <code>paper_craft</code> - Paper cutout style</p> <p>Infographic Orientations: - <code>landscape</code> - 16:9 aspect ratio - <code>portrait</code> - 9:16 aspect ratio - <code>square</code> - 1:1 aspect ratio</p> <p>Slide Deck Formats: - <code>detailed_deck</code> - Comprehensive slides - <code>presenter_slides</code> - Speaker notes style</p>"},{"location":"api_reference/#study-tools-phase-7","title":"Study Tools (Phase 7)","text":""},{"location":"api_reference/#pynotebooklm.study.StudyManager","title":"<code>pynotebooklm.study.StudyManager</code>","text":"<p>Manager for study tools from notebook sources.</p> <p>This class provides methods to create flashcards, quizzes, and data tables from notebook sources.</p> Example <pre><code>async with BrowserSession(auth) as session:\n    study = StudyManager(session)\n\n    # Create flashcards\n    result = await study.create_flashcards(\n        notebook_id=\"abc-123\",\n        source_ids=[\"src-1\", \"src-2\"],\n        difficulty=FlashcardDifficulty.MEDIUM,\n    )\n\n    # Create a quiz\n    quiz = await study.create_quiz(\n        notebook_id=\"abc-123\",\n        source_ids=[\"src-1\", \"src-2\"],\n        question_count=5,\n    )\n\n    # Create a data table\n    table = await study.create_data_table(\n        notebook_id=\"abc-123\",\n        source_ids=[\"src-1\", \"src-2\"],\n        description=\"Extract key dates and events\",\n    )\n</code></pre> Source code in <code>src/pynotebooklm/study.py</code> <pre><code>class StudyManager:\n    \"\"\"\n    Manager for study tools from notebook sources.\n\n    This class provides methods to create flashcards, quizzes,\n    and data tables from notebook sources.\n\n    Example:\n        ```python\n        async with BrowserSession(auth) as session:\n            study = StudyManager(session)\n\n            # Create flashcards\n            result = await study.create_flashcards(\n                notebook_id=\"abc-123\",\n                source_ids=[\"src-1\", \"src-2\"],\n                difficulty=FlashcardDifficulty.MEDIUM,\n            )\n\n            # Create a quiz\n            quiz = await study.create_quiz(\n                notebook_id=\"abc-123\",\n                source_ids=[\"src-1\", \"src-2\"],\n                question_count=5,\n            )\n\n            # Create a data table\n            table = await study.create_data_table(\n                notebook_id=\"abc-123\",\n                source_ids=[\"src-1\", \"src-2\"],\n                description=\"Extract key dates and events\",\n            )\n        ```\n    \"\"\"\n\n    def __init__(self, session: BrowserSession):\n        \"\"\"\n        Initialize the StudyManager.\n\n        Args:\n            session: Active BrowserSession instance.\n        \"\"\"\n        self._session = session\n\n    async def create_flashcards(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        difficulty: FlashcardDifficulty = FlashcardDifficulty.MEDIUM,\n    ) -&gt; FlashcardCreateResult:\n        \"\"\"\n        Create flashcards from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            difficulty: Flashcard difficulty (easy, medium, hard).\n\n        Returns:\n            FlashcardCreateResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If flashcard creation fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        difficulty_code = _difficulty_to_code(difficulty)\n\n        # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        # Flashcard options at position 9\n        # Format: [null, [1, null*5, [difficulty, card_count]]]\n        flashcard_options = [\n            None,\n            [\n                1,  # Format code 1 = Flashcards (vs 2 = Quiz)\n                None,\n                None,\n                None,\n                None,\n                None,\n                [difficulty_code, FLASHCARD_COUNT_DEFAULT],\n            ],\n        ]\n\n        # Build content array: [null, null, type, sources, null*5, options]\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_FLASHCARDS,\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            None,  # positions 4-8\n            flashcard_options,  # position 9\n        ]\n\n        params = [[2], notebook_id, content]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create flashcards: {e}\") from e\n\n        return self._parse_flashcard_result(result, notebook_id, difficulty)\n\n    async def create_quiz(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        question_count: int = 2,\n        difficulty: int = 2,\n    ) -&gt; QuizCreateResult:\n        \"\"\"\n        Create a quiz from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            question_count: Number of quiz questions.\n            difficulty: Difficulty level (integer, default 2).\n\n        Returns:\n            QuizCreateResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If quiz creation fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        # Quiz options at position 9\n        # Format: [null, [2, null*6, [question_count, difficulty]]]\n        # Format code 2 distinguishes Quiz from Flashcards (which uses 1)\n        quiz_options = [\n            None,\n            [\n                2,  # Format code 2 = Quiz (vs 1 = Flashcards)\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                [question_count, difficulty],\n            ],\n        ]\n\n        # Build content array: [null, null, type, sources, null*5, options]\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_FLASHCARDS,  # Type 4 (shared with flashcards)\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            None,  # positions 4-8\n            quiz_options,  # position 9\n        ]\n\n        params = [[2], notebook_id, content]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create quiz: {e}\") from e\n\n        return self._parse_quiz_result(result, notebook_id, question_count, difficulty)\n\n    async def create_data_table(\n        self,\n        notebook_id: str,\n        source_ids: list[str],\n        description: str,\n        language: str = \"en\",\n    ) -&gt; DataTableCreateResult:\n        \"\"\"\n        Create a data table from notebook sources.\n\n        Args:\n            notebook_id: Notebook UUID.\n            source_ids: List of source IDs to include.\n            description: Description of the data to extract.\n            language: BCP-47 language code (e.g., \"en\", \"es\").\n\n        Returns:\n            DataTableCreateResult with artifact_id and initial status.\n\n        Raises:\n            GenerationError: If data table creation fails.\n        \"\"\"\n        if not source_ids:\n            raise GenerationError(\"At least one source ID is required\")\n\n        if not description:\n            raise GenerationError(\"Description is required for data table creation\")\n\n        # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n        sources_nested = [[[sid]] for sid in source_ids]\n\n        # Data table options at position 18\n        # Format: [null, [description, language]]\n        datatable_options = [None, [description, language]]\n\n        # Build content array: [null, null, type, sources, null*14, options]\n        content = [\n            None,\n            None,\n            STUDIO_TYPE_DATA_TABLE,\n            sources_nested,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,  # positions 4-17\n            datatable_options,  # position 18\n        ]\n\n        params = [[2], notebook_id, content]\n\n        try:\n            result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n        except Exception as e:\n            raise GenerationError(f\"Failed to create data table: {e}\") from e\n\n        return self._parse_data_table_result(result, notebook_id, description, language)\n\n    def _parse_flashcard_result(\n        self,\n        result: Any,\n        notebook_id: str,\n        difficulty: FlashcardDifficulty,\n    ) -&gt; FlashcardCreateResult:\n        \"\"\"Parse the result from a create flashcards RPC call.\"\"\"\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise GenerationError(\"Invalid response when creating flashcards\")\n\n        artifact_data = result[0]\n        if not isinstance(artifact_data, list) or len(artifact_data) == 0:\n            raise GenerationError(\"Invalid artifact data when creating flashcards\")\n\n        artifact_id = artifact_data[0]\n        status_code = artifact_data[4] if len(artifact_data) &gt; 4 else None\n\n        if status_code == STATUS_IN_PROGRESS:\n            status = \"in_progress\"\n        elif status_code == STATUS_COMPLETED:\n            status = \"completed\"\n        else:\n            status = \"unknown\"\n\n        return FlashcardCreateResult(\n            artifact_id=artifact_id,\n            notebook_id=notebook_id,\n            status=status,\n            difficulty=difficulty.value,\n        )\n\n    def _parse_quiz_result(\n        self,\n        result: Any,\n        notebook_id: str,\n        question_count: int,\n        difficulty: int,\n    ) -&gt; QuizCreateResult:\n        \"\"\"Parse the result from a create quiz RPC call.\"\"\"\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise GenerationError(\"Invalid response when creating quiz\")\n\n        artifact_data = result[0]\n        if not isinstance(artifact_data, list) or len(artifact_data) == 0:\n            raise GenerationError(\"Invalid artifact data when creating quiz\")\n\n        artifact_id = artifact_data[0]\n        status_code = artifact_data[4] if len(artifact_data) &gt; 4 else None\n\n        if status_code == STATUS_IN_PROGRESS:\n            status = \"in_progress\"\n        elif status_code == STATUS_COMPLETED:\n            status = \"completed\"\n        else:\n            status = \"unknown\"\n\n        return QuizCreateResult(\n            artifact_id=artifact_id,\n            notebook_id=notebook_id,\n            status=status,\n            question_count=question_count,\n            difficulty=difficulty,\n        )\n\n    def _parse_data_table_result(\n        self,\n        result: Any,\n        notebook_id: str,\n        description: str,\n        language: str,\n    ) -&gt; DataTableCreateResult:\n        \"\"\"Parse the result from a create data table RPC call.\"\"\"\n        if not result or not isinstance(result, list) or len(result) == 0:\n            raise GenerationError(\"Invalid response when creating data table\")\n\n        artifact_data = result[0]\n        if not isinstance(artifact_data, list) or len(artifact_data) == 0:\n            raise GenerationError(\"Invalid artifact data when creating data table\")\n\n        artifact_id = artifact_data[0]\n        status_code = artifact_data[4] if len(artifact_data) &gt; 4 else None\n\n        if status_code == STATUS_IN_PROGRESS:\n            status = \"in_progress\"\n        elif status_code == STATUS_COMPLETED:\n            status = \"completed\"\n        else:\n            status = \"unknown\"\n\n        return DataTableCreateResult(\n            artifact_id=artifact_id,\n            notebook_id=notebook_id,\n            status=status,\n            description=description,\n            language=language,\n        )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.study.StudyManager.create_flashcards","title":"<code>create_flashcards(notebook_id, source_ids, difficulty=FlashcardDifficulty.MEDIUM)</code>  <code>async</code>","text":"<p>Create flashcards from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>difficulty</code> <code>FlashcardDifficulty</code> <p>Flashcard difficulty (easy, medium, hard).</p> <code>MEDIUM</code> <p>Returns:</p> Type Description <code>FlashcardCreateResult</code> <p>FlashcardCreateResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If flashcard creation fails.</p> Source code in <code>src/pynotebooklm/study.py</code> <pre><code>async def create_flashcards(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    difficulty: FlashcardDifficulty = FlashcardDifficulty.MEDIUM,\n) -&gt; FlashcardCreateResult:\n    \"\"\"\n    Create flashcards from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        difficulty: Flashcard difficulty (easy, medium, hard).\n\n    Returns:\n        FlashcardCreateResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If flashcard creation fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    difficulty_code = _difficulty_to_code(difficulty)\n\n    # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    # Flashcard options at position 9\n    # Format: [null, [1, null*5, [difficulty, card_count]]]\n    flashcard_options = [\n        None,\n        [\n            1,  # Format code 1 = Flashcards (vs 2 = Quiz)\n            None,\n            None,\n            None,\n            None,\n            None,\n            [difficulty_code, FLASHCARD_COUNT_DEFAULT],\n        ],\n    ]\n\n    # Build content array: [null, null, type, sources, null*5, options]\n    content = [\n        None,\n        None,\n        STUDIO_TYPE_FLASHCARDS,\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        None,  # positions 4-8\n        flashcard_options,  # position 9\n    ]\n\n    params = [[2], notebook_id, content]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create flashcards: {e}\") from e\n\n    return self._parse_flashcard_result(result, notebook_id, difficulty)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.study.StudyManager.create_quiz","title":"<code>create_quiz(notebook_id, source_ids, question_count=2, difficulty=2)</code>  <code>async</code>","text":"<p>Create a quiz from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>question_count</code> <code>int</code> <p>Number of quiz questions.</p> <code>2</code> <code>difficulty</code> <code>int</code> <p>Difficulty level (integer, default 2).</p> <code>2</code> <p>Returns:</p> Type Description <code>QuizCreateResult</code> <p>QuizCreateResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If quiz creation fails.</p> Source code in <code>src/pynotebooklm/study.py</code> <pre><code>async def create_quiz(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    question_count: int = 2,\n    difficulty: int = 2,\n) -&gt; QuizCreateResult:\n    \"\"\"\n    Create a quiz from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        question_count: Number of quiz questions.\n        difficulty: Difficulty level (integer, default 2).\n\n    Returns:\n        QuizCreateResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If quiz creation fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    # Quiz options at position 9\n    # Format: [null, [2, null*6, [question_count, difficulty]]]\n    # Format code 2 distinguishes Quiz from Flashcards (which uses 1)\n    quiz_options = [\n        None,\n        [\n            2,  # Format code 2 = Quiz (vs 1 = Flashcards)\n            None,\n            None,\n            None,\n            None,\n            None,\n            None,\n            [question_count, difficulty],\n        ],\n    ]\n\n    # Build content array: [null, null, type, sources, null*5, options]\n    content = [\n        None,\n        None,\n        STUDIO_TYPE_FLASHCARDS,  # Type 4 (shared with flashcards)\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        None,  # positions 4-8\n        quiz_options,  # position 9\n    ]\n\n    params = [[2], notebook_id, content]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create quiz: {e}\") from e\n\n    return self._parse_quiz_result(result, notebook_id, question_count, difficulty)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.study.StudyManager.create_data_table","title":"<code>create_data_table(notebook_id, source_ids, description, language='en')</code>  <code>async</code>","text":"<p>Create a data table from notebook sources.</p> <p>Parameters:</p> Name Type Description Default <code>notebook_id</code> <code>str</code> <p>Notebook UUID.</p> required <code>source_ids</code> <code>list[str]</code> <p>List of source IDs to include.</p> required <code>description</code> <code>str</code> <p>Description of the data to extract.</p> required <code>language</code> <code>str</code> <p>BCP-47 language code (e.g., \"en\", \"es\").</p> <code>'en'</code> <p>Returns:</p> Type Description <code>DataTableCreateResult</code> <p>DataTableCreateResult with artifact_id and initial status.</p> <p>Raises:</p> Type Description <code>GenerationError</code> <p>If data table creation fails.</p> Source code in <code>src/pynotebooklm/study.py</code> <pre><code>async def create_data_table(\n    self,\n    notebook_id: str,\n    source_ids: list[str],\n    description: str,\n    language: str = \"en\",\n) -&gt; DataTableCreateResult:\n    \"\"\"\n    Create a data table from notebook sources.\n\n    Args:\n        notebook_id: Notebook UUID.\n        source_ids: List of source IDs to include.\n        description: Description of the data to extract.\n        language: BCP-47 language code (e.g., \"en\", \"es\").\n\n    Returns:\n        DataTableCreateResult with artifact_id and initial status.\n\n    Raises:\n        GenerationError: If data table creation fails.\n    \"\"\"\n    if not source_ids:\n        raise GenerationError(\"At least one source ID is required\")\n\n    if not description:\n        raise GenerationError(\"Description is required for data table creation\")\n\n    # Build source IDs in nested format: [[[id1]], [[id2]], ...]\n    sources_nested = [[[sid]] for sid in source_ids]\n\n    # Data table options at position 18\n    # Format: [null, [description, language]]\n    datatable_options = [None, [description, language]]\n\n    # Build content array: [null, null, type, sources, null*14, options]\n    content = [\n        None,\n        None,\n        STUDIO_TYPE_DATA_TABLE,\n        sources_nested,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,  # positions 4-17\n        datatable_options,  # position 18\n    ]\n\n    params = [[2], notebook_id, content]\n\n    try:\n        result = await self._session.call_rpc(RPC_CREATE_STUDIO, params)\n    except Exception as e:\n        raise GenerationError(f\"Failed to create data table: {e}\") from e\n\n    return self._parse_data_table_result(result, notebook_id, description, language)\n</code></pre>"},{"location":"api_reference/#study-tool-options","title":"Study Tool Options","text":"<p>Flashcard Difficulties: - <code>easy</code> - Simple recall questions - <code>medium</code> - Moderate complexity - <code>hard</code> - Advanced concepts</p> <p>Quiz Options: - <code>question_count</code> - Number of questions (default: 2) - <code>difficulty</code> - Difficulty level 1-3 (default: 2)</p>"},{"location":"api_reference/#retry-strategies-phase-10","title":"Retry Strategies (Phase 10)","text":""},{"location":"api_reference/#pynotebooklm.retry.RetryStrategy","title":"<code>pynotebooklm.retry.RetryStrategy</code>","text":"<p>Configuration for retry behavior with exponential backoff.</p> <p>Attributes:</p> Name Type Description <code>max_attempts</code> <p>Maximum number of retry attempts (including initial attempt).</p> <code>base_delay</code> <p>Initial delay between retries in seconds.</p> <code>max_delay</code> <p>Maximum delay between retries in seconds.</p> <code>exponential_base</code> <p>Base for exponential backoff calculation.</p> <code>jitter</code> <p>Whether to add random jitter to delays.</p> Source code in <code>src/pynotebooklm/retry.py</code> <pre><code>class RetryStrategy:\n    \"\"\"\n    Configuration for retry behavior with exponential backoff.\n\n    Attributes:\n        max_attempts: Maximum number of retry attempts (including initial attempt).\n        base_delay: Initial delay between retries in seconds.\n        max_delay: Maximum delay between retries in seconds.\n        exponential_base: Base for exponential backoff calculation.\n        jitter: Whether to add random jitter to delays.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_attempts: int | None = None,\n        base_delay: float | None = None,\n        max_delay: float | None = None,\n        exponential_base: float = 2.0,\n        jitter: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Initialize retry strategy.\n\n        Args:\n            max_attempts: Maximum retry attempts. Defaults to PYNOTEBOOKLM_MAX_RETRIES env var or 3.\n            base_delay: Initial delay in seconds. Defaults to PYNOTEBOOKLM_BASE_DELAY or 1.0.\n            max_delay: Maximum delay in seconds. Defaults to PYNOTEBOOKLM_MAX_DELAY or 60.0.\n            exponential_base: Base for exponential calculation.\n            jitter: Whether to add random jitter to reduce thundering herd.\n        \"\"\"\n        self.max_attempts = (\n            max_attempts\n            if max_attempts is not None\n            else int(os.getenv(\"PYNOTEBOOKLM_MAX_RETRIES\", \"3\"))\n        )\n        self.base_delay = (\n            base_delay\n            if base_delay is not None\n            else float(os.getenv(\"PYNOTEBOOKLM_BASE_DELAY\", \"1.0\"))\n        )\n        self.max_delay = (\n            max_delay\n            if max_delay is not None\n            else float(os.getenv(\"PYNOTEBOOKLM_MAX_DELAY\", \"60.0\"))\n        )\n        self.exponential_base = exponential_base\n        self.jitter = jitter\n\n    def calculate_delay(self, attempt: int) -&gt; float:\n        \"\"\"\n        Calculate delay for a given attempt number.\n\n        Uses exponential backoff: delay = base_delay * (exponential_base ** attempt)\n        Capped at max_delay, with optional jitter.\n\n        Args:\n            attempt: Current attempt number (0-indexed).\n\n        Returns:\n            Delay in seconds before next retry.\n        \"\"\"\n        # Calculate exponential delay\n        delay = self.base_delay * (self.exponential_base**attempt)\n\n        # Cap at max_delay\n        delay = min(delay, self.max_delay)\n\n        # Add jitter if enabled (random value between 0 and delay)\n        if self.jitter:\n            delay = delay * (0.5 + random.random() / 2)\n\n        return delay\n\n    def should_retry(self, exception: Exception, attempt: int) -&gt; bool:\n        \"\"\"\n        Determine if an exception should trigger a retry.\n\n        Args:\n            exception: The exception that was raised.\n            attempt: Current attempt number (0-indexed).\n\n        Returns:\n            True if should retry, False otherwise.\n        \"\"\"\n        # Don't retry if we've exceeded max attempts\n        if attempt &gt;= self.max_attempts:\n            return False\n\n        # Always retry rate limit errors\n        if isinstance(exception, RateLimitError):\n            return True\n\n        # Retry on transient API errors (5xx status codes)\n        if isinstance(exception, APIError):\n            if exception.status_code and 500 &lt;= exception.status_code &lt; 600:\n                return True\n\n        # Don't retry on authentication or not found errors\n        if isinstance(exception, AuthenticationError | NotebookNotFoundError):\n            return False\n\n        return False\n</code></pre>"},{"location":"api_reference/#pynotebooklm.retry.RetryStrategy.__init__","title":"<code>__init__(max_attempts=None, base_delay=None, max_delay=None, exponential_base=2.0, jitter=True)</code>","text":"<p>Initialize retry strategy.</p> <p>Parameters:</p> Name Type Description Default <code>max_attempts</code> <code>int | None</code> <p>Maximum retry attempts. Defaults to PYNOTEBOOKLM_MAX_RETRIES env var or 3.</p> <code>None</code> <code>base_delay</code> <code>float | None</code> <p>Initial delay in seconds. Defaults to PYNOTEBOOKLM_BASE_DELAY or 1.0.</p> <code>None</code> <code>max_delay</code> <code>float | None</code> <p>Maximum delay in seconds. Defaults to PYNOTEBOOKLM_MAX_DELAY or 60.0.</p> <code>None</code> <code>exponential_base</code> <code>float</code> <p>Base for exponential calculation.</p> <code>2.0</code> <code>jitter</code> <code>bool</code> <p>Whether to add random jitter to reduce thundering herd.</p> <code>True</code> Source code in <code>src/pynotebooklm/retry.py</code> <pre><code>def __init__(\n    self,\n    max_attempts: int | None = None,\n    base_delay: float | None = None,\n    max_delay: float | None = None,\n    exponential_base: float = 2.0,\n    jitter: bool = True,\n) -&gt; None:\n    \"\"\"\n    Initialize retry strategy.\n\n    Args:\n        max_attempts: Maximum retry attempts. Defaults to PYNOTEBOOKLM_MAX_RETRIES env var or 3.\n        base_delay: Initial delay in seconds. Defaults to PYNOTEBOOKLM_BASE_DELAY or 1.0.\n        max_delay: Maximum delay in seconds. Defaults to PYNOTEBOOKLM_MAX_DELAY or 60.0.\n        exponential_base: Base for exponential calculation.\n        jitter: Whether to add random jitter to reduce thundering herd.\n    \"\"\"\n    self.max_attempts = (\n        max_attempts\n        if max_attempts is not None\n        else int(os.getenv(\"PYNOTEBOOKLM_MAX_RETRIES\", \"3\"))\n    )\n    self.base_delay = (\n        base_delay\n        if base_delay is not None\n        else float(os.getenv(\"PYNOTEBOOKLM_BASE_DELAY\", \"1.0\"))\n    )\n    self.max_delay = (\n        max_delay\n        if max_delay is not None\n        else float(os.getenv(\"PYNOTEBOOKLM_MAX_DELAY\", \"60.0\"))\n    )\n    self.exponential_base = exponential_base\n    self.jitter = jitter\n</code></pre>"},{"location":"api_reference/#pynotebooklm.retry.RetryStrategy.should_retry","title":"<code>should_retry(exception, attempt)</code>","text":"<p>Determine if an exception should trigger a retry.</p> <p>Parameters:</p> Name Type Description Default <code>exception</code> <code>Exception</code> <p>The exception that was raised.</p> required <code>attempt</code> <code>int</code> <p>Current attempt number (0-indexed).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if should retry, False otherwise.</p> Source code in <code>src/pynotebooklm/retry.py</code> <pre><code>def should_retry(self, exception: Exception, attempt: int) -&gt; bool:\n    \"\"\"\n    Determine if an exception should trigger a retry.\n\n    Args:\n        exception: The exception that was raised.\n        attempt: Current attempt number (0-indexed).\n\n    Returns:\n        True if should retry, False otherwise.\n    \"\"\"\n    # Don't retry if we've exceeded max attempts\n    if attempt &gt;= self.max_attempts:\n        return False\n\n    # Always retry rate limit errors\n    if isinstance(exception, RateLimitError):\n        return True\n\n    # Retry on transient API errors (5xx status codes)\n    if isinstance(exception, APIError):\n        if exception.status_code and 500 &lt;= exception.status_code &lt; 600:\n            return True\n\n    # Don't retry on authentication or not found errors\n    if isinstance(exception, AuthenticationError | NotebookNotFoundError):\n        return False\n\n    return False\n</code></pre>"},{"location":"api_reference/#pynotebooklm.retry.RetryStrategy.calculate_delay","title":"<code>calculate_delay(attempt)</code>","text":"<p>Calculate delay for a given attempt number.</p> <p>Uses exponential backoff: delay = base_delay * (exponential_base ** attempt) Capped at max_delay, with optional jitter.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>Current attempt number (0-indexed).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Delay in seconds before next retry.</p> Source code in <code>src/pynotebooklm/retry.py</code> <pre><code>def calculate_delay(self, attempt: int) -&gt; float:\n    \"\"\"\n    Calculate delay for a given attempt number.\n\n    Uses exponential backoff: delay = base_delay * (exponential_base ** attempt)\n    Capped at max_delay, with optional jitter.\n\n    Args:\n        attempt: Current attempt number (0-indexed).\n\n    Returns:\n        Delay in seconds before next retry.\n    \"\"\"\n    # Calculate exponential delay\n    delay = self.base_delay * (self.exponential_base**attempt)\n\n    # Cap at max_delay\n    delay = min(delay, self.max_delay)\n\n    # Add jitter if enabled (random value between 0 and delay)\n    if self.jitter:\n        delay = delay * (0.5 + random.random() / 2)\n\n    return delay\n</code></pre>"},{"location":"api_reference/#pynotebooklm.retry.with_retry","title":"<code>pynotebooklm.retry.with_retry(strategy=None)</code>","text":"<p>Decorator to add retry logic with exponential backoff to async functions.</p> <p>Parameters:</p> Name Type Description Default <code>strategy</code> <code>RetryStrategy | None</code> <p>Retry strategy to use. If None, uses default strategy.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[F], F]</code> <p>Decorated function with retry logic.</p> Example <p>@with_retry() ... async def call_api(): ...     # Your API call here ...     pass</p> Source code in <code>src/pynotebooklm/retry.py</code> <pre><code>def with_retry(strategy: RetryStrategy | None = None) -&gt; Callable[[F], F]:\n    \"\"\"\n    Decorator to add retry logic with exponential backoff to async functions.\n\n    Args:\n        strategy: Retry strategy to use. If None, uses default strategy.\n\n    Returns:\n        Decorated function with retry logic.\n\n    Example:\n        &gt;&gt;&gt; @with_retry()\n        ... async def call_api():\n        ...     # Your API call here\n        ...     pass\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # With custom strategy\n        &gt;&gt;&gt; @with_retry(RetryStrategy(max_attempts=5, base_delay=2.0))\n        ... async def call_api_with_custom_retry():\n        ...     pass\n    \"\"\"\n\n    def decorator(func: F) -&gt; F:\n        @wraps(func)\n        async def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n            retry_strategy = strategy or RetryStrategy()\n            last_exception: Exception | None = None\n\n            for attempt in range(retry_strategy.max_attempts):\n                try:\n                    return await func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n\n                    # Check if we should retry\n                    if not retry_strategy.should_retry(e, attempt):\n                        logger.debug(\n                            \"Not retrying %s after attempt %d: %s\",\n                            func.__name__,\n                            attempt + 1,\n                            e,\n                        )\n                        raise\n\n                    # Calculate delay and log\n                    delay = retry_strategy.calculate_delay(attempt)\n                    logger.info(\n                        \"Retrying %s after attempt %d/%d (delay: %.2fs): %s\",\n                        func.__name__,\n                        attempt + 1,\n                        retry_strategy.max_attempts,\n                        delay,\n                        str(e)[:100],\n                    )\n\n                    # Wait before retry\n                    await asyncio.sleep(delay)\n\n            # If we get here, all retries failed\n            if last_exception:\n                logger.error(\n                    \"All retry attempts failed for %s: %s\",\n                    func.__name__,\n                    last_exception,\n                )\n                raise last_exception\n\n            # This should never happen, but satisfy type checker\n            raise RuntimeError(\"Retry logic failed unexpectedly\")\n\n        return wrapper  # type: ignore[return-value]\n\n    return decorator\n</code></pre>"},{"location":"api_reference/#pynotebooklm.retry.with_retry--with-custom-strategy","title":"With custom strategy","text":"<p>@with_retry(RetryStrategy(max_attempts=5, base_delay=2.0)) ... async def call_api_with_custom_retry(): ...     pass</p>"},{"location":"api_reference/#environment-configuration","title":"Environment Configuration","text":"<p>Control retry behavior with environment variables:</p> <pre><code>export PYNOTEBOOKLM_MAX_RETRIES=5      # Default: 3\nexport PYNOTEBOOKLM_BASE_DELAY=2.0     # Default: 1.0 seconds\nexport PYNOTEBOOKLM_MAX_DELAY=120.0    # Default: 60.0 seconds\n</code></pre>"},{"location":"api_reference/#data-models","title":"Data Models","text":""},{"location":"api_reference/#pynotebooklm.models.Notebook","title":"<code>pynotebooklm.models.Notebook</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a NotebookLM notebook.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the notebook.</p> <code>name</code> <code>str</code> <p>Display name of the notebook.</p> <code>created_at</code> <code>datetime | None</code> <p>When the notebook was created.</p> <code>updated_at</code> <code>datetime | None</code> <p>When the notebook was last modified.</p> <code>sources</code> <code>list[Source]</code> <p>List of sources in the notebook.</p> <code>source_count</code> <code>int</code> <p>Number of sources.</p> Source code in <code>src/pynotebooklm/models.py</code> <pre><code>class Notebook(BaseModel):\n    \"\"\"\n    Represents a NotebookLM notebook.\n\n    Attributes:\n        id: Unique identifier for the notebook.\n        name: Display name of the notebook.\n        created_at: When the notebook was created.\n        updated_at: When the notebook was last modified.\n        sources: List of sources in the notebook.\n        source_count: Number of sources.\n    \"\"\"\n\n    id: str = Field(..., description=\"Unique notebook identifier\")\n    name: str = Field(..., description=\"Notebook name\")\n    created_at: datetime | None = Field(None, description=\"Creation timestamp\")\n    updated_at: datetime | None = Field(None, description=\"Last update timestamp\")\n    sources: list[Source] = Field(default_factory=list, description=\"Notebook sources\")\n    source_count: int = Field(0, description=\"Number of sources\")\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#pynotebooklm.models.Source","title":"<code>pynotebooklm.models.Source</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a source document in a notebook.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the source.</p> <code>type</code> <code>SourceType</code> <p>Type of source (url, youtube, drive, text).</p> <code>title</code> <code>str</code> <p>Display title of the source.</p> <code>url</code> <code>str | None</code> <p>Original URL for URL/YouTube sources.</p> <code>status</code> <code>SourceStatus</code> <p>Processing status.</p> <code>created_at</code> <code>datetime | None</code> <p>When the source was added.</p> <code>is_fresh</code> <code>bool | None</code> <p>For Drive sources, whether content is up-to-date.</p> <code>source_type_code</code> <code>int | None</code> <p>Internal numeric type code for debugging.</p> Source code in <code>src/pynotebooklm/models.py</code> <pre><code>class Source(BaseModel):\n    \"\"\"\n    Represents a source document in a notebook.\n\n    Attributes:\n        id: Unique identifier for the source.\n        type: Type of source (url, youtube, drive, text).\n        title: Display title of the source.\n        url: Original URL for URL/YouTube sources.\n        status: Processing status.\n        created_at: When the source was added.\n        is_fresh: For Drive sources, whether content is up-to-date.\n        source_type_code: Internal numeric type code for debugging.\n    \"\"\"\n\n    id: str = Field(..., description=\"Unique source identifier\")\n    type: SourceType = Field(..., description=\"Source type\")\n    title: str = Field(..., description=\"Source title\")\n    url: str | None = Field(None, description=\"Source URL (for url/youtube types)\")\n    status: SourceStatus = Field(\n        SourceStatus.PROCESSING, description=\"Processing status\"\n    )\n    created_at: datetime | None = Field(None, description=\"Creation timestamp\")\n    is_fresh: bool | None = Field(\n        None, description=\"For Drive sources, whether content is up-to-date\"\n    )\n    source_type_code: int | None = Field(\n        None, description=\"Internal numeric type code for debugging\"\n    )\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#pynotebooklm.models.Artifact","title":"<code>pynotebooklm.models.Artifact</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a generated content artifact (podcast, video, etc.).</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the artifact.</p> <code>type</code> <code>ArtifactType</code> <p>Type of artifact.</p> <code>status</code> <code>ArtifactStatus</code> <p>Generation status.</p> <code>url</code> <code>str | None</code> <p>Download URL when ready.</p> <code>progress</code> <code>float</code> <p>Generation progress (0.0 to 1.0).</p> <code>error_message</code> <code>str | None</code> <p>Error message if generation failed.</p> <code>created_at</code> <code>datetime | None</code> <p>When generation was started.</p> Source code in <code>src/pynotebooklm/models.py</code> <pre><code>class Artifact(BaseModel):\n    \"\"\"\n    Represents a generated content artifact (podcast, video, etc.).\n\n    Attributes:\n        id: Unique identifier for the artifact.\n        type: Type of artifact.\n        status: Generation status.\n        url: Download URL when ready.\n        progress: Generation progress (0.0 to 1.0).\n        error_message: Error message if generation failed.\n        created_at: When generation was started.\n    \"\"\"\n\n    id: str = Field(..., description=\"Unique artifact identifier\")\n    type: ArtifactType = Field(..., description=\"Artifact type\")\n    status: ArtifactStatus = Field(\n        ArtifactStatus.PENDING, description=\"Generation status\"\n    )\n    url: str | None = Field(None, description=\"Download URL when ready\")\n    progress: float = Field(0.0, ge=0.0, le=1.0, description=\"Progress (0.0-1.0)\")\n    error_message: str | None = Field(None, description=\"Error message if failed\")\n    created_at: datetime | None = Field(None, description=\"Creation timestamp\")\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#pynotebooklm.models.ChatMessage","title":"<code>pynotebooklm.models.ChatMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a message in a notebook chat conversation.</p> <p>Attributes:</p> Name Type Description <code>role</code> <code>ChatRole</code> <p>Message role (user or assistant).</p> <code>content</code> <code>str</code> <p>Message content.</p> <code>citations</code> <code>list[str]</code> <p>Source citations in the response.</p> <code>created_at</code> <code>datetime | None</code> <p>Message timestamp.</p> Source code in <code>src/pynotebooklm/models.py</code> <pre><code>class ChatMessage(BaseModel):\n    \"\"\"\n    Represents a message in a notebook chat conversation.\n\n    Attributes:\n        role: Message role (user or assistant).\n        content: Message content.\n        citations: Source citations in the response.\n        created_at: Message timestamp.\n    \"\"\"\n\n    role: ChatRole = Field(..., description=\"Message role\")\n    content: str = Field(..., description=\"Message content\")\n    citations: list[str] = Field(default_factory=list, description=\"Source citations\")\n    created_at: datetime | None = Field(None, description=\"Message timestamp\")\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#pynotebooklm.research.ResearchResult","title":"<code>pynotebooklm.research.ResearchResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single research result/finding.</p> Source code in <code>src/pynotebooklm/research.py</code> <pre><code>class ResearchResult(BaseModel):\n    \"\"\"Represents a single research result/finding.\"\"\"\n\n    index: int = Field(..., description=\"Result index\")\n    url: str = Field(\"\", description=\"Source URL\")\n    title: str = Field(\"\", description=\"Result title\")\n    description: str = Field(\"\", description=\"Result description/snippet\")\n    result_type: int = Field(1, description=\"Result type code\")\n    result_type_name: str = Field(\"web\", description=\"Human-readable result type\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMap","title":"<code>pynotebooklm.mindmaps.MindMap</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a saved mind map in a notebook.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>class MindMap(BaseModel):\n    \"\"\"Represents a saved mind map in a notebook.\"\"\"\n\n    id: str = Field(..., description=\"Unique mind map identifier\")\n    notebook_id: str = Field(..., description=\"Parent notebook ID\")\n    title: str = Field(\"Mind Map\", description=\"Mind map title\")\n    mind_map_json: str | None = Field(None, description=\"The mind map JSON structure\")\n    created_at: datetime | None = Field(None, description=\"Creation timestamp\")\n    source_ids: list[str] = Field(\n        default_factory=list, description=\"Source IDs used to create this map\"\n    )\n\n    model_config = {\"frozen\": False}\n\n    def get_root_node(self) -&gt; MindMapNode | None:\n        \"\"\"Parse the JSON and return the root MindMapNode.\"\"\"\n        if not self.mind_map_json:\n            return None\n        try:\n            data = json.loads(self.mind_map_json)\n            return _parse_node(data)\n        except (json.JSONDecodeError, KeyError):\n            return None\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMap.get_root_node","title":"<code>get_root_node()</code>","text":"<p>Parse the JSON and return the root MindMapNode.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>def get_root_node(self) -&gt; MindMapNode | None:\n    \"\"\"Parse the JSON and return the root MindMapNode.\"\"\"\n    if not self.mind_map_json:\n        return None\n    try:\n        data = json.loads(self.mind_map_json)\n        return _parse_node(data)\n    except (json.JSONDecodeError, KeyError):\n        return None\n</code></pre>"},{"location":"api_reference/#pynotebooklm.mindmaps.MindMapNode","title":"<code>pynotebooklm.mindmaps.MindMapNode</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a node in a mind map tree structure.</p> Source code in <code>src/pynotebooklm/mindmaps.py</code> <pre><code>class MindMapNode(BaseModel):\n    \"\"\"Represents a node in a mind map tree structure.\"\"\"\n\n    name: str = Field(..., description=\"Node label/content\")\n    children: list[\"MindMapNode\"] = Field(\n        default_factory=list, description=\"Child nodes\"\n    )\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#pynotebooklm.content.StudioArtifact","title":"<code>pynotebooklm.content.StudioArtifact</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a studio artifact (audio, video, infographic, slide deck).</p> Source code in <code>src/pynotebooklm/content.py</code> <pre><code>class StudioArtifact(BaseModel):\n    \"\"\"Represents a studio artifact (audio, video, infographic, slide deck).\"\"\"\n\n    artifact_id: str = Field(..., description=\"Unique artifact identifier\")\n    notebook_id: str = Field(..., description=\"Parent notebook ID\")\n    title: str = Field(\"\", description=\"Artifact title\")\n    artifact_type: StudioArtifactType = Field(..., description=\"Type of artifact\")\n    status: StudioArtifactStatus = Field(..., description=\"Generation status\")\n    created_at: str | None = Field(None, description=\"ISO timestamp when created\")\n\n    # Type-specific URLs\n    audio_url: str | None = Field(None, description=\"Audio download URL\")\n    video_url: str | None = Field(None, description=\"Video download URL\")\n    infographic_url: str | None = Field(None, description=\"Infographic image URL\")\n    slide_deck_url: str | None = Field(None, description=\"Slide deck download URL\")\n\n    # Additional metadata\n    duration_seconds: int | None = Field(None, description=\"Audio duration in seconds\")\n    report_content: str | None = Field(None, description=\"Report markdown content\")\n    flashcard_count: int | None = Field(None, description=\"Number of flashcards\")\n\n    model_config = {\"frozen\": False}\n</code></pre>"},{"location":"api_reference/#exceptions","title":"Exceptions","text":""},{"location":"api_reference/#pynotebooklm.exceptions.PyNotebookLMError","title":"<code>pynotebooklm.exceptions.PyNotebookLMError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all PyNotebookLM errors.</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class PyNotebookLMError(Exception):\n    \"\"\"Base exception for all PyNotebookLM errors.\"\"\"\n\n    def __init__(self, message: str = \"An error occurred in PyNotebookLM\") -&gt; None:\n        self.message = message\n        super().__init__(self.message)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.AuthenticationError","title":"<code>pynotebooklm.exceptions.AuthenticationError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when authentication fails or cookies are expired/invalid.</p> <p>This typically occurs when: - No authentication cookies exist - Cookies have expired (usually after 2-4 weeks) - Cookies are malformed or invalid</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class AuthenticationError(PyNotebookLMError):\n    \"\"\"\n    Raised when authentication fails or cookies are expired/invalid.\n\n    This typically occurs when:\n    - No authentication cookies exist\n    - Cookies have expired (usually after 2-4 weeks)\n    - Cookies are malformed or invalid\n    \"\"\"\n\n    def __init__(\n        self, message: str = \"Authentication failed. Please login again.\"\n    ) -&gt; None:\n        super().__init__(message)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.NotebookNotFoundError","title":"<code>pynotebooklm.exceptions.NotebookNotFoundError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when a requested notebook does not exist.</p> <p>Attributes:</p> Name Type Description <code>notebook_id</code> <p>The ID of the notebook that was not found.</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class NotebookNotFoundError(PyNotebookLMError):\n    \"\"\"\n    Raised when a requested notebook does not exist.\n\n    Attributes:\n        notebook_id: The ID of the notebook that was not found.\n    \"\"\"\n\n    def __init__(self, notebook_id: str) -&gt; None:\n        self.notebook_id = notebook_id\n        super().__init__(f\"Notebook not found: {notebook_id}\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.SourceError","title":"<code>pynotebooklm.exceptions.SourceError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when source operations fail.</p> <p>This can occur when: - Adding a source fails (invalid URL, unsupported format) - Source processing fails - Source deletion fails</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class SourceError(PyNotebookLMError):\n    \"\"\"\n    Raised when source operations fail.\n\n    This can occur when:\n    - Adding a source fails (invalid URL, unsupported format)\n    - Source processing fails\n    - Source deletion fails\n    \"\"\"\n\n    def __init__(\n        self, message: str = \"Source operation failed\", source_id: str | None = None\n    ) -&gt; None:\n        self.source_id = source_id\n        super().__init__(message)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.GenerationError","title":"<code>pynotebooklm.exceptions.GenerationError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when content generation fails.</p> <p>This can occur when: - Not enough sources in notebook - Generation process encounters an error - Invalid generation parameters</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class GenerationError(PyNotebookLMError):\n    \"\"\"\n    Raised when content generation fails.\n\n    This can occur when:\n    - Not enough sources in notebook\n    - Generation process encounters an error\n    - Invalid generation parameters\n    \"\"\"\n\n    def __init__(\n        self, message: str = \"Content generation failed\", artifact_id: str | None = None\n    ) -&gt; None:\n        self.artifact_id = artifact_id\n        super().__init__(message)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.GenerationTimeoutError","title":"<code>pynotebooklm.exceptions.GenerationTimeoutError</code>","text":"<p>               Bases: <code>GenerationError</code></p> <p>Raised when content generation exceeds the maximum allowed time.</p> <p>Attributes:</p> Name Type Description <code>timeout</code> <p>The timeout value in seconds that was exceeded.</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class GenerationTimeoutError(GenerationError):\n    \"\"\"\n    Raised when content generation exceeds the maximum allowed time.\n\n    Attributes:\n        timeout: The timeout value in seconds that was exceeded.\n    \"\"\"\n\n    def __init__(self, timeout: int, artifact_id: str | None = None) -&gt; None:\n        self.timeout = timeout\n        super().__init__(\n            message=f\"Generation timed out after {timeout} seconds\",\n            artifact_id=artifact_id,\n        )\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.RateLimitError","title":"<code>pynotebooklm.exceptions.RateLimitError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when the API rate limit is exceeded.</p> <p>Attributes:</p> Name Type Description <code>retry_after</code> <p>Suggested time to wait before retrying (in seconds).</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class RateLimitError(PyNotebookLMError):\n    \"\"\"\n    Raised when the API rate limit is exceeded.\n\n    Attributes:\n        retry_after: Suggested time to wait before retrying (in seconds).\n    \"\"\"\n\n    def __init__(\n        self, message: str = \"Rate limit exceeded\", retry_after: int | None = None\n    ) -&gt; None:\n        self.retry_after = retry_after\n        if retry_after:\n            message = f\"{message}. Retry after {retry_after} seconds.\"\n        super().__init__(message)\n</code></pre>"},{"location":"api_reference/#pynotebooklm.exceptions.APIError","title":"<code>pynotebooklm.exceptions.APIError</code>","text":"<p>               Bases: <code>PyNotebookLMError</code></p> <p>Raised when the NotebookLM internal API returns an error.</p> <p>Attributes:</p> Name Type Description <code>status_code</code> <p>HTTP status code (if applicable).</p> <code>response_body</code> <p>Raw response body from the API.</p> Source code in <code>src/pynotebooklm/exceptions.py</code> <pre><code>class APIError(PyNotebookLMError):\n    \"\"\"\n    Raised when the NotebookLM internal API returns an error.\n\n    Attributes:\n        status_code: HTTP status code (if applicable).\n        response_body: Raw response body from the API.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str = \"API error occurred\",\n        status_code: int | None = None,\n        response_body: str | None = None,\n    ) -&gt; None:\n        self.status_code = status_code\n        self.response_body = response_body\n        if status_code:\n            message = f\"{message} (status: {status_code})\"\n        super().__init__(message)\n</code></pre>"},{"location":"api_reference/#browser-session-management","title":"Browser Session Management","text":""},{"location":"api_reference/#pynotebooklm.session.BrowserSession","title":"<code>pynotebooklm.session.BrowserSession</code>","text":"<p>Manages a Playwright browser session for NotebookLM API calls.</p> <p>This class provides an async context manager for browser lifecycle and methods for making API calls via page.evaluate().</p> Example <p>auth = AuthManager() async with BrowserSession(auth) as session: ...     result = await session.call_rpc(\"wXbhsf\", [None, 1, None, [2]]) ...     print(result)</p> <p>Attributes:</p> Name Type Description <code>auth</code> <p>AuthManager instance for cookie management.</p> <code>headless</code> <p>Whether to run browser in headless mode.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>class BrowserSession:\n    \"\"\"\n    Manages a Playwright browser session for NotebookLM API calls.\n\n    This class provides an async context manager for browser lifecycle\n    and methods for making API calls via page.evaluate().\n\n    Example:\n        &gt;&gt;&gt; auth = AuthManager()\n        &gt;&gt;&gt; async with BrowserSession(auth) as session:\n        ...     result = await session.call_rpc(\"wXbhsf\", [None, 1, None, [2]])\n        ...     print(result)\n\n    Attributes:\n        auth: AuthManager instance for cookie management.\n        headless: Whether to run browser in headless mode.\n    \"\"\"\n\n    def __init__(\n        self,\n        auth: AuthManager,\n        headless: bool = True,\n        timeout: int = 60000,\n        auto_refresh: bool = False,\n        block_resources: bool = True,\n        streaming_timeout: int = DEFAULT_STREAMING_TIMEOUT_MS,\n        csrf_cache_ttl: int = DEFAULT_CSRF_TTL_SECONDS,\n        wait_until: Literal[\n            \"commit\", \"domcontentloaded\", \"load\", \"networkidle\"\n        ] = \"load\",\n    ) -&gt; None:\n        \"\"\"\n        Initialize the browser session.\n\n        Args:\n            auth: AuthManager instance with valid authentication.\n            headless: Whether to run browser in headless mode.\n            timeout: Default timeout for page operations in milliseconds.\n            auto_refresh: Whether to refresh cookies on auth failures.\n            block_resources: Block images/fonts/media to speed page load.\n            streaming_timeout: Timeout for streaming endpoints (milliseconds).\n            csrf_cache_ttl: Cache TTL for CSRF tokens (seconds).\n            wait_until: Playwright wait_until strategy for page navigation.\n        \"\"\"\n        self.auth = auth\n        self.headless = headless\n        self.timeout = timeout\n        self.auto_refresh = auto_refresh\n        self.block_resources = block_resources\n        self.streaming_timeout = streaming_timeout\n        self.csrf_cache_ttl = timedelta(seconds=csrf_cache_ttl)\n        self.wait_until = wait_until\n\n        # These are set in __aenter__\n        self._playwright: Playwright | None = None\n        self._browser: Browser | None = None\n        self._context: BrowserContext | None = None\n        self._page: Page | None = None\n        self._csrf_token: str | None = None\n        self._csrf_cached_at: datetime | None = None\n        self._rpc_calls = 0\n        self._rpc_failures = 0\n\n    def _launch_args(self) -&gt; list[str]:\n        \"\"\"Return Chromium launch args optimized for speed.\"\"\"\n        return [\n            \"--no-sandbox\",\n            \"--disable-setuid-sandbox\",\n            \"--disable-dev-shm-usage\",\n            \"--disable-extensions\",\n            \"--disable-gpu\",\n        ]\n\n    def _context_options(self) -&gt; dict[str, Any]:\n        \"\"\"Return BrowserContext options.\"\"\"\n        return {\n            \"viewport\": {\"width\": 1280, \"height\": 800},\n            \"user_agent\": (\n                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                \"Chrome/120.0.0.0 Safari/537.36\"\n            ),\n        }\n\n    async def _apply_resource_blocking(self, context: BrowserContext) -&gt; None:\n        \"\"\"Block non-essential resources for faster page loads.\"\"\"\n        await context.route(\"**/*\", self._route_request)\n\n    async def _route_request(self, route: Any, request: Any) -&gt; None:\n        if request.resource_type in {\"image\", \"media\", \"font\", \"stylesheet\"}:\n            await route.abort()\n        else:\n            await route.continue_()\n\n    def _is_authenticated_page(self) -&gt; bool:\n        if self._page is None:\n            return False\n        return not any(marker in self._page.url for marker in AUTH_REDIRECT_MARKERS)\n\n    async def _check_auth_validity(self) -&gt; None:\n        \"\"\"Raise AuthenticationError if cookies appear invalid.\"\"\"\n        if self.auth.is_expired():\n            raise AuthenticationError(\"Authentication expired. Please login again.\")\n        if not self._is_authenticated_page():\n            raise AuthenticationError(\"Cookies expired or invalid. Please login again.\")\n\n    async def _ensure_csrf_token(self) -&gt; None:\n        \"\"\"Refresh CSRF token if cache has expired.\"\"\"\n        if self._page is None:\n            return\n        if self._csrf_token and self._csrf_cached_at:\n            if datetime.now() - self._csrf_cached_at &lt;= self.csrf_cache_ttl:\n                return\n        self._csrf_token = await self._extract_csrf_token()\n        self._csrf_cached_at = datetime.now()\n\n    async def _refresh_session(self) -&gt; None:\n        \"\"\"Refresh cookies and recreate the browser context.\"\"\"\n        await self.auth.refresh()\n        if self._browser is None:\n            raise SessionError(\"Browser not active\")\n\n        if self._page:\n            await self._page.close()\n            self._page = None\n        if self._context:\n            await self._context.close()\n            self._context = None\n\n        self._context = await self._browser.new_context(**self._context_options())\n        if self.block_resources:\n            await self._apply_resource_blocking(self._context)\n        await self._context.add_cookies(self.auth.get_cookies())  # type: ignore[arg-type]\n\n        self._page = await self._context.new_page()\n        self._page.set_default_timeout(self.timeout)\n        await self._page.goto(NOTEBOOKLM_URL, wait_until=self.wait_until)\n\n        if not self._is_authenticated_page():\n            raise AuthenticationError(\"Cookies expired or invalid after refresh.\")\n\n        self._csrf_token = await self._extract_csrf_token()\n        self._csrf_cached_at = datetime.now()\n\n    def _response_indicates_auth_failure(self, text: str) -&gt; bool:\n        return any(marker in text for marker in AUTH_REDIRECT_MARKERS)\n\n    def _emit_telemetry(self, rpc_id: str, duration_ms: float, success: bool) -&gt; None:\n        if not _env_flag(TELEMETRY_ENV_VAR):\n            return\n        payload = {\n            \"event\": \"rpc_call\",\n            \"rpc_id\": rpc_id,\n            \"duration_ms\": round(duration_ms, 2),\n            \"success\": success,\n            \"total_calls\": self._rpc_calls,\n            \"total_failures\": self._rpc_failures,\n        }\n        logger.info(json.dumps(payload))\n\n    async def __aenter__(self) -&gt; \"BrowserSession\":\n        \"\"\"\n        Enter the async context manager.\n\n        Launches browser, injects cookies, and navigates to NotebookLM.\n\n        Returns:\n            Self for use in async with statements.\n\n        Raises:\n            AuthenticationError: If not authenticated.\n            BrowserError: If browser launch fails.\n        \"\"\"\n        if not self.auth.is_authenticated():\n            raise AuthenticationError(\n                \"Not authenticated. Please run 'pynotebooklm auth login' first.\"\n            )\n\n        try:\n            logger.debug(\"Starting Playwright...\")\n            self._playwright = await async_playwright().start()\n\n            logger.debug(\"Launching browser (headless=%s)...\", self.headless)\n            self._browser = await self._playwright.chromium.launch(\n                headless=self.headless,\n                args=self._launch_args(),\n            )\n\n            # Create context with cookies\n            logger.debug(\"Creating browser context with cookies...\")\n            self._context = await self._browser.new_context(**self._context_options())\n            if self.block_resources:\n                await self._apply_resource_blocking(self._context)\n\n            # Add cookies (Playwright expects SetCookieParam which matches our dict format)\n            await self._context.add_cookies(self.auth.get_cookies())  # type: ignore[arg-type]\n\n            # Create page and navigate\n            self._page = await self._context.new_page()\n            self._page.set_default_timeout(self.timeout)\n\n            logger.debug(\"Navigating to NotebookLM...\")\n            await self._page.goto(NOTEBOOKLM_URL, wait_until=self.wait_until)\n\n            # Verify we're authenticated\n            if not self._is_authenticated_page():\n                raise AuthenticationError(\n                    \"Cookies expired or invalid. Please login again.\"\n                )\n\n            # Extract CSRF token\n            self._csrf_token = await self._extract_csrf_token()\n            self._csrf_cached_at = datetime.now()\n            logger.info(\n                \"Browser session ready (CSRF token: %s)\", bool(self._csrf_token)\n            )\n\n            return self\n\n        except AuthenticationError:\n            await self._cleanup()\n            raise\n        except Exception as e:\n            await self._cleanup()\n            logger.error(\"Failed to start browser session: %s\", e)\n            raise BrowserError(f\"Failed to start browser session: {e}\") from e\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: Any,\n    ) -&gt; None:\n        \"\"\"Exit the async context manager and cleanup resources.\"\"\"\n        await self._cleanup()\n\n    async def _cleanup(self) -&gt; None:\n        \"\"\"Clean up browser resources.\"\"\"\n        if self._page:\n            try:\n                await self._page.close()\n            except Exception:\n                pass\n            self._page = None\n\n        if self._context:\n            try:\n                await self._context.close()\n            except Exception:\n                pass\n            self._context = None\n\n        if self._browser:\n            try:\n                await self._browser.close()\n            except Exception:\n                pass\n            self._browser = None\n\n        if self._playwright:\n            try:\n                await self._playwright.stop()\n            except Exception:\n                pass\n            self._playwright = None\n\n        self._csrf_token = None\n        self._csrf_cached_at = None\n        logger.debug(\"Browser session cleaned up\")\n\n    async def _extract_csrf_token(self) -&gt; str | None:\n        \"\"\"\n        Extract CSRF token (SNlM0e) from page.\n\n        Returns:\n            CSRF token string or None if not found.\n        \"\"\"\n        if self._page is None:\n            return None\n\n        try:\n            token = await self._page.evaluate(\n                \"\"\"\n                () =&gt; {\n                    const scripts = document.querySelectorAll('script');\n                    for (const script of scripts) {\n                        const match = script.textContent?.match(/SNlM0e\":\"([^\"]+)/);\n                        if (match) return match[1];\n                    }\n                    return null;\n                }\n                \"\"\"\n            )\n            return str(token) if token else None\n        except Exception as e:\n            logger.warning(\"Failed to extract CSRF token: %s\", e)\n            return None\n\n    @property\n    def page(self) -&gt; Page:\n        \"\"\"Get the current page, raising if session not active.\"\"\"\n        if self._page is None:\n            raise SessionError(\"Browser session not active. Use 'async with' context.\")\n        return self._page\n\n    @property\n    def csrf_token(self) -&gt; str | None:\n        \"\"\"Get the CSRF token.\"\"\"\n        return self._csrf_token\n\n    async def ensure_csrf_token(self) -&gt; None:\n        \"\"\"Ensure the CSRF token is refreshed if cache expired.\"\"\"\n        await self._ensure_csrf_token()\n\n    @with_retry()\n    async def call_rpc(\n        self,\n        rpc_id: str,\n        params: list[Any],\n        timeout: int | None = None,\n    ) -&gt; Any:\n        \"\"\"\n        Call a NotebookLM internal RPC endpoint.\n\n        Args:\n            rpc_id: The RPC function ID (e.g., \"wXbhsf\" for list notebooks).\n            params: Parameters to pass to the RPC function.\n            timeout: Optional timeout in milliseconds.\n\n        Returns:\n            Parsed response data from the RPC call.\n\n        Raises:\n            SessionError: If session not active.\n            APIError: If the API returns an error.\n            RateLimitError: If rate limited.\n        \"\"\"\n        if self._page is None:\n            raise SessionError(\"Browser session not active\")\n\n        logger.debug(\"Calling RPC %s with params: %s\", rpc_id, params)\n\n        attempt_refresh = self.auto_refresh\n        last_error: Exception | None = None\n\n        for attempt in range(2 if attempt_refresh else 1):\n            duration_ms = 0.0\n            try:\n                await self._check_auth_validity()\n                await self._ensure_csrf_token()\n\n                # Build the request payload\n                payload = self._encode_payload(rpc_id, params)\n                _log_if_debug(\n                    logger.debug,\n                    f\"RPC payload {rpc_id}: {_sanitize_text(payload)}\",\n                )\n\n                self._rpc_calls += 1\n                start_time = time.perf_counter()\n                response = await self._page.evaluate(\n                    \"\"\"\n                    async (payload) =&gt; {\n                        const response = await fetch(payload.url, {\n                            method: 'POST',\n                            headers: {\n                                'Content-Type': 'application/x-www-form-urlencoded',\n                            },\n                            body: payload.body,\n                            credentials: 'include',\n                        });\n\n                        return {\n                            ok: response.ok,\n                            status: response.status,\n                            statusText: response.statusText,\n                            text: await response.text(),\n                        };\n                    }\n                    \"\"\",\n                    {\n                        \"url\": BATCH_EXECUTE_URL,\n                        \"body\": payload,\n                    },\n                )\n                duration_ms = (time.perf_counter() - start_time) * 1000\n\n                response_text = str(response.get(\"text\", \"\"))\n                _log_if_debug(\n                    logger.debug,\n                    f\"RPC response {rpc_id}: {_sanitize_text(response_text)}\",\n                )\n\n                if self._response_indicates_auth_failure(response_text):\n                    raise AuthenticationError(\"Authentication expired during RPC call.\")\n\n                result = self._parse_response(response)\n                self._emit_telemetry(rpc_id, duration_ms, True)\n                return result\n\n            except AuthenticationError as e:\n                last_error = e\n                if attempt_refresh and attempt == 0:\n                    logger.info(\"Authentication failed; attempting auto-refresh.\")\n                    await self._refresh_session()\n                    continue\n                raise\n            except Exception as e:\n                if isinstance(e, APIError | RateLimitError):\n                    self._rpc_failures += 1\n                    self._emit_telemetry(rpc_id, duration_ms, False)\n                    raise\n                last_error = e\n                self._rpc_failures += 1\n                self._emit_telemetry(rpc_id, duration_ms, False)\n                logger.error(\"RPC call failed: %s\", e)\n                raise APIError(f\"RPC call failed: {e}\") from e\n\n        if last_error:\n            raise last_error\n        raise APIError(\"RPC call failed unexpectedly\")\n\n    def _encode_payload(self, rpc_id: str, params: list[Any]) -&gt; str:\n        \"\"\"\n        Encode RPC parameters into request body format.\n\n        Args:\n            rpc_id: The RPC function ID.\n            params: Parameters for the RPC call.\n\n        Returns:\n            URL-encoded request body string.\n        \"\"\"\n        # Build the JSON payload structure\n        # Format: [[[rpc_id, json_params, null, \"generic\"]]]\n        json_params = json.dumps(params, separators=(\",\", \":\"))\n        inner = [[rpc_id, json_params, None, \"generic\"]]\n        full_payload = json.dumps([inner], separators=(\",\", \":\"))\n\n        # URL encode the payload\n        encoded = urllib.parse.quote(full_payload)\n\n        # Build the request body\n        body_parts = [\n            f\"f.req={encoded}\",\n        ]\n\n        # Add CSRF token if available\n        if self._csrf_token:\n            body_parts.append(f\"at={urllib.parse.quote(self._csrf_token)}\")\n\n        return \"&amp;\".join(body_parts)\n\n    def _parse_response(self, response: dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Parse RPC response data.\n\n        Args:\n            response: Raw response dict with status and text.\n\n        Returns:\n            Parsed response data.\n\n        Raises:\n            APIError: If response indicates an error.\n            RateLimitError: If rate limited.\n        \"\"\"\n        status = response.get(\"status\", 0)\n        text = response.get(\"text\", \"\")\n\n        # Check for rate limiting\n        if status == 429:\n            raise RateLimitError(\"Rate limit exceeded\", retry_after=60)\n\n        # Check for errors\n        if not response.get(\"ok\", False):\n            raise APIError(\n                f\"API returned error: {response.get('statusText', 'Unknown')}\",\n                status_code=status,\n                response_body=text,\n            )\n\n        # Remove anti-XSSI prefix\n        if text.startswith(ANTI_XSSI_PREFIX):\n            text = text[len(ANTI_XSSI_PREFIX) :]\n\n        # Get all non-empty lines\n        lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n        if not lines:\n            raise APIError(\"Empty response from API\")\n\n        # Remove byte count lines\n        data_lines = [line for line in lines if not line.isdigit()]\n        if not data_lines:\n            snippet = text[:200]\n            raise APIError(f\"No data lines found in response: {snippet}\")\n\n        def unwrap_payload(data: Any) -&gt; Any:\n            if isinstance(data, list) and len(data) &gt; 0:\n                inner = data[0]\n                if isinstance(inner, list) and len(inner) &gt; 2:\n                    result_str = inner[2]\n                    if isinstance(result_str, str):\n                        return json.loads(result_str)\n                    return result_str\n            return data\n\n        buffer = \"\"\n        last_error: Exception | None = None\n        for line in data_lines:\n            buffer += line\n            try:\n                parsed = json.loads(buffer)\n                return unwrap_payload(parsed)\n            except json.JSONDecodeError as e:\n                last_error = e\n                # Likely incomplete chunk; keep buffering.\n                if e.msg.lower().startswith(\"unterminated\") or e.msg.lower().startswith(\n                    \"expecting\"\n                ):\n                    continue\n                # Reset buffer for malformed chunk.\n                buffer = \"\"\n                continue\n            except (IndexError, TypeError) as e:\n                last_error = e\n                buffer = \"\"\n\n        snippet = _sanitize_text(text[:300])\n        if last_error:\n            logger.error(\"Failed to parse response: %s\", last_error)\n            raise APIError(\n                f\"Failed to parse response: {last_error} (snippet: {snippet})\"\n            )\n        raise APIError(f\"Failed to parse response (snippet: {snippet})\")\n\n    def parse_streaming_response(self, response_text: str) -&gt; list[Any]:\n        \"\"\"\n        Parse streaming responses into JSON chunks.\n\n        Handles partial/incomplete chunks gracefully by buffering lines.\n        \"\"\"\n        if not response_text:\n            return []\n\n        if response_text.startswith(\")]}'\"):\n            response_text = response_text[4:]\n\n        lines = [line.strip() for line in response_text.split(\"\\n\") if line.strip()]\n        chunks: list[Any] = []\n        buffer = \"\"\n\n        for line in lines:\n            if line.isdigit():\n                continue\n            buffer += line\n            try:\n                chunks.append(json.loads(buffer))\n                buffer = \"\"\n            except json.JSONDecodeError as e:\n                if e.msg.lower().startswith(\"unterminated\") or e.msg.lower().startswith(\n                    \"expecting\"\n                ):\n                    continue\n                logger.debug(\n                    \"Skipping malformed streaming chunk: %s\", _sanitize_text(line[:200])\n                )\n                buffer = \"\"\n\n        if buffer:\n            logger.debug(\n                \"Dropped incomplete streaming chunk: %s\", _sanitize_text(buffer[:200])\n            )\n\n        return chunks\n\n    async def call_api_raw(\n        self,\n        endpoint: str,\n        method: str = \"GET\",\n        body: str | None = None,\n        headers: dict[str, str] | None = None,\n        timeout_ms: int | None = None,\n    ) -&gt; str:\n        \"\"\"\n        Make a raw API call via the browser context.\n\n        Args:\n            endpoint: API endpoint URL.\n            method: HTTP method.\n            body: Request body string.\n            headers: Additional headers.\n            timeout_ms: Timeout in milliseconds for streaming endpoints.\n\n        Returns:\n            Raw response text.\n\n        Raises:\n            SessionError: If session not active.\n            APIError: If request fails.\n        \"\"\"\n        if self._page is None:\n            raise SessionError(\"Browser session not active\")\n\n        attempt_refresh = self.auto_refresh\n        for attempt in range(2 if attempt_refresh else 1):\n            try:\n                await self._check_auth_validity()\n                await self._ensure_csrf_token()\n\n                sanitized_headers = _sanitize_headers(headers or {})\n                _log_if_debug(\n                    logger.debug,\n                    f\"API raw request {method} {endpoint} headers={sanitized_headers} body={_sanitize_text(body or '')}\",\n                )\n\n                response = await self._page.evaluate(\n                    \"\"\"\n                    async (args) =&gt; {\n                        const controller = new AbortController();\n                        const timeoutId = args.timeoutMs\n                            ? setTimeout(() =&gt; controller.abort(), args.timeoutMs)\n                            : null;\n\n                        const options = {\n                            method: args.method,\n                            headers: args.headers || {},\n                            credentials: 'include',\n                            signal: controller.signal,\n                        };\n\n                        if (args.body) {\n                            options.body = args.body;\n                        }\n\n                        let response;\n                        try {\n                            response = await fetch(args.endpoint, options);\n                        } catch (error) {\n                            return {\n                                ok: false,\n                                status: 0,\n                                statusText: error &amp;&amp; error.name ? error.name : 'FetchError',\n                                text: '',\n                            };\n                        } finally {\n                            if (timeoutId) {\n                                clearTimeout(timeoutId);\n                            }\n                        }\n\n                        return {\n                            ok: response.ok,\n                            status: response.status,\n                            statusText: response.statusText,\n                            text: await response.text().catch(() =&gt; ''),\n                        };\n                    }\n                    \"\"\",\n                    {\n                        \"endpoint\": endpoint,\n                        \"method\": method,\n                        \"body\": body,\n                        \"headers\": headers or {},\n                        \"timeoutMs\": timeout_ms or self.streaming_timeout,\n                    },\n                )\n\n                response_text = str(response.get(\"text\", \"\"))\n                _log_if_debug(\n                    logger.debug,\n                    f\"API raw response {endpoint}: {_sanitize_text(response_text)}\",\n                )\n\n                if self._response_indicates_auth_failure(response_text):\n                    raise AuthenticationError(\"Authentication expired during API call.\")\n\n                if not response.get(\"ok\"):\n                    raise APIError(\n                        f\"API request failed: {response.get('statusText')}\",\n                        status_code=response.get(\"status\"),\n                        response_body=response_text,\n                    )\n\n                return response_text\n\n            except AuthenticationError:\n                if attempt_refresh and attempt == 0:\n                    logger.info(\"Authentication failed; attempting auto-refresh.\")\n                    await self._refresh_session()\n                    continue\n                raise\n            except APIError:\n                raise\n            except Exception as e:\n                raise APIError(f\"API call failed: {e}\") from e\n\n        raise APIError(\"API call failed after refresh\")\n\n    async def call_api(\n        self,\n        endpoint: str,\n        method: str = \"GET\",\n        data: dict[str, Any] | None = None,\n        headers: dict[str, str] | None = None,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Make a generic API call via the browser context.\n\n        Args:\n            endpoint: API endpoint URL.\n            method: HTTP method.\n            data: Request body data.\n            headers: Additional headers.\n\n        Returns:\n            Parsed JSON response.\n\n        Raises:\n            SessionError: If session not active.\n            APIError: If request fails.\n        \"\"\"\n        if self._page is None:\n            raise SessionError(\"Browser session not active\")\n\n        attempt_refresh = self.auto_refresh\n        for attempt in range(2 if attempt_refresh else 1):\n            try:\n                await self._check_auth_validity()\n                await self._ensure_csrf_token()\n\n                sanitized_headers = _sanitize_headers(headers or {})\n                _log_if_debug(\n                    logger.debug,\n                    f\"API request {method} {endpoint} headers={sanitized_headers} data={data}\",\n                )\n\n                response = await self._page.evaluate(\n                    \"\"\"\n                    async (args) =&gt; {\n                        const options = {\n                            method: args.method,\n                            headers: args.headers || {},\n                            credentials: 'include',\n                        };\n\n                        if (args.data) {\n                            options.body = JSON.stringify(args.data);\n                            options.headers['Content-Type'] = 'application/json';\n                        }\n\n                        const response = await fetch(args.endpoint, options);\n\n                        return {\n                            ok: response.ok,\n                            status: response.status,\n                            json: await response.json().catch(() =&gt; null),\n                            text: await response.text().catch(() =&gt; ''),\n                        };\n                    }\n                    \"\"\",\n                    {\n                        \"endpoint\": endpoint,\n                        \"method\": method,\n                        \"data\": data,\n                        \"headers\": headers or {},\n                    },\n                )\n\n                response_text = str(response.get(\"text\", \"\"))\n                _log_if_debug(\n                    logger.debug,\n                    f\"API response {endpoint}: {_sanitize_text(response_text)}\",\n                )\n\n                if self._response_indicates_auth_failure(response_text):\n                    raise AuthenticationError(\"Authentication expired during API call.\")\n\n                if not response.get(\"ok\"):\n                    raise APIError(\n                        \"API request failed\",\n                        status_code=response.get(\"status\"),\n                        response_body=response_text,\n                    )\n\n                return response.get(\"json\") or {}\n\n            except AuthenticationError:\n                if attempt_refresh and attempt == 0:\n                    logger.info(\"Authentication failed; attempting auto-refresh.\")\n                    await self._refresh_session()\n                    continue\n                raise\n            except APIError:\n                raise\n            except Exception as e:\n                raise APIError(f\"API call failed: {e}\") from e\n\n        raise APIError(\"API call failed after refresh\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.__init__","title":"<code>__init__(auth, headless=True, timeout=60000, auto_refresh=False, block_resources=True, streaming_timeout=DEFAULT_STREAMING_TIMEOUT_MS, csrf_cache_ttl=DEFAULT_CSRF_TTL_SECONDS, wait_until='load')</code>","text":"<p>Initialize the browser session.</p> <p>Parameters:</p> Name Type Description Default <code>auth</code> <code>AuthManager</code> <p>AuthManager instance with valid authentication.</p> required <code>headless</code> <code>bool</code> <p>Whether to run browser in headless mode.</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Default timeout for page operations in milliseconds.</p> <code>60000</code> <code>auto_refresh</code> <code>bool</code> <p>Whether to refresh cookies on auth failures.</p> <code>False</code> <code>block_resources</code> <code>bool</code> <p>Block images/fonts/media to speed page load.</p> <code>True</code> <code>streaming_timeout</code> <code>int</code> <p>Timeout for streaming endpoints (milliseconds).</p> <code>DEFAULT_STREAMING_TIMEOUT_MS</code> <code>csrf_cache_ttl</code> <code>int</code> <p>Cache TTL for CSRF tokens (seconds).</p> <code>DEFAULT_CSRF_TTL_SECONDS</code> <code>wait_until</code> <code>Literal['commit', 'domcontentloaded', 'load', 'networkidle']</code> <p>Playwright wait_until strategy for page navigation.</p> <code>'load'</code> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>def __init__(\n    self,\n    auth: AuthManager,\n    headless: bool = True,\n    timeout: int = 60000,\n    auto_refresh: bool = False,\n    block_resources: bool = True,\n    streaming_timeout: int = DEFAULT_STREAMING_TIMEOUT_MS,\n    csrf_cache_ttl: int = DEFAULT_CSRF_TTL_SECONDS,\n    wait_until: Literal[\n        \"commit\", \"domcontentloaded\", \"load\", \"networkidle\"\n    ] = \"load\",\n) -&gt; None:\n    \"\"\"\n    Initialize the browser session.\n\n    Args:\n        auth: AuthManager instance with valid authentication.\n        headless: Whether to run browser in headless mode.\n        timeout: Default timeout for page operations in milliseconds.\n        auto_refresh: Whether to refresh cookies on auth failures.\n        block_resources: Block images/fonts/media to speed page load.\n        streaming_timeout: Timeout for streaming endpoints (milliseconds).\n        csrf_cache_ttl: Cache TTL for CSRF tokens (seconds).\n        wait_until: Playwright wait_until strategy for page navigation.\n    \"\"\"\n    self.auth = auth\n    self.headless = headless\n    self.timeout = timeout\n    self.auto_refresh = auto_refresh\n    self.block_resources = block_resources\n    self.streaming_timeout = streaming_timeout\n    self.csrf_cache_ttl = timedelta(seconds=csrf_cache_ttl)\n    self.wait_until = wait_until\n\n    # These are set in __aenter__\n    self._playwright: Playwright | None = None\n    self._browser: Browser | None = None\n    self._context: BrowserContext | None = None\n    self._page: Page | None = None\n    self._csrf_token: str | None = None\n    self._csrf_cached_at: datetime | None = None\n    self._rpc_calls = 0\n    self._rpc_failures = 0\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"<p>Enter the async context manager.</p> <p>Launches browser, injects cookies, and navigates to NotebookLM.</p> <p>Returns:</p> Type Description <code>BrowserSession</code> <p>Self for use in async with statements.</p> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If not authenticated.</p> <code>BrowserError</code> <p>If browser launch fails.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def __aenter__(self) -&gt; \"BrowserSession\":\n    \"\"\"\n    Enter the async context manager.\n\n    Launches browser, injects cookies, and navigates to NotebookLM.\n\n    Returns:\n        Self for use in async with statements.\n\n    Raises:\n        AuthenticationError: If not authenticated.\n        BrowserError: If browser launch fails.\n    \"\"\"\n    if not self.auth.is_authenticated():\n        raise AuthenticationError(\n            \"Not authenticated. Please run 'pynotebooklm auth login' first.\"\n        )\n\n    try:\n        logger.debug(\"Starting Playwright...\")\n        self._playwright = await async_playwright().start()\n\n        logger.debug(\"Launching browser (headless=%s)...\", self.headless)\n        self._browser = await self._playwright.chromium.launch(\n            headless=self.headless,\n            args=self._launch_args(),\n        )\n\n        # Create context with cookies\n        logger.debug(\"Creating browser context with cookies...\")\n        self._context = await self._browser.new_context(**self._context_options())\n        if self.block_resources:\n            await self._apply_resource_blocking(self._context)\n\n        # Add cookies (Playwright expects SetCookieParam which matches our dict format)\n        await self._context.add_cookies(self.auth.get_cookies())  # type: ignore[arg-type]\n\n        # Create page and navigate\n        self._page = await self._context.new_page()\n        self._page.set_default_timeout(self.timeout)\n\n        logger.debug(\"Navigating to NotebookLM...\")\n        await self._page.goto(NOTEBOOKLM_URL, wait_until=self.wait_until)\n\n        # Verify we're authenticated\n        if not self._is_authenticated_page():\n            raise AuthenticationError(\n                \"Cookies expired or invalid. Please login again.\"\n            )\n\n        # Extract CSRF token\n        self._csrf_token = await self._extract_csrf_token()\n        self._csrf_cached_at = datetime.now()\n        logger.info(\n            \"Browser session ready (CSRF token: %s)\", bool(self._csrf_token)\n        )\n\n        return self\n\n    except AuthenticationError:\n        await self._cleanup()\n        raise\n    except Exception as e:\n        await self._cleanup()\n        logger.error(\"Failed to start browser session: %s\", e)\n        raise BrowserError(f\"Failed to start browser session: {e}\") from e\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Exit the async context manager and cleanup resources.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def __aexit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: Any,\n) -&gt; None:\n    \"\"\"Exit the async context manager and cleanup resources.\"\"\"\n    await self._cleanup()\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.call_rpc","title":"<code>call_rpc(rpc_id, params, timeout=None)</code>  <code>async</code>","text":"<p>Call a NotebookLM internal RPC endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>rpc_id</code> <code>str</code> <p>The RPC function ID (e.g., \"wXbhsf\" for list notebooks).</p> required <code>params</code> <code>list[Any]</code> <p>Parameters to pass to the RPC function.</p> required <code>timeout</code> <code>int | None</code> <p>Optional timeout in milliseconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Parsed response data from the RPC call.</p> <p>Raises:</p> Type Description <code>SessionError</code> <p>If session not active.</p> <code>APIError</code> <p>If the API returns an error.</p> <code>RateLimitError</code> <p>If rate limited.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>@with_retry()\nasync def call_rpc(\n    self,\n    rpc_id: str,\n    params: list[Any],\n    timeout: int | None = None,\n) -&gt; Any:\n    \"\"\"\n    Call a NotebookLM internal RPC endpoint.\n\n    Args:\n        rpc_id: The RPC function ID (e.g., \"wXbhsf\" for list notebooks).\n        params: Parameters to pass to the RPC function.\n        timeout: Optional timeout in milliseconds.\n\n    Returns:\n        Parsed response data from the RPC call.\n\n    Raises:\n        SessionError: If session not active.\n        APIError: If the API returns an error.\n        RateLimitError: If rate limited.\n    \"\"\"\n    if self._page is None:\n        raise SessionError(\"Browser session not active\")\n\n    logger.debug(\"Calling RPC %s with params: %s\", rpc_id, params)\n\n    attempt_refresh = self.auto_refresh\n    last_error: Exception | None = None\n\n    for attempt in range(2 if attempt_refresh else 1):\n        duration_ms = 0.0\n        try:\n            await self._check_auth_validity()\n            await self._ensure_csrf_token()\n\n            # Build the request payload\n            payload = self._encode_payload(rpc_id, params)\n            _log_if_debug(\n                logger.debug,\n                f\"RPC payload {rpc_id}: {_sanitize_text(payload)}\",\n            )\n\n            self._rpc_calls += 1\n            start_time = time.perf_counter()\n            response = await self._page.evaluate(\n                \"\"\"\n                async (payload) =&gt; {\n                    const response = await fetch(payload.url, {\n                        method: 'POST',\n                        headers: {\n                            'Content-Type': 'application/x-www-form-urlencoded',\n                        },\n                        body: payload.body,\n                        credentials: 'include',\n                    });\n\n                    return {\n                        ok: response.ok,\n                        status: response.status,\n                        statusText: response.statusText,\n                        text: await response.text(),\n                    };\n                }\n                \"\"\",\n                {\n                    \"url\": BATCH_EXECUTE_URL,\n                    \"body\": payload,\n                },\n            )\n            duration_ms = (time.perf_counter() - start_time) * 1000\n\n            response_text = str(response.get(\"text\", \"\"))\n            _log_if_debug(\n                logger.debug,\n                f\"RPC response {rpc_id}: {_sanitize_text(response_text)}\",\n            )\n\n            if self._response_indicates_auth_failure(response_text):\n                raise AuthenticationError(\"Authentication expired during RPC call.\")\n\n            result = self._parse_response(response)\n            self._emit_telemetry(rpc_id, duration_ms, True)\n            return result\n\n        except AuthenticationError as e:\n            last_error = e\n            if attempt_refresh and attempt == 0:\n                logger.info(\"Authentication failed; attempting auto-refresh.\")\n                await self._refresh_session()\n                continue\n            raise\n        except Exception as e:\n            if isinstance(e, APIError | RateLimitError):\n                self._rpc_failures += 1\n                self._emit_telemetry(rpc_id, duration_ms, False)\n                raise\n            last_error = e\n            self._rpc_failures += 1\n            self._emit_telemetry(rpc_id, duration_ms, False)\n            logger.error(\"RPC call failed: %s\", e)\n            raise APIError(f\"RPC call failed: {e}\") from e\n\n    if last_error:\n        raise last_error\n    raise APIError(\"RPC call failed unexpectedly\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.call_api","title":"<code>call_api(endpoint, method='GET', data=None, headers=None)</code>  <code>async</code>","text":"<p>Make a generic API call via the browser context.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>API endpoint URL.</p> required <code>method</code> <code>str</code> <p>HTTP method.</p> <code>'GET'</code> <code>data</code> <code>dict[str, Any] | None</code> <p>Request body data.</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Additional headers.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Parsed JSON response.</p> <p>Raises:</p> Type Description <code>SessionError</code> <p>If session not active.</p> <code>APIError</code> <p>If request fails.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def call_api(\n    self,\n    endpoint: str,\n    method: str = \"GET\",\n    data: dict[str, Any] | None = None,\n    headers: dict[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Make a generic API call via the browser context.\n\n    Args:\n        endpoint: API endpoint URL.\n        method: HTTP method.\n        data: Request body data.\n        headers: Additional headers.\n\n    Returns:\n        Parsed JSON response.\n\n    Raises:\n        SessionError: If session not active.\n        APIError: If request fails.\n    \"\"\"\n    if self._page is None:\n        raise SessionError(\"Browser session not active\")\n\n    attempt_refresh = self.auto_refresh\n    for attempt in range(2 if attempt_refresh else 1):\n        try:\n            await self._check_auth_validity()\n            await self._ensure_csrf_token()\n\n            sanitized_headers = _sanitize_headers(headers or {})\n            _log_if_debug(\n                logger.debug,\n                f\"API request {method} {endpoint} headers={sanitized_headers} data={data}\",\n            )\n\n            response = await self._page.evaluate(\n                \"\"\"\n                async (args) =&gt; {\n                    const options = {\n                        method: args.method,\n                        headers: args.headers || {},\n                        credentials: 'include',\n                    };\n\n                    if (args.data) {\n                        options.body = JSON.stringify(args.data);\n                        options.headers['Content-Type'] = 'application/json';\n                    }\n\n                    const response = await fetch(args.endpoint, options);\n\n                    return {\n                        ok: response.ok,\n                        status: response.status,\n                        json: await response.json().catch(() =&gt; null),\n                        text: await response.text().catch(() =&gt; ''),\n                    };\n                }\n                \"\"\",\n                {\n                    \"endpoint\": endpoint,\n                    \"method\": method,\n                    \"data\": data,\n                    \"headers\": headers or {},\n                },\n            )\n\n            response_text = str(response.get(\"text\", \"\"))\n            _log_if_debug(\n                logger.debug,\n                f\"API response {endpoint}: {_sanitize_text(response_text)}\",\n            )\n\n            if self._response_indicates_auth_failure(response_text):\n                raise AuthenticationError(\"Authentication expired during API call.\")\n\n            if not response.get(\"ok\"):\n                raise APIError(\n                    \"API request failed\",\n                    status_code=response.get(\"status\"),\n                    response_body=response_text,\n                )\n\n            return response.get(\"json\") or {}\n\n        except AuthenticationError:\n            if attempt_refresh and attempt == 0:\n                logger.info(\"Authentication failed; attempting auto-refresh.\")\n                await self._refresh_session()\n                continue\n            raise\n        except APIError:\n            raise\n        except Exception as e:\n            raise APIError(f\"API call failed: {e}\") from e\n\n    raise APIError(\"API call failed after refresh\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.call_api_raw","title":"<code>call_api_raw(endpoint, method='GET', body=None, headers=None, timeout_ms=None)</code>  <code>async</code>","text":"<p>Make a raw API call via the browser context.</p> <p>Parameters:</p> Name Type Description Default <code>endpoint</code> <code>str</code> <p>API endpoint URL.</p> required <code>method</code> <code>str</code> <p>HTTP method.</p> <code>'GET'</code> <code>body</code> <code>str | None</code> <p>Request body string.</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Additional headers.</p> <code>None</code> <code>timeout_ms</code> <code>int | None</code> <p>Timeout in milliseconds for streaming endpoints.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Raw response text.</p> <p>Raises:</p> Type Description <code>SessionError</code> <p>If session not active.</p> <code>APIError</code> <p>If request fails.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def call_api_raw(\n    self,\n    endpoint: str,\n    method: str = \"GET\",\n    body: str | None = None,\n    headers: dict[str, str] | None = None,\n    timeout_ms: int | None = None,\n) -&gt; str:\n    \"\"\"\n    Make a raw API call via the browser context.\n\n    Args:\n        endpoint: API endpoint URL.\n        method: HTTP method.\n        body: Request body string.\n        headers: Additional headers.\n        timeout_ms: Timeout in milliseconds for streaming endpoints.\n\n    Returns:\n        Raw response text.\n\n    Raises:\n        SessionError: If session not active.\n        APIError: If request fails.\n    \"\"\"\n    if self._page is None:\n        raise SessionError(\"Browser session not active\")\n\n    attempt_refresh = self.auto_refresh\n    for attempt in range(2 if attempt_refresh else 1):\n        try:\n            await self._check_auth_validity()\n            await self._ensure_csrf_token()\n\n            sanitized_headers = _sanitize_headers(headers or {})\n            _log_if_debug(\n                logger.debug,\n                f\"API raw request {method} {endpoint} headers={sanitized_headers} body={_sanitize_text(body or '')}\",\n            )\n\n            response = await self._page.evaluate(\n                \"\"\"\n                async (args) =&gt; {\n                    const controller = new AbortController();\n                    const timeoutId = args.timeoutMs\n                        ? setTimeout(() =&gt; controller.abort(), args.timeoutMs)\n                        : null;\n\n                    const options = {\n                        method: args.method,\n                        headers: args.headers || {},\n                        credentials: 'include',\n                        signal: controller.signal,\n                    };\n\n                    if (args.body) {\n                        options.body = args.body;\n                    }\n\n                    let response;\n                    try {\n                        response = await fetch(args.endpoint, options);\n                    } catch (error) {\n                        return {\n                            ok: false,\n                            status: 0,\n                            statusText: error &amp;&amp; error.name ? error.name : 'FetchError',\n                            text: '',\n                        };\n                    } finally {\n                        if (timeoutId) {\n                            clearTimeout(timeoutId);\n                        }\n                    }\n\n                    return {\n                        ok: response.ok,\n                        status: response.status,\n                        statusText: response.statusText,\n                        text: await response.text().catch(() =&gt; ''),\n                    };\n                }\n                \"\"\",\n                {\n                    \"endpoint\": endpoint,\n                    \"method\": method,\n                    \"body\": body,\n                    \"headers\": headers or {},\n                    \"timeoutMs\": timeout_ms or self.streaming_timeout,\n                },\n            )\n\n            response_text = str(response.get(\"text\", \"\"))\n            _log_if_debug(\n                logger.debug,\n                f\"API raw response {endpoint}: {_sanitize_text(response_text)}\",\n            )\n\n            if self._response_indicates_auth_failure(response_text):\n                raise AuthenticationError(\"Authentication expired during API call.\")\n\n            if not response.get(\"ok\"):\n                raise APIError(\n                    f\"API request failed: {response.get('statusText')}\",\n                    status_code=response.get(\"status\"),\n                    response_body=response_text,\n                )\n\n            return response_text\n\n        except AuthenticationError:\n            if attempt_refresh and attempt == 0:\n                logger.info(\"Authentication failed; attempting auto-refresh.\")\n                await self._refresh_session()\n                continue\n            raise\n        except APIError:\n            raise\n        except Exception as e:\n            raise APIError(f\"API call failed: {e}\") from e\n\n    raise APIError(\"API call failed after refresh\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.ensure_csrf_token","title":"<code>ensure_csrf_token()</code>  <code>async</code>","text":"<p>Ensure the CSRF token is refreshed if cache expired.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def ensure_csrf_token(self) -&gt; None:\n    \"\"\"Ensure the CSRF token is refreshed if cache expired.\"\"\"\n    await self._ensure_csrf_token()\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.BrowserSession.parse_streaming_response","title":"<code>parse_streaming_response(response_text)</code>","text":"<p>Parse streaming responses into JSON chunks.</p> <p>Handles partial/incomplete chunks gracefully by buffering lines.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>def parse_streaming_response(self, response_text: str) -&gt; list[Any]:\n    \"\"\"\n    Parse streaming responses into JSON chunks.\n\n    Handles partial/incomplete chunks gracefully by buffering lines.\n    \"\"\"\n    if not response_text:\n        return []\n\n    if response_text.startswith(\")]}'\"):\n        response_text = response_text[4:]\n\n    lines = [line.strip() for line in response_text.split(\"\\n\") if line.strip()]\n    chunks: list[Any] = []\n    buffer = \"\"\n\n    for line in lines:\n        if line.isdigit():\n            continue\n        buffer += line\n        try:\n            chunks.append(json.loads(buffer))\n            buffer = \"\"\n        except json.JSONDecodeError as e:\n            if e.msg.lower().startswith(\"unterminated\") or e.msg.lower().startswith(\n                \"expecting\"\n            ):\n                continue\n            logger.debug(\n                \"Skipping malformed streaming chunk: %s\", _sanitize_text(line[:200])\n            )\n            buffer = \"\"\n\n    if buffer:\n        logger.debug(\n            \"Dropped incomplete streaming chunk: %s\", _sanitize_text(buffer[:200])\n        )\n\n    return chunks\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.PersistentBrowserSession","title":"<code>pynotebooklm.session.PersistentBrowserSession</code>","text":"<p>               Bases: <code>BrowserSession</code></p> <p>Browser session that reuses a shared browser instance across contexts.</p> <p>This reduces startup time for repeated operations and supports concurrent contexts via a simple pool.</p> Source code in <code>src/pynotebooklm/session.py</code> <pre><code>class PersistentBrowserSession(BrowserSession):\n    \"\"\"\n    Browser session that reuses a shared browser instance across contexts.\n\n    This reduces startup time for repeated operations and supports\n    concurrent contexts via a simple pool.\n    \"\"\"\n\n    _pool: _BrowserPool | None = None\n    _pool_lock = asyncio.Lock()\n\n    def __init__(\n        self,\n        auth: AuthManager,\n        headless: bool = True,\n        timeout: int = 60000,\n        auto_refresh: bool = False,\n        block_resources: bool = True,\n        streaming_timeout: int = DEFAULT_STREAMING_TIMEOUT_MS,\n        csrf_cache_ttl: int = DEFAULT_CSRF_TTL_SECONDS,\n        wait_until: Literal[\n            \"commit\", \"domcontentloaded\", \"load\", \"networkidle\"\n        ] = \"load\",\n        max_contexts: int = 3,\n    ) -&gt; None:\n        super().__init__(\n            auth=auth,\n            headless=headless,\n            timeout=timeout,\n            auto_refresh=auto_refresh,\n            block_resources=block_resources,\n            streaming_timeout=streaming_timeout,\n            csrf_cache_ttl=csrf_cache_ttl,\n            wait_until=wait_until,\n        )\n        self.max_contexts = max_contexts\n        self._pool_ref: _BrowserPool | None = None\n\n    @classmethod\n    async def _get_pool(cls, session: \"PersistentBrowserSession\") -&gt; _BrowserPool:\n        async with cls._pool_lock:\n            if cls._pool is None:\n                cls._pool = _BrowserPool(\n                    headless=session.headless,\n                    launch_args=session._launch_args(),\n                    context_options=session._context_options(),\n                    block_resources=session.block_resources,\n                    max_contexts=session.max_contexts,\n                )\n            return cls._pool\n\n    @classmethod\n    async def shutdown_pool(cls) -&gt; None:\n        if cls._pool is None:\n            return\n        await cls._pool.shutdown()\n        cls._pool = None\n\n    async def __aenter__(self) -&gt; \"PersistentBrowserSession\":\n        if not self.auth.is_authenticated():\n            raise AuthenticationError(\n                \"Not authenticated. Please run 'pynotebooklm auth login' first.\"\n            )\n\n        try:\n            pool = await self._get_pool(self)\n            self._pool_ref = pool\n            self._context = await pool.acquire_context(self._apply_resource_blocking)\n            self._browser = pool.browser\n            self._playwright = pool.playwright\n\n            try:\n                await self._context.clear_cookies()\n            except Exception:\n                pass\n            await self._context.add_cookies(self.auth.get_cookies())  # type: ignore[arg-type]\n\n            self._page = await self._context.new_page()\n            self._page.set_default_timeout(self.timeout)\n\n            logger.debug(\"Navigating to NotebookLM (persistent session)...\")\n            await self._page.goto(NOTEBOOKLM_URL, wait_until=self.wait_until)\n\n            if not self._is_authenticated_page():\n                raise AuthenticationError(\n                    \"Cookies expired or invalid. Please login again.\"\n                )\n\n            self._csrf_token = await self._extract_csrf_token()\n            self._csrf_cached_at = datetime.now()\n            logger.info(\n                \"Persistent browser session ready (CSRF token: %s)\",\n                bool(self._csrf_token),\n            )\n\n            return self\n\n        except AuthenticationError:\n            await self._cleanup()\n            raise\n        except Exception as e:\n            await self._cleanup()\n            logger.error(\"Failed to start persistent browser session: %s\", e)\n            raise BrowserError(\n                f\"Failed to start persistent browser session: {e}\"\n            ) from e\n\n    async def _cleanup(self) -&gt; None:\n        if self._page:\n            try:\n                await self._page.close()\n            except Exception:\n                pass\n            self._page = None\n\n        if self._context and self._pool_ref:\n            try:\n                await self._pool_ref.release_context(self._context)\n            except Exception:\n                pass\n            self._context = None\n        self._pool_ref = None\n\n        self._csrf_token = None\n        self._csrf_cached_at = None\n\n        logger.debug(\"Persistent browser session cleaned up\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.PersistentBrowserSession.__init__","title":"<code>__init__(auth, headless=True, timeout=60000, auto_refresh=False, block_resources=True, streaming_timeout=DEFAULT_STREAMING_TIMEOUT_MS, csrf_cache_ttl=DEFAULT_CSRF_TTL_SECONDS, wait_until='load', max_contexts=3)</code>","text":"Source code in <code>src/pynotebooklm/session.py</code> <pre><code>def __init__(\n    self,\n    auth: AuthManager,\n    headless: bool = True,\n    timeout: int = 60000,\n    auto_refresh: bool = False,\n    block_resources: bool = True,\n    streaming_timeout: int = DEFAULT_STREAMING_TIMEOUT_MS,\n    csrf_cache_ttl: int = DEFAULT_CSRF_TTL_SECONDS,\n    wait_until: Literal[\n        \"commit\", \"domcontentloaded\", \"load\", \"networkidle\"\n    ] = \"load\",\n    max_contexts: int = 3,\n) -&gt; None:\n    super().__init__(\n        auth=auth,\n        headless=headless,\n        timeout=timeout,\n        auto_refresh=auto_refresh,\n        block_resources=block_resources,\n        streaming_timeout=streaming_timeout,\n        csrf_cache_ttl=csrf_cache_ttl,\n        wait_until=wait_until,\n    )\n    self.max_contexts = max_contexts\n    self._pool_ref: _BrowserPool | None = None\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.PersistentBrowserSession.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"Source code in <code>src/pynotebooklm/session.py</code> <pre><code>async def __aenter__(self) -&gt; \"PersistentBrowserSession\":\n    if not self.auth.is_authenticated():\n        raise AuthenticationError(\n            \"Not authenticated. Please run 'pynotebooklm auth login' first.\"\n        )\n\n    try:\n        pool = await self._get_pool(self)\n        self._pool_ref = pool\n        self._context = await pool.acquire_context(self._apply_resource_blocking)\n        self._browser = pool.browser\n        self._playwright = pool.playwright\n\n        try:\n            await self._context.clear_cookies()\n        except Exception:\n            pass\n        await self._context.add_cookies(self.auth.get_cookies())  # type: ignore[arg-type]\n\n        self._page = await self._context.new_page()\n        self._page.set_default_timeout(self.timeout)\n\n        logger.debug(\"Navigating to NotebookLM (persistent session)...\")\n        await self._page.goto(NOTEBOOKLM_URL, wait_until=self.wait_until)\n\n        if not self._is_authenticated_page():\n            raise AuthenticationError(\n                \"Cookies expired or invalid. Please login again.\"\n            )\n\n        self._csrf_token = await self._extract_csrf_token()\n        self._csrf_cached_at = datetime.now()\n        logger.info(\n            \"Persistent browser session ready (CSRF token: %s)\",\n            bool(self._csrf_token),\n        )\n\n        return self\n\n    except AuthenticationError:\n        await self._cleanup()\n        raise\n    except Exception as e:\n        await self._cleanup()\n        logger.error(\"Failed to start persistent browser session: %s\", e)\n        raise BrowserError(\n            f\"Failed to start persistent browser session: {e}\"\n        ) from e\n</code></pre>"},{"location":"api_reference/#pynotebooklm.session.PersistentBrowserSession.shutdown_pool","title":"<code>shutdown_pool()</code>  <code>async</code> <code>classmethod</code>","text":"Source code in <code>src/pynotebooklm/session.py</code> <pre><code>@classmethod\nasync def shutdown_pool(cls) -&gt; None:\n    if cls._pool is None:\n        return\n    await cls._pool.shutdown()\n    cls._pool = None\n</code></pre>"},{"location":"api_reference/#authentication","title":"Authentication","text":""},{"location":"api_reference/#pynotebooklm.auth.AuthManager","title":"<code>pynotebooklm.auth.AuthManager</code>","text":"<p>Manages authentication state for NotebookLM.</p> <p>This class handles: - Interactive browser-based login - Cookie extraction and persistence - Authentication state validation - Cookie refresh when needed</p> Example <p>auth = AuthManager() if not auth.is_authenticated(): ...     await auth.login() cookies = auth.get_cookies()</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>class AuthManager:\n    \"\"\"\n    Manages authentication state for NotebookLM.\n\n    This class handles:\n    - Interactive browser-based login\n    - Cookie extraction and persistence\n    - Authentication state validation\n    - Cookie refresh when needed\n\n    Example:\n        &gt;&gt;&gt; auth = AuthManager()\n        &gt;&gt;&gt; if not auth.is_authenticated():\n        ...     await auth.login()\n        &gt;&gt;&gt; cookies = auth.get_cookies()\n    \"\"\"\n\n    def __init__(\n        self,\n        auth_path: Path | str | None = None,\n        headless: bool = False,\n        refresh_threshold: int | timedelta = COOKIE_VALIDITY_DAYS,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the authentication manager.\n\n        Args:\n            auth_path: Path to store authentication state.\n                      Defaults to ~/.pynotebooklm/auth.json\n            headless: Whether to run browser in headless mode for login.\n                     Set to False for interactive login (recommended).\n            refresh_threshold: Threshold in days (or timedelta) for expiration warnings.\n        \"\"\"\n        self.auth_path = Path(auth_path) if auth_path else DEFAULT_AUTH_FILE\n        self.headless = headless\n        self.refresh_threshold = self._normalize_refresh_threshold(refresh_threshold)\n        self._auth_state: AuthState | None = None\n        self._warned_expiration = False\n\n        # Ensure config directory exists\n        self.auth_path.parent.mkdir(parents=True, exist_ok=True)\n\n        # Try to load existing auth state\n        self._load_cookies()\n\n    @staticmethod\n    def _normalize_refresh_threshold(\n        refresh_threshold: int | timedelta,\n    ) -&gt; timedelta:\n        \"\"\"Normalize refresh threshold to a timedelta.\"\"\"\n        if isinstance(refresh_threshold, timedelta):\n            return refresh_threshold\n        return timedelta(days=refresh_threshold)\n\n    def _load_cookies(self) -&gt; None:\n        \"\"\"Load authentication state from file.\"\"\"\n        if not self.auth_path.exists():\n            logger.debug(\"No existing auth file found at %s\", self.auth_path)\n            self._auth_state = None\n            return\n\n        try:\n            data = json.loads(self.auth_path.read_text())\n            self._auth_state = AuthState.model_validate(data)\n            logger.info(\n                \"Loaded auth state from %s (authenticated: %s)\",\n                self.auth_path,\n                self._auth_state.is_valid(),\n            )\n        except (json.JSONDecodeError, ValueError) as e:\n            logger.warning(\"Failed to load auth state: %s\", e)\n            self._auth_state = None\n\n    def _save_cookies(self) -&gt; None:\n        \"\"\"Persist authentication state to file.\"\"\"\n        if self._auth_state is None:\n            return\n\n        try:\n            self.auth_path.write_text(self._auth_state.model_dump_json(indent=2))\n            logger.info(\"Saved auth state to %s\", self.auth_path)\n        except OSError as e:\n            logger.error(\"Failed to save auth state: %s\", e)\n            raise AuthenticationError(f\"Failed to save authentication: {e}\") from e\n\n    def is_authenticated(self) -&gt; bool:\n        \"\"\"\n        Check if current authentication state is valid.\n\n        Returns:\n            True if authenticated with valid cookies, False otherwise.\n        \"\"\"\n        if self._auth_state is None:\n            return False\n        is_valid = self._auth_state.is_valid()\n        if is_valid:\n            self._log_expiration_warning()\n        return is_valid\n\n    def is_expired(self) -&gt; bool:\n        \"\"\"\n        Check whether authentication cookies are expired.\n\n        Returns:\n            True if expired, False otherwise.\n        \"\"\"\n        if self._auth_state is None:\n            return True\n        if self._auth_state.expires_at is None:\n            return False\n        return datetime.now() &gt; self._auth_state.expires_at\n\n    def _log_expiration_warning(self) -&gt; None:\n        \"\"\"Warn once if cookies are close to expiration.\"\"\"\n        if self._warned_expiration or self._auth_state is None:\n            return\n        expires_at = self._auth_state.expires_at\n        if not expires_at:\n            return\n        if expires_at - datetime.now() &lt;= self.refresh_threshold:\n            logger.warning(\n                \"Authentication cookies are nearing expiration (expires_at=%s)\",\n                expires_at.isoformat(),\n            )\n            self._warned_expiration = True\n\n    def get_cookies(self) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Get cookies in Playwright-compatible format.\n\n        Returns:\n            List of cookie dictionaries for Playwright context.\n\n        Raises:\n            AuthenticationError: If not authenticated.\n        \"\"\"\n        if not self.is_authenticated():\n            raise AuthenticationError(\"Not authenticated. Please login first.\")\n\n        assert self._auth_state is not None\n        return [\n            {\n                \"name\": c.name,\n                \"value\": c.value,\n                \"domain\": c.domain,\n                \"path\": c.path,\n                \"expires\": c.expires,\n                \"httpOnly\": c.http_only,\n                \"secure\": c.secure,\n                \"sameSite\": c.same_site,\n            }\n            for c in self._auth_state.cookies\n        ]\n\n    def get_csrf_token(self) -&gt; str | None:\n        \"\"\"\n        Get the CSRF token (SNlM0e) if available.\n\n        Returns:\n            CSRF token string or None if not available.\n        \"\"\"\n        if self._auth_state is None:\n            return None\n        return self._auth_state.csrf_token\n\n    async def login(self, timeout: int = 300) -&gt; None:\n        \"\"\"\n        Perform interactive browser-based login to NotebookLM.\n\n        Opens a browser window for the user to login with their Google account.\n        Waits for successful authentication and extracts cookies.\n\n        Args:\n            timeout: Maximum time to wait for login in seconds.\n\n        Raises:\n            AuthenticationError: If login fails or times out.\n            BrowserError: If browser automation fails.\n        \"\"\"\n        logger.info(\"Starting interactive login flow...\")\n\n        try:\n            async with async_playwright() as p:\n                # Launch browser\n                browser = await p.chromium.launch(\n                    headless=self.headless,\n                    args=[\n                        \"--no-sandbox\",\n                        \"--disable-setuid-sandbox\",\n                        \"--disable-dev-shm-usage\",\n                    ],\n                )\n\n                try:\n                    context = await browser.new_context(\n                        viewport={\"width\": 1280, \"height\": 800},\n                        user_agent=(\n                            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n                            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                            \"Chrome/120.0.0.0 Safari/537.36\"\n                        ),\n                    )\n\n                    page = await context.new_page()\n\n                    # Navigate to NotebookLM\n                    await page.goto(NOTEBOOKLM_URL, wait_until=\"load\")\n\n                    # Wait for user to complete login\n                    await self._wait_for_authentication(page, browser, timeout)\n\n                    # Extract cookies (Playwright returns TypedDict, cast for compatibility)\n                    cookies = await context.cookies()\n                    await self._store_cookies(cast(list[dict[str, Any]], cookies), page)\n\n                    logger.info(\"Login successful!\")\n\n                finally:\n                    await browser.close()\n\n        except Exception as e:\n            if isinstance(e, AuthenticationError | BrowserError):\n                raise\n            logger.error(\"Login failed: %s\", e)\n            raise BrowserError(f\"Browser automation failed: {e}\") from e\n\n    async def _wait_for_authentication(\n        self, page: Page, browser: Browser, timeout: int\n    ) -&gt; None:\n        \"\"\"\n        Wait for the user to complete authentication.\n\n        Args:\n            page: Playwright page object.\n            browser: Playwright browser object.\n            timeout: Maximum wait time in seconds.\n\n        Raises:\n            AuthenticationError: If authentication times out or fails.\n        \"\"\"\n        logger.info(\n            \"Please login with your Google account in the browser window. \"\n            \"You have %d seconds to complete login.\",\n            timeout,\n        )\n\n        start_time = datetime.now()\n        check_interval = 2  # seconds\n\n        while (datetime.now() - start_time).seconds &lt; timeout:\n            try:\n                # Check if browser or page was closed\n                if not browser.is_connected() or page.is_closed():\n                    raise AuthenticationError(\n                        \"Browser or page was closed before login completed\"\n                    )\n\n                # Check if we're on NotebookLM main page (indicates successful login)\n                current_url = page.url\n                if (\n                    NOTEBOOKLM_URL in current_url\n                    and \"accounts.google.com\" not in current_url\n                ):\n                    # Verify we have the essential cookies\n                    context = page.context\n                    cookies = await context.cookies()\n                    cookie_names = {c[\"name\"] for c in cookies}\n\n                    if ESSENTIAL_COOKIES.issubset(cookie_names):\n                        logger.info(\"Authentication detected!\")\n                        return\n\n                await page.wait_for_timeout(check_interval * 1000)\n            except PlaywrightError as e:\n                # Catch \"Target closed\" errors which occur if user closes browser/tab\n                if \"closed\" in str(e).lower():\n                    raise AuthenticationError(\n                        \"Browser or page was closed before login completed\"\n                    ) from e\n                raise\n\n        raise AuthenticationError(\n            f\"Login timed out after {timeout} seconds. Please try again.\"\n        )\n\n    async def _store_cookies(self, cookies: list[dict[str, Any]], page: Page) -&gt; None:\n        \"\"\"\n        Store extracted cookies and CSRF token.\n\n        Args:\n            cookies: List of cookie dictionaries from Playwright.\n            page: Playwright page for CSRF token extraction.\n        \"\"\"\n        # Convert to Cookie models\n        cookie_models = []\n        for c in cookies:\n            # Filter to essential and related cookies\n            if c.get(\"domain\", \"\").endswith(\"google.com\"):\n                cookie_models.append(\n                    Cookie(\n                        name=c[\"name\"],\n                        value=c[\"value\"],\n                        domain=c[\"domain\"],\n                        path=c.get(\"path\", \"/\"),\n                        expires=c.get(\"expires\"),\n                        http_only=c.get(\"httpOnly\", False),\n                        secure=c.get(\"secure\", False),\n                        same_site=c.get(\"sameSite\", \"Lax\"),\n                    )\n                )\n\n        # Try to extract CSRF token from page\n        csrf_token = await self._extract_csrf_token(page)\n\n        # Calculate expiration\n        now = datetime.now()\n        expires_at = now + timedelta(days=COOKIE_VALIDITY_DAYS)\n\n        # Create and save auth state\n        self._auth_state = AuthState(\n            cookies=cookie_models,\n            csrf_token=csrf_token,\n            authenticated_at=now,\n            expires_at=expires_at,\n        )\n\n        self._save_cookies()\n        logger.info(\n            \"Stored %d cookies, expires at %s\",\n            len(cookie_models),\n            expires_at.isoformat(),\n        )\n\n    async def _extract_csrf_token(self, page: Page) -&gt; str | None:\n        \"\"\"\n        Extract CSRF token (SNlM0e) from page HTML.\n\n        Args:\n            page: Playwright page object.\n\n        Returns:\n            CSRF token string or None if not found.\n        \"\"\"\n        try:\n            # Try to find SNlM0e token in page scripts\n            token = await page.evaluate(\n                \"\"\"\n                () =&gt; {\n                    const scripts = document.querySelectorAll('script');\n                    for (const script of scripts) {\n                        const match = script.textContent?.match(/SNlM0e\":\"([^\"]+)/);\n                        if (match) return match[1];\n                    }\n                    return null;\n                }\n                \"\"\"\n            )\n            if token:\n                logger.debug(\"Extracted CSRF token\")\n            return cast(str | None, token)\n        except Exception as e:\n            logger.warning(\"Failed to extract CSRF token: %s\", e)\n            return None\n\n    async def refresh(self) -&gt; None:\n        \"\"\"\n        Refresh authentication by re-extracting cookies.\n\n        Opens browser, navigates to NotebookLM (using existing cookies),\n        and re-extracts fresh cookies.\n\n        Raises:\n            AuthenticationError: If refresh fails.\n        \"\"\"\n        if not self.is_authenticated():\n            # No existing auth, need full login\n            await self.login()\n            return\n\n        logger.info(\"Refreshing authentication...\")\n\n        try:\n            async with async_playwright() as p:\n                browser = await p.chromium.launch(\n                    headless=True,\n                    args=[\"--no-sandbox\", \"--disable-setuid-sandbox\"],\n                )\n\n                try:\n                    context = await browser.new_context()\n                    # Playwright expects SetCookieParam which matches our dict format\n                    await context.add_cookies(self.get_cookies())  # type: ignore[arg-type]\n\n                    page = await context.new_page()\n                    await page.goto(NOTEBOOKLM_URL, wait_until=\"load\")\n\n                    # Check if still authenticated\n                    current_url = page.url\n                    if \"accounts.google.com\" in current_url:\n                        # Cookies expired, need full login\n                        logger.warning(\"Cookies expired, full login required\")\n                        await browser.close()\n                        await self.login()\n                        return\n\n                    # Re-extract cookies (cast for type compatibility)\n                    cookies = await context.cookies()\n                    await self._store_cookies(cast(list[dict[str, Any]], cookies), page)\n                    logger.info(\"Authentication refreshed successfully\")\n\n                finally:\n                    await browser.close()\n\n        except Exception as e:\n            logger.error(\"Refresh failed: %s\", e)\n            raise AuthenticationError(f\"Failed to refresh authentication: {e}\") from e\n\n    def logout(self) -&gt; None:\n        \"\"\"\n        Clear authentication state.\n\n        Removes stored cookies and resets auth state.\n        \"\"\"\n        self._auth_state = None\n        if self.auth_path.exists():\n            self.auth_path.unlink()\n            logger.info(\"Removed auth file: %s\", self.auth_path)\n        logger.info(\"Logged out successfully\")\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.AuthManager.login","title":"<code>login(timeout=300)</code>  <code>async</code>","text":"<p>Perform interactive browser-based login to NotebookLM.</p> <p>Opens a browser window for the user to login with their Google account. Waits for successful authentication and extracts cookies.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Maximum time to wait for login in seconds.</p> <code>300</code> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If login fails or times out.</p> <code>BrowserError</code> <p>If browser automation fails.</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>async def login(self, timeout: int = 300) -&gt; None:\n    \"\"\"\n    Perform interactive browser-based login to NotebookLM.\n\n    Opens a browser window for the user to login with their Google account.\n    Waits for successful authentication and extracts cookies.\n\n    Args:\n        timeout: Maximum time to wait for login in seconds.\n\n    Raises:\n        AuthenticationError: If login fails or times out.\n        BrowserError: If browser automation fails.\n    \"\"\"\n    logger.info(\"Starting interactive login flow...\")\n\n    try:\n        async with async_playwright() as p:\n            # Launch browser\n            browser = await p.chromium.launch(\n                headless=self.headless,\n                args=[\n                    \"--no-sandbox\",\n                    \"--disable-setuid-sandbox\",\n                    \"--disable-dev-shm-usage\",\n                ],\n            )\n\n            try:\n                context = await browser.new_context(\n                    viewport={\"width\": 1280, \"height\": 800},\n                    user_agent=(\n                        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n                        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                        \"Chrome/120.0.0.0 Safari/537.36\"\n                    ),\n                )\n\n                page = await context.new_page()\n\n                # Navigate to NotebookLM\n                await page.goto(NOTEBOOKLM_URL, wait_until=\"load\")\n\n                # Wait for user to complete login\n                await self._wait_for_authentication(page, browser, timeout)\n\n                # Extract cookies (Playwright returns TypedDict, cast for compatibility)\n                cookies = await context.cookies()\n                await self._store_cookies(cast(list[dict[str, Any]], cookies), page)\n\n                logger.info(\"Login successful!\")\n\n            finally:\n                await browser.close()\n\n    except Exception as e:\n        if isinstance(e, AuthenticationError | BrowserError):\n            raise\n        logger.error(\"Login failed: %s\", e)\n        raise BrowserError(f\"Browser automation failed: {e}\") from e\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.AuthManager.is_authenticated","title":"<code>is_authenticated()</code>","text":"<p>Check if current authentication state is valid.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if authenticated with valid cookies, False otherwise.</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>def is_authenticated(self) -&gt; bool:\n    \"\"\"\n    Check if current authentication state is valid.\n\n    Returns:\n        True if authenticated with valid cookies, False otherwise.\n    \"\"\"\n    if self._auth_state is None:\n        return False\n    is_valid = self._auth_state.is_valid()\n    if is_valid:\n        self._log_expiration_warning()\n    return is_valid\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.AuthManager.is_expired","title":"<code>is_expired()</code>","text":"<p>Check whether authentication cookies are expired.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if expired, False otherwise.</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>def is_expired(self) -&gt; bool:\n    \"\"\"\n    Check whether authentication cookies are expired.\n\n    Returns:\n        True if expired, False otherwise.\n    \"\"\"\n    if self._auth_state is None:\n        return True\n    if self._auth_state.expires_at is None:\n        return False\n    return datetime.now() &gt; self._auth_state.expires_at\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.AuthManager.get_cookies","title":"<code>get_cookies()</code>","text":"<p>Get cookies in Playwright-compatible format.</p> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of cookie dictionaries for Playwright context.</p> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If not authenticated.</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>def get_cookies(self) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Get cookies in Playwright-compatible format.\n\n    Returns:\n        List of cookie dictionaries for Playwright context.\n\n    Raises:\n        AuthenticationError: If not authenticated.\n    \"\"\"\n    if not self.is_authenticated():\n        raise AuthenticationError(\"Not authenticated. Please login first.\")\n\n    assert self._auth_state is not None\n    return [\n        {\n            \"name\": c.name,\n            \"value\": c.value,\n            \"domain\": c.domain,\n            \"path\": c.path,\n            \"expires\": c.expires,\n            \"httpOnly\": c.http_only,\n            \"secure\": c.secure,\n            \"sameSite\": c.same_site,\n        }\n        for c in self._auth_state.cookies\n    ]\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.AuthManager.refresh","title":"<code>refresh()</code>  <code>async</code>","text":"<p>Refresh authentication by re-extracting cookies.</p> <p>Opens browser, navigates to NotebookLM (using existing cookies), and re-extracts fresh cookies.</p> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If refresh fails.</p> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>async def refresh(self) -&gt; None:\n    \"\"\"\n    Refresh authentication by re-extracting cookies.\n\n    Opens browser, navigates to NotebookLM (using existing cookies),\n    and re-extracts fresh cookies.\n\n    Raises:\n        AuthenticationError: If refresh fails.\n    \"\"\"\n    if not self.is_authenticated():\n        # No existing auth, need full login\n        await self.login()\n        return\n\n    logger.info(\"Refreshing authentication...\")\n\n    try:\n        async with async_playwright() as p:\n            browser = await p.chromium.launch(\n                headless=True,\n                args=[\"--no-sandbox\", \"--disable-setuid-sandbox\"],\n            )\n\n            try:\n                context = await browser.new_context()\n                # Playwright expects SetCookieParam which matches our dict format\n                await context.add_cookies(self.get_cookies())  # type: ignore[arg-type]\n\n                page = await context.new_page()\n                await page.goto(NOTEBOOKLM_URL, wait_until=\"load\")\n\n                # Check if still authenticated\n                current_url = page.url\n                if \"accounts.google.com\" in current_url:\n                    # Cookies expired, need full login\n                    logger.warning(\"Cookies expired, full login required\")\n                    await browser.close()\n                    await self.login()\n                    return\n\n                # Re-extract cookies (cast for type compatibility)\n                cookies = await context.cookies()\n                await self._store_cookies(cast(list[dict[str, Any]], cookies), page)\n                logger.info(\"Authentication refreshed successfully\")\n\n            finally:\n                await browser.close()\n\n    except Exception as e:\n        logger.error(\"Refresh failed: %s\", e)\n        raise AuthenticationError(f\"Failed to refresh authentication: {e}\") from e\n</code></pre>"},{"location":"api_reference/#pynotebooklm.auth.save_auth_tokens","title":"<code>pynotebooklm.auth.save_auth_tokens(cookies, csrf_token=None, auth_path=None)</code>","text":"<p>Manually save authentication tokens/cookies.</p> <p>Parameters:</p> Name Type Description Default <code>cookies</code> <code>str | list[dict[str, Any]]</code> <p>Either a cookie header string (\"SID=abc; HSID=def\")     or a list of cookie dictionaries (Playwright/Chrome format).</p> required <code>csrf_token</code> <code>str | None</code> <p>Optional CSRF token (SNlM0e).</p> <code>None</code> <code>auth_path</code> <code>Path | str | None</code> <p>Optional path to save the auth state.</p> <code>None</code> Source code in <code>src/pynotebooklm/auth.py</code> <pre><code>def save_auth_tokens(\n    cookies: str | list[dict[str, Any]],\n    csrf_token: str | None = None,\n    auth_path: Path | str | None = None,\n) -&gt; None:\n    \"\"\"\n    Manually save authentication tokens/cookies.\n\n    Args:\n        cookies: Either a cookie header string (\"SID=abc; HSID=def\")\n                or a list of cookie dictionaries (Playwright/Chrome format).\n        csrf_token: Optional CSRF token (SNlM0e).\n        auth_path: Optional path to save the auth state.\n    \"\"\"\n    auth = AuthManager(auth_path=auth_path)\n    cookie_models = []\n\n    if isinstance(cookies, str):\n        # Parse cookie header string\n        # format: name1=value1; name2=value2\n        pairs = cookies.split(\";\")\n        for pair in pairs:\n            if \"=\" not in pair:\n                continue\n            name, value = pair.strip().split(\"=\", 1)\n            cookie_models.append(\n                Cookie(\n                    name=name,\n                    value=value,\n                    domain=\".google.com\",\n                    path=\"/\",\n                    secure=True,\n                    http_only=True,\n                )\n            )\n    elif isinstance(cookies, list):\n        # Parse list of dicts\n        for c in cookies:\n            cookie_models.append(\n                Cookie(\n                    name=c[\"name\"],\n                    value=c[\"value\"],\n                    domain=c.get(\"domain\", \".google.com\"),\n                    path=c.get(\"path\", \"/\"),\n                    expires=c.get(\"expires\"),\n                    http_only=c.get(\"httpOnly\", False),\n                    secure=c.get(\"secure\", False),\n                    same_site=c.get(\"sameSite\", \"Lax\"),\n                )\n            )\n    else:\n        raise ValueError(\"cookies must be a string or a list of dictionaries\")\n\n    # Update state\n    now = datetime.now()\n    auth._auth_state = AuthState(\n        cookies=cookie_models,\n        csrf_token=csrf_token,\n        authenticated_at=now,\n        expires_at=now + timedelta(days=COOKIE_VALIDITY_DAYS),\n    )\n    auth._save_cookies()\n    logger.info(\"Manually saved %d tokens\", len(cookie_models))\n</code></pre>"},{"location":"api_reference/#usage-examples","title":"Usage Examples","text":"<p>For detailed usage examples of all APIs, see: - Examples Documentation - Comprehensive code walkthroughs - Advanced Usage - Retry strategies and optimization - FAQ - Common issues and solutions</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#architecture-design","title":"Architecture &amp; Design","text":""},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     User Applications                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Python API   \u2502  \u2502 CLI Tool     \u2502  \u2502 DeterminAgent Adapter\u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    pynotebooklm Library                        \u2502\n\u2502                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                   NotebookLMClient                       \u2502  \u2502\n\u2502  \u2502  (Main entry point - combines all managers)              \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 NotebookMgr  \u2502 \u2502 SourceMgr    \u2502 \u2502 ContentGenerator     \u2502    \u2502\n\u2502  \u2502 - create     \u2502 \u2502 - add_url    \u2502 \u2502 - audio_podcast      \u2502    \u2502\n\u2502  \u2502 - list       \u2502 \u2502 - add_youtube\u2502 \u2502 - video_overview     \u2502    \u2502\n\u2502  \u2502 - get        \u2502 \u2502 - add_drive  \u2502 \u2502 - infographic        \u2502    \u2502\n\u2502  \u2502 - rename     \u2502 \u2502 - add_text   \u2502 \u2502 - slide_deck         \u2502    \u2502\n\u2502  \u2502 - delete     \u2502 \u2502 - delete     \u2502 \u2502 - poll_status        \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502 Research     \u2502 \u2502 MindMapGen   \u2502 \u2502 StudyTools           \u2502    \u2502\n\u2502  \u2502 - query      \u2502 \u2502 - create     \u2502 \u2502 - flashcards         \u2502    \u2502\n\u2502  \u2502 - search_web \u2502 \u2502 - list       \u2502 \u2502 - quiz               \u2502    \u2502\n\u2502  \u2502 - import     \u2502 \u2502 - export_xml \u2502 \u2502 - briefing           \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                   Core Infrastructure                    \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n\u2502  \u2502  \u2502 AuthMgr    \u2502  \u2502 BrowserSession\u2502  \u2502 NotebookLMAPI   \u2502  \u2502  \u2502\n\u2502  \u2502  \u2502 - login    \u2502  \u2502 - context mgr \u2502  \u2502 - call_rpc      \u2502  \u2502  \u2502\n\u2502  \u2502  \u2502 - cookies  \u2502  \u2502 - refresh     \u2502  \u2502 - parse_response\u2502  \u2502  \u2502\n\u2502  \u2502  \u2502 - save     \u2502  \u2502 - failover    \u2502  \u2502 - handle_error  \u2502  \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Browser Layer                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Playwright/Chromium  \u2502  \u2502 ~/.pynotebooklm/                \u2502 \u2502\n\u2502  \u2502 - headless mode      \u2502  \u2502   \u251c\u2500\u2500 auth.json (cookies)       \u2502 \u2502\n\u2502  \u2502 - cookie injection   \u2502  \u2502   \u2514\u2500\u2500 chrome_profile/           \u2502 \u2502\n\u2502  \u2502 - page.evaluate()    \u2502  \u2502       \u2514\u2500\u2500 (session persistence) \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502 NotebookLM Web UI \u2502\n                  \u2502 (Google internal  \u2502\n                  \u2502  RPC endpoints)   \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":"Component Choice Rationale Python 3.10+ Match DeterminAgent requirements Browser Automation Playwright Python-native, auto-wait, headless performance Type Safety Pydantic v2 Runtime validation, JSON serialization Async asyncio Browser ops are async; modern Python HTTP httpx Async HTTP client Testing pytest + pytest-asyncio Standard, good async support Packaging Poetry Modern dependency management CLI Typer Easy CLI from type hints"},{"location":"architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>pynotebooklm/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 pynotebooklm/\n\u2502       \u251c\u2500\u2500 __init__.py           # Public API exports\n\u2502       \u251c\u2500\u2500 client.py             # NotebookLMClient (main entry point)\n\u2502       \u251c\u2500\u2500 auth.py               # AuthManager (cookie extraction/persistence)\n\u2502       \u251c\u2500\u2500 session.py            # BrowserSession (Playwright context manager)\n\u2502       \u251c\u2500\u2500 api.py                # NotebookLMAPI (low-level RPC wrapper)\n\u2502       \u251c\u2500\u2500 models.py             # Pydantic schemas\n\u2502       \u251c\u2500\u2500 exceptions.py         # Custom exceptions\n\u2502       \u251c\u2500\u2500 notebooks.py          # NotebookManager\n\u2502       \u251c\u2500\u2500 sources.py            # SourceManager\n\u2502       \u251c\u2500\u2500 content.py            # ContentGenerator\n\u2502       \u251c\u2500\u2500 research.py           # ResearchDiscovery\n\u2502       \u251c\u2500\u2500 mindmaps.py           # MindMapGenerator\n\u2502       \u251c\u2500\u2500 study.py              # Flashcards, quizzes, briefings\n\u2502       \u2514\u2500\u2500 cli.py                # CLI interface\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 unit/                     # Fast tests with mocks\n\u2502   \u251c\u2500\u2500 integration/              # Tests against real NotebookLM\n\u2502   \u2514\u2500\u2500 fixtures/                 # Mock responses\n\u251c\u2500\u2500 docs/                         # mkdocs documentation\n\u251c\u2500\u2500 examples/                     # Usage examples\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"architecture/#data-models-pydantic","title":"Data Models (Pydantic)","text":"<p>High-level representation of the core entities.</p> <pre><code>class Notebook(BaseModel):\n    id: str\n    name: str\n    created_at: datetime\n    sources: list[\"Source\"] = []\n\nclass Source(BaseModel):\n    id: str\n    type: Literal[\"url\", \"youtube\", \"drive\", \"text\"]\n    url: Optional[str] = None\n    title: str\n    status: Literal[\"processing\", \"ready\", \"failed\"]\n\nclass Artifact(BaseModel):\n    id: str\n    type: Literal[\"audio\", \"video\", \"infographic\", \"slides\", \"mindmap\", \"flashcards\", \"briefing\"]\n    status: Literal[\"generating\", \"ready\", \"failed\"]\n    url: Optional[str] = None\n    progress: float = 0.0\n\nclass ChatMessage(BaseModel):\n    role: Literal[\"user\", \"assistant\"]\n    content: str\n    citations: list[str] = []\n</code></pre>"},{"location":"architecture/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>class PyNotebookLMError(Exception):\n    \"\"\"Base exception\"\"\"\n\nclass AuthenticationError(PyNotebookLMError):\n    \"\"\"Cookie expired or invalid\"\"\"\n\nclass NotebookNotFoundError(PyNotebookLMError):\n    \"\"\"Notebook ID doesn't exist\"\"\"\n\nclass SourceError(PyNotebookLMError):\n    \"\"\"Source add/processing failed\"\"\"\n\nclass GenerationError(PyNotebookLMError):\n    \"\"\"Content generation failed\"\"\"\n\nclass GenerationTimeoutError(GenerationError):\n    \"\"\"Generation exceeded timeout\"\"\"\n\nclass RateLimitError(PyNotebookLMError):\n    \"\"\"Too many requests\"\"\"\n\nclass APIError(PyNotebookLMError):\n    \"\"\"Internal API returned error\"\"\"\n</code></pre>"},{"location":"competitor_analysis/","title":"Competitor Analysis: notebooklm-mcp","text":"<p>Repository: <code>PleasePrompto/notebooklm-mcp</code> (also linked to <code>jacob-bd</code>) Description: MCP Server for NotebookLM with \"31 tools\" (approx. 15 implemented tools). Analysis Date: 2026-01-10</p>"},{"location":"competitor_analysis/#executive-summary","title":"Executive Summary","text":"<p>The <code>notebooklm-mcp</code> project does not use internal RPC calls (like <code>wXbhsf</code> or <code>CCqFvf</code>) to control NotebookLM. Instead, it relies entirely on Browser Automation (Playwright) to interact with the NotebookLM web interface, primarily by typing into the chat box.</p> <p>For notebook management, it does not support creating or managing notebooks on the Google side programmatically. It uses a local JSON database (<code>library.json</code>) to track URLs of notebooks that the user manually creates and shares.</p>"},{"location":"competitor_analysis/#architecture","title":"Architecture","text":"<ol> <li> <p>Browser Session (<code>src/session/browser-session.ts</code>):</p> <ul> <li>Uses <code>patchright</code> (Playwright fork) to launch a Headless Chrome instance.</li> <li>Manages Google Authentication by saving/loading cookies and <code>sessionStorage</code>.</li> <li>Chat Interaction: Types queries into <code>textarea.query-box-input</code> (or <code>textarea[aria-label=\"Feld f\u00fcr Anfragen\"]</code>) and simulates \"human-like\" typing with delays and typos to avoid detection.</li> <li>Response Handling: Waits for the DOM to update with the new answer.</li> </ul> </li> <li> <p>Notebook Library (<code>src/library/notebook-library.ts</code>):</p> <ul> <li>A local wrapper around a <code>library.json</code> file.</li> <li>Stores metadata: <code>id</code>, <code>url</code>, <code>name</code>, <code>description</code>, <code>topics</code>.</li> <li>Crucial Limitation: The <code>add_notebook</code> tool only adds an entry to this local JSON file. It requires the user to provide an existing NotebookLM URL. It cannot create new notebooks on Google.</li> </ul> </li> <li> <p>Tools Implementation (<code>src/tools/handlers.ts</code>):</p> <ul> <li><code>ask_question</code>: Navigates to the stored URL and automates the chat UI.</li> <li><code>notebook_create</code> (etc): Not implemented. The \"31 tools\" likely refers to the granular conversational steps or is a marketing claim. The actual codebase implements ~15 MCP tools, mostly for local library management.</li> </ul> </li> </ol>"},{"location":"competitor_analysis/#implication-for-pynotebooklm","title":"Implication for PyNotebookLM","text":"<p>We cannot copy RPC definitions from this project because it doesn't use them.</p>"},{"location":"competitor_analysis/#options-for-pynotebooklm","title":"Options for PyNotebookLM:","text":"<ol> <li> <p>Continue Reverse Engineering RPCs:</p> <ul> <li>We have identified some RPC IDs (<code>wXbhsf</code>, etc.) in our own docs. We need to verify and implement these ourselves.</li> <li>This is harder but much faster and more robust than UI automation.</li> </ul> </li> <li> <p>Fallback to UI Automation:</p> <ul> <li>For features where RPCs are elusive (e.g., complex chat interactions), we can adopt the competitor's strategy of typing into the chat box.</li> <li>Reference <code>src/session/browser-session.ts</code> in the competitor repo for robust selectors and \"stealth\" strategies (random delays, error detection).</li> </ul> </li> </ol>"},{"location":"competitor_analysis/#key-implementation-details-to-enable-porting","title":"Key Implementation Details (to enable \"Porting\")","text":"<p>If we decide to usage UI automation for specific features, here are the key patterns from the competitor:</p> <ul> <li>Selectors:<ul> <li>Input: <code>textarea.query-box-input</code></li> <li>Error/Rate Limit: <code>.error-message</code>, <code>.rate-limit-message</code></li> </ul> </li> <li>Stealth:<ul> <li>Uses <code>humanType</code> function (random intervals between keystrokes).</li> <li>Restores <code>sessionStorage</code> meticulously to maintain auth state.</li> </ul> </li> <li>Streaming Detection:<ul> <li>Polls the DOM for the answer container to stabilize.</li> </ul> </li> </ul>"},{"location":"competitor_analysis/#conclusion","title":"Conclusion","text":"<p>The \"reverse engineer RPCs\" shortcut via this competitor is a dead end. We must proceed with our own reverse engineering effort or accept UI automation as the primary method.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome! Please follow these steps to set up your development environment.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/victor/pynotebooklm.git\ncd pynotebooklm\n</code></pre> <ol> <li>Install dependencies using Poetry:</li> </ol> <pre><code>poetry install\n</code></pre> <ol> <li>Install Playwright browsers:</li> </ol> <pre><code>poetry run playwright install chromium\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>Run the full test suite:</p> <pre><code>make check\n</code></pre> <p>Or individual tests:</p> <pre><code>poetry run pytest tests/unit/\n</code></pre>"},{"location":"contributing/#linting-and-formatting","title":"Linting and Formatting","text":"<p>We use <code>ruff</code> for linting and <code>black</code> for formatting.</p> <pre><code>poetry run ruff check src tests\npoetry run black src tests\npoetry run mypy src\n</code></pre>"},{"location":"contributing/#adding-new-features","title":"Adding New Features","text":"<p>If you want to add support for a new NotebookLM tool:</p> <ol> <li>Identify the RPC ID and payload structure (see <code>docs/internal_protocol.md</code>).</li> <li>Add the corresponding method to <code>src/pynotebooklm/api.py</code>.</li> <li>Create or update a manager/service class.</li> <li>Add CLI commands in <code>src/pynotebooklm/cli.py</code>.</li> <li>Add unit and integration tests.</li> </ol>"},{"location":"decisions/","title":"Decisions","text":""},{"location":"decisions/#decisions-risks","title":"Decisions &amp; Risks","text":""},{"location":"decisions/#research-summary","title":"Research Summary","text":"<p>Comparison of existing projects that influenced this design:</p> Project Key Strengths Key Weaknesses khengyun/notebooklm-mcp Production-ready, Pydantic v2 Fewer features jacob-bd/notebooklm-mcp Complete feature set, RPC details Weak typing PleasePrompto Session continuity patterns No content generation"},{"location":"decisions/#decisions","title":"Decisions","text":"<ol> <li>FastMCP &amp; Pydantic V2: Adopted from <code>khengyun</code> for robust typing.</li> <li>31-Tool Inventory: Adopted from <code>jacob-bd</code> to ensure completeness.</li> <li>Playwright: Chosen over Selenium for better async support and reliability.</li> </ol>"},{"location":"decisions/#risk-mitigation","title":"Risk Mitigation","text":"Risk Impact Mitigation API Changes High The API is internal. We run daily CI tests against the real NotebookLM to detect breakage immediately. Cookie Expiry Medium Cookies last 2-4 weeks. The CLI provides <code>auth check</code> and clear re-login prompts. Rate Limiting Medium Requests are cached where possible, and exponential backoff is used for retries. Verification High All features are verified with both automated integration tests and manual CLI commands."},{"location":"decisions/#future-decision-points","title":"Future Decision Points","text":"<p>After Phase 2: Evaluate API stability. If RPCs change too frequently, consider forking <code>jacob-bd</code>'s approach or contributing back to it, though our current strict-typing approach provides safer maintenance.</p>"},{"location":"decisions/#references","title":"References","text":"<ul> <li>jacob-bd/notebooklm-mcp: https://github.com/jacob-bd/notebooklm-mcp (tools, RPC protocol)</li> <li>khengyun/notebooklm-mcp: https://github.com/khengyun/notebooklm-mcp (architecture, testing)</li> <li>Podcastfy: https://github.com/souzatharsis/podcastfy (async patterns)</li> <li>Playwright docs: https://playwright.dev/python/docs/intro</li> <li>Pydantic v2 docs: https://docs.pydantic.dev/latest/</li> </ul>"},{"location":"examples/","title":"Code Examples","text":"<p>This guide provides detailed walkthroughs of the example scripts included with PyNotebookLM. Each example demonstrates specific features and patterns for building production-ready automation with NotebookLM.</p>"},{"location":"examples/#quick-start","title":"Quick Start","text":"<p>All examples are located in the <code>examples/</code> directory. To run any example:</p> <pre><code># Make sure you're authenticated first\npoetry run pynotebooklm auth login\n\n# Run an example\npoetry run python examples/01_basic_usage.py\n</code></pre>"},{"location":"examples/#example-files","title":"Example Files","text":""},{"location":"examples/#01_basic_usagepy-core-operations","title":"01_basic_usage.py - Core Operations","text":"<p>Purpose: Introduction to fundamental PyNotebookLM operations.</p> <p>What it demonstrates: - Creating and listing notebooks - Adding sources (URLs, YouTube, text, Google Drive) - Querying notebooks - Deleting resources with confirmation</p> <p>Key patterns: - Using async context managers (<code>async with NotebookLMClient()</code>) - Error handling with try/except - Rich console output for better UX</p> <p>Code walkthrough:</p> <pre><code>async with NotebookLMClient() as client:\n    # Create a notebook\n    notebook = await client.notebooks.create(\"My Research Project\")\n\n    # Add sources\n    source = await client.sources.add_url(\n        notebook.id, \n        \"https://www.python.org\"\n    )\n\n    # Query the notebook\n    response = await client.chat.query(\n        notebook.id,\n        \"What is Python?\"\n    )\n</code></pre> <p>When to use: Start here if you're new to PyNotebookLM.</p>"},{"location":"examples/#02_research_workflowpy-discovery-import","title":"02_research_workflow.py - Discovery &amp; Import","text":"<p>Purpose: Automate web research and source discovery.</p> <p>What it demonstrates: - Starting fast and deep research sessions - Polling for research completion - Importing discovered sources - Handling long-running operations</p> <p>Key patterns: - Polling with exponential backoff - Task completion detection - Bulk source import</p> <p>Code walkthrough:</p> <pre><code># Start deep research\ntask = await client.research.start_research(\n    notebook_id,\n    \"artificial intelligence ethics\",\n    mode=\"deep\",\n    source=\"web\"\n)\n\n# Poll until complete (with timeout)\ntimeout = 300  # 5 minutes\nwhile timeout &gt; 0:\n    result = await client.research.poll_research(notebook_id)\n    if result.status == \"completed\":\n        break\n    await asyncio.sleep(5)\n    timeout -= 5\n\n# Import discovered sources\nsources = await client.research.import_research_sources(\n    notebook_id,\n    result.task_id,\n    result.sources\n)\n</code></pre> <p>When to use: Automating content research pipelines.</p>"},{"location":"examples/#03_content_generationpy-multi-modal-content","title":"03_content_generation.py - Multi-Modal Content","text":"<p>Purpose: Generate audio, video, infographics, and slide decks.</p> <p>What it demonstrates: - Creating audio overviews (podcasts) with different formats - Generating videos with visual style customization - Creating infographics with orientation options - Building slide decks - Polling studio artifacts for completion</p> <p>Key patterns: - Studio artifact status polling - Download URL extraction - Format/style parameter configuration</p> <p>Code walkthrough:</p> <pre><code># Generate audio (podcast)\naudio = await client.content.create_audio(\n    notebook_id,\n    source_ids,\n    format=\"deep_dive\",  # conversational format\n    length=\"default\",\n    language=\"en\"\n)\n\n# Poll for completion\nwhile True:\n    artifacts = await client.content.poll_status(notebook_id)\n    audio_artifact = next(a for a in artifacts if a.id == audio.artifact_id)\n    if audio_artifact.status == \"completed\":\n        console.print(f\"Download: {audio_artifact.download_url}\")\n        break\n    await asyncio.sleep(10)\n</code></pre> <p>When to use: Building content generation workflows.</p>"},{"location":"examples/#04_study_toolspy-educational-content","title":"04_study_tools.py - Educational Content","text":"<p>Purpose: Create flashcards, quizzes, and data tables.</p> <p>What it demonstrates: - Generating flashcards with difficulty levels - Creating quizzes with custom question counts - Extracting structured data into tables - Study artifact management</p> <p>Key patterns: - Difficulty parameter configuration - Custom prompts for data extraction - Multi-language support</p> <p>Code walkthrough:</p> <pre><code># Create flashcards\nflashcards = await client.study.create_flashcards(\n    notebook_id,\n    source_ids,\n    difficulty=\"hard\",\n    card_count=20\n)\n\n# Create quiz\nquiz = await client.study.create_quiz(\n    notebook_id,\n    source_ids,\n    question_count=10,\n    difficulty=2  # medium\n)\n\n# Extract data table\ntable = await client.study.create_data_table(\n    notebook_id,\n    source_ids,\n    description=\"Extract all dates and events mentioned\",\n    language=\"en\"\n)\n</code></pre> <p>When to use: Building educational automation or study aids.</p>"},{"location":"examples/#05_mind_mapspy-visualization","title":"05_mind_maps.py - Visualization","text":"<p>Purpose: Generate and export mind maps from notebook sources.</p> <p>What it demonstrates: - Creating mind maps from all sources - Listing existing mind maps - Exporting to JSON, OPML, and FreeMind formats - Mind map structure parsing</p> <p>Key patterns: - Two-step generation (generate + save) - Format conversion utilities - File I/O for exports</p> <p>Code walkthrough:</p> <pre><code># Create mind map\nmind_map = await client.mindmaps.create(\n    notebook_id,\n    source_ids,\n    title=\"Research Overview\"\n)\n\n# Export to different formats\nimport json\n\n# JSON export\njson_data = mind_map.data\nwith open(\"mindmap.json\", \"w\") as f:\n    json.dump(json_data, f, indent=2)\n\n# OPML export\nfrom pynotebooklm.mindmaps import export_to_opml\nopml_xml = export_to_opml(json_data)\nwith open(\"mindmap.opml\", \"w\") as f:\n    f.write(opml_xml)\n\n# FreeMind export\nfrom pynotebooklm.mindmaps import export_to_freemind\nfreemind_xml = export_to_freemind(json_data)\nwith open(\"mindmap.mm\", \"w\") as f:\n    f.write(freemind_xml)\n</code></pre> <p>When to use: Visualizing research connections and hierarchies.</p>"},{"location":"examples/#06_batch_operationspy-concurrent-operations","title":"06_batch_operations.py - Concurrent Operations","text":"<p>Purpose: Perform multiple operations efficiently with concurrency.</p> <p>What it demonstrates: - Batch creating notebooks in parallel - Adding multiple sources concurrently - Bulk deletion operations - Rate limiting and chunking strategies</p> <p>Key patterns: - Using <code>asyncio.gather()</code> for parallel execution - Progress tracking with rich.progress - Error handling for each operation - Chunking large batches to respect rate limits</p> <p>Code walkthrough:</p> <pre><code># Batch add URLs with progress tracking\ntasks = [\n    client.sources.add_url(notebook_id, url)\n    for url in urls\n]\n\n# Execute concurrently\nresults = []\nfor coro in asyncio.as_completed(tasks):\n    try:\n        result = await coro\n        results.append(result)\n    except PyNotebookLMError as e:\n        console.print(f\"Error: {e}\")\n\n# Rate-limited batch operations (chunking)\nchunk_size = 5  # Process 5 at a time\nfor i in range(0, len(urls), chunk_size):\n    chunk = urls[i:i + chunk_size]\n    tasks = [client.sources.add_url(notebook_id, url) for url in chunk]\n    await asyncio.gather(*tasks, return_exceptions=True)\n    await asyncio.sleep(1)  # Rate limit pause\n</code></pre> <p>When to use: Processing large datasets or automating bulk operations.</p>"},{"location":"examples/#07_error_handlingpy-production-patterns","title":"07_error_handling.py - Production Patterns","text":"<p>Purpose: Demonstrate robust error handling for production systems.</p> <p>What it demonstrates: - Comprehensive exception handling - Retry strategies with custom configuration - Graceful degradation - Logging and debugging patterns</p> <p>Key patterns: - Type-specific exception handling - Using RetryStrategy for transient errors - Cleanup in finally blocks - Structured error logging</p> <p>Code walkthrough:</p> <pre><code>from pynotebooklm.exceptions import (\n    AuthenticationError,\n    NotebookNotFoundError,\n    RateLimitError,\n    APIError\n)\n\ntry:\n    async with NotebookLMClient() as client:\n        notebook = await client.notebooks.create(name)\n\nexcept AuthenticationError:\n    # Don't retry - cookies expired\n    console.print(\"Please run: pynotebooklm auth login\")\n\nexcept NotebookNotFoundError:\n    # Resource doesn't exist - don't retry\n    console.print(\"Notebook not found\")\n\nexcept RateLimitError as e:\n    # Retry after delay\n    console.print(f\"Rate limited. Retry after {e.retry_after}s\")\n    await asyncio.sleep(e.retry_after)\n\nexcept APIError as e:\n    # Check if retryable (5xx errors)\n    if e.status_code and 500 &lt;= e.status_code &lt; 600:\n        # Retry with backoff\n        await retry_with_backoff(operation)\n    else:\n        raise  # Don't retry 4xx errors\n</code></pre> <p>When to use: Building production-grade automation systems.</p>"},{"location":"examples/#common-patterns","title":"Common Patterns","text":""},{"location":"examples/#async-context-manager-pattern","title":"Async Context Manager Pattern","text":"<p>Always use the async context manager to ensure proper cleanup:</p> <pre><code>async with NotebookLMClient() as client:\n    # Your operations here\n    pass\n# Browser session automatically closed\n</code></pre>"},{"location":"examples/#progress-tracking-pattern","title":"Progress Tracking Pattern","text":"<p>Use rich.progress for long-running operations:</p> <pre><code>from rich.progress import Progress, SpinnerColumn, TextColumn\n\nwith Progress(SpinnerColumn(), TextColumn(\"[progress.description]{task.description}\")) as progress:\n    task = progress.add_task(\"Processing...\", total=100)\n    for i in range(100):\n        # Do work\n        progress.advance(task)\n</code></pre>"},{"location":"examples/#error-handling-pattern","title":"Error Handling Pattern","text":"<p>Handle specific exceptions and provide actionable feedback:</p> <pre><code>try:\n    result = await client.notebooks.create(name)\nexcept AuthenticationError:\n    console.print(\"[red]Not authenticated. Run: pynotebooklm auth login[/red]\")\n    return\nexcept PyNotebookLMError as e:\n    console.print(f\"[red]Error: {e}[/red]\")\n    raise\n</code></pre>"},{"location":"examples/#retry-pattern","title":"Retry Pattern","text":"<p>Use the built-in retry decorator or RetryStrategy:</p> <pre><code>from pynotebooklm.retry import RetryStrategy, with_retry\n\n# Configure retry strategy\nstrategy = RetryStrategy(\n    max_attempts=5,\n    base_delay=2.0,\n    max_delay=60.0\n)\n\n# Apply to a function\n@with_retry(strategy)\nasync def flaky_operation():\n    # Operation that might fail transiently\n    pass\n</code></pre>"},{"location":"examples/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always authenticate before operations <pre><code>poetry run pynotebooklm auth login\npoetry run pynotebooklm auth check\n</code></pre></p> </li> <li> <p>Use environment variables for configuration <pre><code>export PYNOTEBOOKLM_MAX_RETRIES=5\nexport PYNOTEBOOKLM_BASE_DELAY=2.0\nexport PYNOTEBOOKLM_DEBUG=1  # Enable debug logging\n</code></pre></p> </li> <li> <p>Rate limit batch operations</p> </li> <li>Process in chunks (5-10 items at a time)</li> <li>Add delays between chunks</li> <li> <p>Handle failures gracefully</p> </li> <li> <p>Clean up resources</p> </li> <li>Delete test notebooks after use</li> <li>Remove unused sources</li> <li> <p>Clear old studio artifacts</p> </li> <li> <p>Log operations for debugging <pre><code>import logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nlogger.info(f\"Created notebook: {notebook.id}\")\nlogger.error(f\"Failed to add source: {e}\")\n</code></pre></p> </li> </ol>"},{"location":"examples/#running-examples","title":"Running Examples","text":""},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Install dependencies:    <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Authenticate:    <pre><code>poetry run pynotebooklm auth login\n</code></pre></p> </li> <li> <p>Verify authentication:    <pre><code>poetry run pynotebooklm auth check\n</code></pre></p> </li> </ol>"},{"location":"examples/#running-individual-examples","title":"Running Individual Examples","text":"<pre><code># Basic usage\npoetry run python examples/01_basic_usage.py\n\n# Research workflow\npoetry run python examples/02_research_workflow.py\n\n# Content generation\npoetry run python examples/03_content_generation.py\n\n# Study tools\npoetry run python examples/04_study_tools.py\n\n# Mind maps\npoetry run python examples/05_mind_maps.py\n\n# Batch operations\npoetry run python examples/06_batch_operations.py\n\n# Error handling\npoetry run python examples/07_error_handling.py\n</code></pre>"},{"location":"examples/#customizing-examples","title":"Customizing Examples","text":"<p>All examples are designed to be modified for your use case:</p> <ol> <li>Edit source URLs, notebook names, etc.</li> <li>Adjust parameters (difficulty, format, length)</li> <li>Add custom error handling</li> <li>Integrate with your existing workflows</li> </ol>"},{"location":"examples/#further-reading","title":"Further Reading","text":"<ul> <li>Advanced Usage Guide - Retry strategies, persistent sessions, performance tuning</li> <li>FAQ - Common issues and solutions</li> <li>API Reference - Complete API documentation</li> <li>Architecture - How PyNotebookLM works internally</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#authentication-cookies","title":"Authentication &amp; Cookies","text":""},{"location":"faq/#q-how-long-do-authentication-cookies-last","title":"Q: How long do authentication cookies last?","text":"<p>A: Typically 2-4 weeks. When cookies expire, you'll get an <code>AuthenticationError</code>. You can re-authenticate with <code>pynotebooklm auth login</code> or enable auto-refresh with <code>BrowserSession(auto_refresh=True)</code> for long-running sessions.</p>"},{"location":"faq/#q-where-are-cookies-stored","title":"Q: Where are cookies stored?","text":"<p>A: Cookies are stored in <code>~/.pynotebooklm/auth.json</code>. This file contains sensitive session data - never share it or commit it to version control.</p>"},{"location":"faq/#q-can-i-use-pynotebooklm-with-google-workspace-accounts","title":"Q: Can I use PyNotebookLM with Google Workspace accounts?","text":"<p>A: PyNotebookLM is primarily tested with personal Google accounts. Workspace accounts may work but haven't been extensively tested. Some organizations may block automated access.</p>"},{"location":"faq/#q-what-happens-if-im-not-authenticated","title":"Q: What happens if I'm not authenticated?","text":"<p>A: You'll receive an <code>AuthenticationError</code> when trying to use any client method. Run <code>pynotebooklm auth login</code> first.</p>"},{"location":"faq/#q-can-i-use-environment-variables-for-authentication","title":"Q: Can I use environment variables for authentication?","text":"<p>A: Not currently recommended for production. The browser-based authentication flow is the most reliable method.</p>"},{"location":"faq/#rate-limiting","title":"Rate Limiting","text":""},{"location":"faq/#q-what-are-the-rate-limits","title":"Q: What are the rate limits?","text":"<p>A: NotebookLM has internal rate limits that vary by operation. The exact limits aren't publicly documented. PyNotebookLM automatically handles rate limits with exponential backoff.</p>"},{"location":"faq/#q-how-does-retry-logic-work","title":"Q: How does retry logic work?","text":"<p>A: When a rate limit (429) or transient error (5xx) occurs, PyNotebookLM: 1. Waits using exponential backoff (1s, 2s, 4s, ...) 2. Adds random jitter to prevent thundering herd 3. Retries up to 3 times by default 4. Throws the error if all retries fail</p>"},{"location":"faq/#q-can-i-customize-retry-behavior","title":"Q: Can I customize retry behavior?","text":"<p>A: Yes! Set environment variables: <pre><code>export PYNOTEBOOKLM_MAX_RETRIES=5\nexport PYNOTEBOOKLM_BASE_DELAY=2.0\nexport PYNOTEBOOKLM_MAX_DELAY=60.0\n</code></pre></p> <p>Or use custom retry strategy: <pre><code>from pynotebooklm.retry import RetryStrategy, with_retry\n\n@with_retry(RetryStrategy(max_attempts=5, base_delay=2.0))\nasync def my_function():\n    # Your code here\n    pass\n</code></pre></p>"},{"location":"faq/#content-generation","title":"Content Generation","text":""},{"location":"faq/#q-how-long-does-content-generation-take","title":"Q: How long does content generation take?","text":"<p>A:  - Audio overviews: 60-180 seconds - Video overviews: 120-300 seconds - Infographics: 60-120 seconds - Slide decks: 60-180 seconds - Flashcards/Quiz: 30-60 seconds</p> <p>Use <code>pynotebooklm studio status &lt;notebook_id&gt;</code> to check progress.</p>"},{"location":"faq/#q-why-is-my-content-generation-stuck-in-progress","title":"Q: Why is my content generation stuck \"in progress\"?","text":"<p>A: Content generation is asynchronous. It can take several minutes. If it's stuck for &gt; 10 minutes: 1. Check if you have enough sources (minimum 1-2 recommended) 2. Verify your network connection 3. Try again - internal API might have had a temporary issue</p>"},{"location":"faq/#q-can-i-download-generated-content","title":"Q: Can I download generated content?","text":"<p>A: Yes! When generation completes, use: <pre><code>pynotebooklm studio status &lt;notebook_id&gt;\n</code></pre> This shows download URLs for audio (MP3), video (MP4), infographics (PDF), etc.</p>"},{"location":"faq/#q-how-many-sources-do-i-need-for-content-generation","title":"Q: How many sources do I need for content generation?","text":"<p>A: Minimum 1 source, but 2-5 sources provide better results. Too many sources (&gt; 50) may make generation slower.</p>"},{"location":"faq/#research-discovery","title":"Research Discovery","text":""},{"location":"faq/#q-whats-the-difference-between-standard-and-deep-research","title":"Q: What's the difference between standard and deep research?","text":"<p>A: - Standard: Fast (~15-30s), finds 5-10 sources, good for quick research - Deep: Comprehensive (~60-120s), finds 10-20 sources, includes detailed report</p>"},{"location":"faq/#q-can-i-search-google-drive-with-research","title":"Q: Can I search Google Drive with research?","text":"<p>A: Yes! Use <code>--source drive</code> flag: <pre><code>pynotebooklm research start &lt;notebook_id&gt; \"topic\" --source drive\n</code></pre></p>"},{"location":"faq/#q-how-do-i-import-discovered-sources","title":"Q: How do I import discovered sources?","text":"<p>A: Two methods:</p> <ol> <li> <p>Automatic import while polling: <pre><code>pynotebooklm research poll &lt;notebook_id&gt; --auto-import\n</code></pre></p> </li> <li> <p>Manual import after research completes: <pre><code>pynotebooklm research import &lt;notebook_id&gt;\n</code></pre></p> </li> </ol>"},{"location":"faq/#q-can-i-import-specific-sources-not-all","title":"Q: Can I import specific sources, not all?","text":"<p>A: Yes! Use the <code>--indices</code> flag: <pre><code>pynotebooklm research import &lt;notebook_id&gt; --indices 0,1,2\n</code></pre></p>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#q-why-is-browser-startup-slow","title":"Q: Why is browser startup slow?","text":"<p>A: First startup takes 3-5 seconds as Playwright launches Chrome. This is normal. For better performance, reuse the client within a single async context:</p> <pre><code>async with NotebookLMClient() as client:\n    # Multiple operations here\n    await client.notebooks.list()\n    await client.sources.add_url(...)\n    # Browser stays open for all operations\n</code></pre>"},{"location":"faq/#q-can-i-make-operations-faster","title":"Q: Can I make operations faster?","text":"<p>A: Yes: 1. Reuse client context - keeps browser open 2. Use batch operations - multiple calls in one session 3. For bulk operations - consider parallel execution with <code>asyncio.gather()</code></p>"},{"location":"faq/#q-is-there-a-way-to-keep-browser-open-between-scripts","title":"Q: Is there a way to keep browser open between scripts?","text":"<p>A: Not currently. Each script invocation starts a new browser session. For long-running operations, wrap everything in a single async context.</p>"},{"location":"faq/#errors-debugging","title":"Errors &amp; Debugging","text":""},{"location":"faq/#q-im-getting-browser-automation-failed","title":"Q: I'm getting \"Browser automation failed\"","text":"<p>A: This usually means Playwright browser isn't installed: <pre><code>playwright install chromium\n</code></pre></p> <p>Or your system is missing dependencies. On Linux: <pre><code>sudo apt-get install -y \\\n    libnss3 libnspr4 libatk1.0-0 libatk-bridge2.0-0 \\\n    libcups2 libdrm2 libxkbcommon0 libxcomposite1 \\\n    libxdamage1 libxfixes3 libxrandr2 libgbm1 libasound2\n</code></pre></p>"},{"location":"faq/#q-how-do-i-enable-debug-logging","title":"Q: How do I enable debug logging?","text":"<p>A: Set environment variable: <pre><code>export PYNOTEBOOKLM_DEBUG=1\n</code></pre></p> <p>Or in Python: <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre></p>"},{"location":"faq/#q-im-getting-session-not-active-errors","title":"Q: I'm getting \"Session not active\" errors","text":"<p>A: You're trying to call methods outside the async context manager. Use: <pre><code>async with NotebookLMClient() as client:\n    # All operations here\n</code></pre></p>"},{"location":"faq/#q-what-does-csrf-token-not-found-mean","title":"Q: What does \"CSRF token not found\" mean?","text":"<p>A: Rare error indicating the page structure changed or cookies are invalid. Try: 1. Re-authenticate: <code>pynotebooklm auth login</code> 2. Clear cookies: <code>rm ~/.pynotebooklm/auth.json</code> then login again 3. Report bug if persistent</p>"},{"location":"faq/#notebooks-sources","title":"Notebooks &amp; Sources","text":""},{"location":"faq/#q-what-types-of-sources-are-supported","title":"Q: What types of sources are supported?","text":"<p>A: - URLs: Any public webpage - YouTube: Videos (auto-detected from URL) - Google Drive: Docs, Sheets, PDFs (requires Drive permission) - Text: Plain text snippets, notes, summaries</p>"},{"location":"faq/#q-can-i-add-local-files","title":"Q: Can I add local files?","text":"<p>A: Not directly. Workaround: add as text source by reading file content: <pre><code>with open(\"file.txt\") as f:\n    content = f.read()\nawait client.sources.add_text(notebook_id, \"My File\", content)\n</code></pre></p>"},{"location":"faq/#q-how-many-notebookssources-can-i-have","title":"Q: How many notebooks/sources can I have?","text":"<p>A: NotebookLM doesn't publish hard limits. In practice: - Notebooks: 100+ is fine - Sources per notebook: 50+ works, but generation slows down</p>"},{"location":"faq/#q-can-i-organize-notebooks-into-folders","title":"Q: Can I organize notebooks into folders?","text":"<p>A: NotebookLM doesn't support folders natively. Use naming conventions: <pre><code>await client.notebooks.create(\"Project A - Research\")\nawait client.notebooks.create(\"Project A - Analysis\")\nawait client.notebooks.create(\"Project B - Planning\")\n</code></pre></p>"},{"location":"faq/#docker-deployment","title":"Docker &amp; Deployment","text":""},{"location":"faq/#q-can-i-run-pynotebooklm-in-docker","title":"Q: Can I run PyNotebookLM in Docker?","text":"<p>A: Yes! A Dockerfile is provided. Note that authentication requires browser access, so you'll need to: 1. Authenticate on host machine first 2. Mount <code>~/.pynotebooklm/auth.json</code> into container <pre><code>docker run -v ~/.pynotebooklm:/root/.pynotebooklm pynotebooklm\n</code></pre></p>"},{"location":"faq/#q-can-i-deploy-pynotebooklm-as-a-web-service","title":"Q: Can I deploy PyNotebookLM as a web service?","text":"<p>A: Possible, but challenging. Each request needs a browser context. Consider: - Serverless: Cold starts are slow (~5s) - Long-running service: Better performance, but needs state management - Cookie rotation: Implement automatic refresh every 2 weeks</p>"},{"location":"faq/#q-is-pynotebooklm-production-ready","title":"Q: Is PyNotebookLM production-ready?","text":"<p>A: For automated workflows, yes. For high-traffic web services, consider: - Rate limiting (NotebookLM enforces limits) - Cookie refresh automation - Error handling and retry logic - Cost of browser automation (memory/CPU)</p>"},{"location":"faq/#contributing-support","title":"Contributing &amp; Support","text":""},{"location":"faq/#q-how-do-i-report-bugs","title":"Q: How do I report bugs?","text":"<p>A: Open an issue on GitHub with: - Error message and stack trace - Steps to reproduce - Python version and OS - Log output (with <code>PYNOTEBOOKLM_DEBUG=1</code>)</p>"},{"location":"faq/#q-can-i-contribute","title":"Q: Can I contribute?","text":"<p>A: Yes! See <code>CONTRIBUTING.md</code> for guidelines.</p>"},{"location":"faq/#q-is-this-library-officially-supported-by-google","title":"Q: Is this library officially supported by Google?","text":"<p>A: No. This is an unofficial library using NotebookLM's internal APIs. It may break if Google changes their API.</p>"},{"location":"faq/#q-will-google-block-my-account","title":"Q: Will Google block my account?","text":"<p>A: Unlikely if used reasonably. Don't: - Make thousands of requests per hour - Share your account cookies - Automate on behalf of many users</p>"},{"location":"faq/#q-where-can-i-get-help","title":"Q: Where can I get help?","text":"<p>A:  1. Check this FAQ and documentation 2. Search GitHub issues 3. Open a new issue with details 4. Review examples in <code>examples/</code> directory</p>"},{"location":"implementation_plan/","title":"Implementation Plan","text":""},{"location":"implementation_plan/#implementation-plan","title":"Implementation Plan","text":"<p>This document outlines the phased implementation plan for the <code>pynotebooklm</code> library.</p>"},{"location":"implementation_plan/#phase-1-foundation-project-setup","title":"Phase 1: Foundation &amp; Project Setup","text":"<p>Goal: User can authenticate and see cookies saved. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components","title":"Key Components","text":"<ul> <li>Project structure and dependencies (Poetry, Playwright).</li> <li><code>AuthManager</code> for handling Google login and cookie persistence.</li> <li><code>BrowserSession</code> for managing the Playwright context.</li> <li>CI/CD pipeline setup.</li> </ul>"},{"location":"implementation_plan/#verification","title":"Verification","text":"<ul> <li>Unit tests pass: <code>pytest tests/unit/ -v</code></li> <li>Manual auth works: <code>pynotebooklm auth login</code></li> </ul>"},{"location":"implementation_plan/#phase-2-notebook-source-management","title":"Phase 2: Notebook &amp; Source Management","text":"<p>Goal: User can create notebook, add sources, and list them. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_1","title":"Key Components","text":"<ul> <li><code>NotebookLMAPI</code>: Low-level RPC wrapper.</li> <li><code>NotebookManager</code>: High-level CRUD for notebooks.</li> <li><code>SourceManager</code>: Handling URL, Text, and Drive sources.</li> <li>Integration tests against real NotebookLM.</li> </ul>"},{"location":"implementation_plan/#verification_1","title":"Verification","text":"<ul> <li>Integration tests pass: <code>make test-integration</code></li> <li>CLI commands verify functionality:   <pre><code>pynotebooklm notebooks list\npynotebooklm notebooks create \"My Project\"\npynotebooklm sources add &lt;id&gt; \"https://example.com\"\npynotebooklm notebooks delete &lt;id&gt;\n</code></pre></li> </ul>"},{"location":"implementation_plan/#phase-3-research-discovery","title":"Phase 3: Research Discovery","text":"<p>Goal: User can perform web searches and gather sources. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_2","title":"Key Components","text":"<ul> <li><code>ResearchDiscovery</code> class (<code>src/pynotebooklm/research.py</code>).</li> <li><code>start_research()</code>, <code>poll_research()</code>, <code>import_research_sources()</code>.</li> <li>Backward-compatible <code>start_web_research()</code> wrapper.</li> <li>Research is async; <code>start_research()</code> returns a <code>task_id</code>, <code>poll_research()</code> returns results.</li> <li>CLI commands: <code>research start</code>, <code>research poll</code>.</li> </ul>"},{"location":"implementation_plan/#verification_2","title":"Verification","text":"<ul> <li><code>pytest tests/integration/test_research.py</code>.</li> <li>CLI: <code>pynotebooklm research start &lt;notebook_id&gt; \"topic\"</code> returns task ID.</li> <li>CLI: <code>pynotebooklm research poll &lt;notebook_id&gt;</code> shows status and results.</li> <li>CLI: <code>pynotebooklm research import &lt;notebook_id&gt;</code> imports discovered sources to notebook.</li> </ul>"},{"location":"implementation_plan/#phase-4-mind-maps","title":"Phase 4: Mind Maps","text":"<p>Goal: User can visualize research connections. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_3","title":"Key Components","text":"<ul> <li><code>MindMapGenerator</code> class.</li> <li>Create, list, and export mind maps (XML/OPML).</li> </ul>"},{"location":"implementation_plan/#verification_3","title":"Verification","text":"<ul> <li><code>pytest tests/integration/test_mindmaps.py</code></li> </ul>"},{"location":"implementation_plan/#phase-5-chat-writing-tone","title":"Phase 5: Chat, Writing &amp; Tone","text":"<p>Goal: User can write blog posts with specific tone. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_4","title":"Key Components","text":"<ul> <li><code>ChatSession</code> for querying notebooks.</li> <li>Tone/style configuration.</li> <li>Briefing document generation.</li> </ul>"},{"location":"implementation_plan/#verification_4","title":"Verification","text":"<ul> <li><code>pytest tests/integration/test_chat.py</code></li> </ul>"},{"location":"implementation_plan/#phase-6-multi-modal-content-generation","title":"Phase 6: Multi-modal Content Generation","text":"<p>Goal: Generate Audio, Video, Slides, Infographics. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_5","title":"Key Components","text":"<ul> <li><code>ContentGenerator</code> class for all content types.</li> <li>Async polling for long-running tasks with <code>poll_status()</code>.</li> <li>Studio artifact management with <code>delete()</code>.</li> <li>CLI commands: <code>generate audio</code>, <code>generate video</code>, <code>generate infographic</code>, <code>generate slides</code>.</li> <li>Studio management: <code>studio status</code>, <code>studio delete</code>, <code>studio list</code>.</li> </ul>"},{"location":"implementation_plan/#verification_5","title":"Verification","text":"<ul> <li><code>pytest tests/unit/test_content.py</code> (54 tests)</li> <li>CLI commands documented in README.md</li> </ul>"},{"location":"implementation_plan/#phase-7-study-tools","title":"Phase 7: Study Tools","text":"<p>Goal: Generate flashcards, quizzes, and data tables. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_6","title":"Key Components","text":"<ul> <li><code>StudyManager</code> class.</li> <li>CLI commands: <code>study flashcards</code>, <code>study quiz</code>, <code>study table</code>.</li> </ul>"},{"location":"implementation_plan/#verification_6","title":"Verification","text":"<ul> <li><code>pytest tests/unit/test_study.py</code></li> </ul>"},{"location":"implementation_plan/#phase-8-production-readiness","title":"Phase 8: Production Readiness","text":"<p>Goal: Library is pip-installable and documented. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_7","title":"Key Components","text":"<ul> <li>Unified <code>NotebookLMClient</code>.</li> <li>Docker support.</li> <li>Documentation (<code>mkdocs</code>).</li> </ul>"},{"location":"implementation_plan/#verification_7","title":"Verification","text":"<ul> <li><code>pip install .</code> works.</li> <li>Docker container runs.</li> </ul>"},{"location":"implementation_plan/#phase-9-research-import-feature","title":"Phase 9: Research Import Feature","text":"<p>Goal: User can automatically import discovered research sources into notebook. Status: \u2705 Complete</p>"},{"location":"implementation_plan/#key-components_8","title":"Key Components","text":"<ul> <li><code>research import</code> CLI command for explicit source import.</li> <li><code>--auto-import</code> flag for <code>research poll</code> command.</li> <li>Deep research report import as text source.</li> <li>Support for <code>--indices</code> to import specific sources.</li> </ul>"},{"location":"implementation_plan/#verification_8","title":"Verification","text":"<ul> <li><code>pytest tests/unit/test_cli_research.py</code> (20 tests)</li> <li>CLI: <code>pynotebooklm research import &lt;notebook_id&gt;</code> imports sources.</li> <li>CLI: <code>pynotebooklm research poll &lt;notebook_id&gt; --auto-import</code> polls and imports.</li> </ul>"},{"location":"implementation_plan/#phase-10-stabilization-optimization","title":"Phase 10: Stabilization &amp; Optimization","text":"<p>Goal: High reliability, improved performance, and ecosystem integration. Status: \ud83d\udea7 In Progress</p>"},{"location":"implementation_plan/#key-components_9","title":"Key Components","text":""},{"location":"implementation_plan/#reliability-improvements","title":"Reliability Improvements","text":"<ul> <li>Exponential Backoff: <code>retry.py</code> module with <code>RetryStrategy</code> class and <code>with_retry()</code> decorator.</li> <li>Automatic Cookie Refresh: Enhanced <code>BrowserSession</code> and <code>AuthManager</code> to detect and refresh expired cookies.</li> <li>Enhanced Error Handling: Better streaming response parsing, debug logging via <code>PYNOTEBOOKLM_DEBUG</code>.</li> </ul>"},{"location":"implementation_plan/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Persistent Browser Context: <code>PersistentBrowserSession</code> class to reuse browser instances.</li> <li>CSRF Token Caching: Cache tokens for 5 minutes to avoid repeated extraction.</li> <li>Batch Operations: <code>batch_delete()</code>, <code>batch_add_urls()</code>, and parallel RPC calls.</li> </ul>"},{"location":"implementation_plan/#examples-documentation","title":"Examples &amp; Documentation","text":"<ul> <li>Library Examples: 7 complete examples covering basic usage, research, content generation, study tools, mind maps, batch operations, and error handling.</li> <li>Automation Scripts: Research pipeline, content batch generator, notebook backup, and artifact cleanup.</li> <li>Advanced Documentation: <code>advanced_usage.md</code>, <code>faq.md</code>, <code>examples.md</code> with comprehensive guides.</li> </ul>"},{"location":"implementation_plan/#publishing-release","title":"Publishing &amp; Release","text":"<ul> <li>PyPI Preparation: Updated <code>pyproject.toml</code>, <code>CHANGELOG.md</code>, <code>CONTRIBUTING.md</code>.</li> <li>GitHub Release Workflow: Automated publishing on version tags.</li> <li>Documentation Site: Deploy mkdocs to GitHub Pages.</li> </ul>"},{"location":"implementation_plan/#verification_9","title":"Verification","text":"<ul> <li>All existing tests pass (<code>make check</code>).</li> <li>Coverage remains &gt;90%.</li> <li>Examples run successfully.</li> <li>Performance benchmarks: browser startup &lt;500ms, RPC latency &lt;200ms.</li> <li>Package installs and CLI works: <code>pip install dist/*.whl</code>.</li> </ul>"},{"location":"internal_protocol/","title":"Internal Protocol","text":""},{"location":"internal_protocol/#internal-api-protocol-reverse-engineering","title":"Internal API Protocol &amp; Reverse Engineering","text":""},{"location":"internal_protocol/#internal-api-protocol","title":"Internal API Protocol","text":"<p>Base URL: <code>https://notebooklm.google.com/_/LabsTailwindUi/data/batchexecute</code></p>"},{"location":"internal_protocol/#request-format-rpc-protocol","title":"Request Format (RPC Protocol)","text":"<p>Requests are sent as <code>POST</code> to the <code>batchexecute</code> endpoint. The payload is form-encoded:</p> <pre><code># URL-encoded payload\nbody = f\"f.req={urllib.parse.quote(json_payload)}&amp;at={csrf_token}&amp;\"\n</code></pre> <p>The <code>json_payload</code> is a complex nested structure:</p> <pre><code>json_payload = json.dumps([\n    [[rpc_id, params, None, \"generic\"]]\n], separators=(',', ':'))\n</code></pre>"},{"location":"internal_protocol/#response-parsing","title":"Response Parsing","text":"<p>The response is a custom format that needs text processing before JSON parsing:</p> <ol> <li>Remove Prefix: Strip the anti-XSSI prefix <code>)]}'</code>.</li> <li>Split Lines: The response is often newline-delimited JSON.</li> <li>Extract Data: The actual data is usually deeply nested within the parsed JSON, often at index <code>[0][2]</code>.</li> </ol>"},{"location":"internal_protocol/#key-rpc-endpoints","title":"Key RPC Endpoints","text":"<p>(See <code>docs/tools.md</code> for tool mappings)</p> ID Operation Params Structure <code>wXbhsf</code> List Notebooks <code>[null, 1, null, [2]]</code> <code>CCqFvf</code> Create Notebook <code>[title, null, null, [2], [...]]</code> <code>izAoDd</code> Add Source <code>[[source_data], notebook_id, [2], extra_param]</code> <code>tGMBJ</code> Delete Source <code>[[[source_id]], [2]]</code> <code>Ljjv0c</code> Fast Research <code>[[query, source_type], null, 1, notebook_id]</code> <code>QA9ei</code> Deep Research <code>[null, [1], [query, source_type], 5, notebook_id]</code> <code>e3bVqc</code> Poll Research <code>[null, null, notebook_id]</code> <code>LBwxtb</code> Import Research <code>[null, [1], task_id, notebook_id, source_array]</code> <p>Source types: 1=web, 2=drive Research modes: 1=fast, 5=deep</p>"},{"location":"internal_protocol/#authentication-flow","title":"Authentication Flow","text":"<p>Essential Cookies: - <code>SID</code>, <code>HSID</code>, <code>SSID</code>: Google account authentication. - <code>__Secure-*PSID</code>: Secure persistent session tokens.</p> <p>Tokens: - <code>CSRF Token</code>: Often passed as <code>at=</code> in the body or strictly required headers. - <code>SNlM0e</code>, <code>FdrFJe</code>: specific tokens found in the page HTML (via <code>window.WIZ_global_data</code> or similar scripts).</p> <p>Strategy: Uses <code>BrowserSession</code> (Playwright) to log in via the standard Google login flow, then extracts cookies and saves them to <code>~/.pynotebooklm/auth.json</code>.</p>"},{"location":"internal_protocol/#reverse-engineering-guide","title":"Reverse Engineering Guide","text":""},{"location":"internal_protocol/#the-methodology","title":"The Methodology","text":"<p>Since the API is undocumented, we use an agentic browser approach to discover RPC IDs and payload structures.</p>"},{"location":"internal_protocol/#tooling-browser-subagent","title":"Tooling: Browser Subagent","text":"<p>We use the Antigravity <code>browser_subagent</code> to automate UI interactions and intercept network requests.</p>"},{"location":"internal_protocol/#the-interceptor-script","title":"The Interceptor Script","text":"<p>Inject this JavaScript to spy on <code>batchexecute</code> calls:</p> <pre><code>(function() {\n    window.CAPTURED_RPCS = window.CAPTURED_RPCS || [];\n    const originalFetch = window.fetch;\n    window.fetch = async function(...args) {\n        const [resource, config] = args;\n        if (resource &amp;&amp; resource.toString().includes('batchexecute') &amp;&amp; config &amp;&amp; config.method === 'POST') {\n            window.CAPTURED_RPCS.push({type: 'fetch', body: config.body.toString()});\n        }\n        return originalFetch.apply(this, args);\n    };\n})();\n</code></pre>"},{"location":"internal_protocol/#workflow","title":"Workflow","text":"<ol> <li>Navigate: Go to <code>https://notebooklm.google.com</code>.</li> <li>Inject: Run the interceptor script.</li> <li>Action: Perform the UI action you want to reverse engineer (e.g., \"Pin Notebook\").</li> <li>Extract: Read <code>window.CAPTURED_RPCS</code>.</li> <li>Decode: URL-decode the <code>f.req</code> parameter to see the JSON structure.</li> </ol>"},{"location":"internal_protocol/#case-study-deleting-a-source","title":"Case Study: Deleting a Source","text":"<p>In Jan 2026, <code>delete_source</code> failed. By using the subagent to perform the action and capture the RPC, we identified the correct RPC ID changed from <code>oPkhIc</code> to <code>tGMBJ</code> and the payload structure was simplified.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Get started with PyNotebookLM in three simple steps.</p>"},{"location":"quickstart/#1-installation","title":"1. Installation","text":"<p>Install PyNotebookLM via pip:</p> <pre><code>pip install pynotebooklm\n</code></pre> <p>After installing, you need to install the Playwright browser:</p> <pre><code>playwright install chromium\n</code></pre>"},{"location":"quickstart/#2-authentication","title":"2. Authentication","text":"<p>First, login to NotebookLM with your Google account:</p> <pre><code>pynotebooklm auth login\n</code></pre> <p>This opens a browser window. Once you log in, cookies are saved to <code>~/.pynotebooklm/auth.json</code>.</p> <p>Verify your authentication status:</p> <pre><code>pynotebooklm auth check\n</code></pre>"},{"location":"quickstart/#3-basic-usage","title":"3. Basic Usage","text":""},{"location":"quickstart/#using-the-cli","title":"Using the CLI","text":"<p>List your notebooks:</p> <pre><code>pynotebooklm notebooks list\n</code></pre> <p>Tip</p> <p>You can run any command or sub-command without arguments to see the available options and help. For example: <code>pynotebooklm research start</code>.</p>"},{"location":"quickstart/#using-the-library","title":"Using the Library","text":"<pre><code>import asyncio\nfrom pynotebooklm import NotebookLMClient\n\nasync def main():\n    async with NotebookLMClient() as client:\n        # Create a new notebook\n        notebook = await client.notebooks.create(\"My New Research\")\n        print(f\"Created: {notebook.name} ({notebook.id})\")\n\n        # Add a source\n        source = await client.sources.add_url(\n            notebook.id, \n            \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n        )\n        print(f\"Added source: {source.title}\")\n\n        # Ask a question\n        answer = await client.chat.query(notebook.id, \"What is AI?\")\n        print(f\"Answer: {answer}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>See the Usage Guide for more advanced examples.</p>"},{"location":"reverse_engineering_findings/","title":"Reverse Engineering: Findings from jacob-bd/notebooklm-mcp","text":"<p>Data Source: <code>analysis_repos/jacob-bd-notebooklm-mcp/src/notebooklm_mcp/api_client.py</code> Analysis Date: 2026-01-10</p>"},{"location":"reverse_engineering_findings/#executive-summary","title":"Executive Summary","text":"<p>The <code>jacob-bd</code> repository contains a complete, Python-based implementation of the NotebookLM internal API. Unlike <code>PleasePrompto</code> (which used Playwright), this project uses direct HTTP requests via <code>httpx</code>.</p> <p>We can port this code directly to PyNotebookLM.</p>"},{"location":"reverse_engineering_findings/#rpc-constants-map","title":"RPC Constants Map","text":"Action RPC ID Endpoint Notes List Notebooks <code>wXbhsf</code> <code>batchexecute</code> Params: <code>[None, 1, None, [2]]</code> Create Notebook <code>CCqFvf</code> <code>batchexecute</code> Params: <code>[title, None, None, [2], ...]</code> Get Notebook <code>rLM1Ne</code> <code>batchexecute</code> Params: <code>[notebook_id, None, [2], None, 0]</code> Delete Notebook <code>WWINqb</code> <code>batchexecute</code> Params: <code>[[notebook_id], [2]]</code> Add Source (URL/Text) <code>izAoDd</code> <code>batchexecute</code> Handles URL, Text, and Drive. Delete Source <code>tGMBJ</code> <code>batchexecute</code> Params: <code>[[[source_id]], [2]]</code> Start Fast Research <code>Ljjv0c</code> <code>batchexecute</code> Params: <code>[[query, source_type], None, 1, nb_id]</code> Start Deep Research <code>QA9ei</code> <code>batchexecute</code> Params: <code>[None, [1], [query, src_type], 5, nb_id]</code> Poll Research <code>e3bVqc</code> <code>batchexecute</code> Returns async results. Query (Chat) N/A <code>GenerateFreeFormStreamed</code> Special Endpoint: <code>/_/LabsTailwindUi/data/google.internal.labs.tailwind.orchestration.v1.LabsTailwindOrchestrationService/GenerateFreeFormStreamed</code>"},{"location":"reverse_engineering_findings/#key-implementation-details","title":"Key Implementation Details","text":"<ol> <li> <p>Chat &amp; Query:</p> <ul> <li>Does NOT use <code>batchexecute</code>.</li> <li>Uses a streaming gRPC-style endpoint: <code>GenerateFreeFormStreamed</code>.</li> <li>Requires <code>_reqid</code> parameter (incrementing integer).</li> <li>Payload uses specific <code>f.req</code> structure with <code>sources_array</code> and <code>conversation_history</code>.</li> </ul> </li> <li> <p>Authentication:</p> <ul> <li>Standard cookie-based auth (<code>SID</code>, <code>HSID</code>, etc.).</li> <li>Requires <code>SNlM0e</code> (CSRF token) and <code>FdrFJe</code> (Session ID) extracted from the HTML homepage.</li> <li><code>jacob-bd</code> refreshes these tokens on init.</li> </ul> </li> <li> <p>Drive Sources:</p> <ul> <li>Supported! Uses <code>izAoDd</code> with <code>mime_type</code> and <code>document_id</code>.</li> </ul> </li> </ol>"},{"location":"reverse_engineering_findings/#action-plan-porting-strategy","title":"Action Plan (Porting Strategy)","text":"<ol> <li>API Client: Update <code>src/pynotebooklm/api.py</code> to support the special <code>GenerateFreeFormStreamed</code> endpoint (currently we only support <code>batchexecute</code>).</li> <li>Notebooks: Implement <code>create</code> and <code>delete</code> using the payload structures from <code>api_client.py</code>. (We already have <code>wXbhsf</code> and <code>rLM1Ne</code>).</li> <li>Sources: Implement <code>add_url</code>, <code>add_text</code> using <code>izAoDd</code>.</li> <li>Chat: Implement <code>query</code> using the new endpoint. This is the biggest piece of missing functionality.</li> </ol>"},{"location":"reverse_engineering_findings/#json-payload-reference-snippet","title":"JSON Payload Reference (Snippet)","text":"<pre><code># Create Notebook\nparams = [title, None, None, [2], [1, None, None, None, None, None, None, None, None, None, [1]]]\n\n# List Notebooks\nparams = [None, 1, None, [2]]\n\n# Add URL Source\n# URL: [null, null, [url], null, null, null, null, null, null, null, 1]\nparams = [[source_data], notebook_id, [2], [1, ...]]\n</code></pre>"},{"location":"rpc_harvesting/","title":"RPC Harvesting Strategy","text":"<p>Objective: Reverse engineer the internal NotebookLM API (\"RPCs\") by using browser automation to trigger user actions and capturing the resulting network traffic.</p> <p>Methodology: 1.  Automate: Use Playwright to simulate a specific user action (e.g., \"Ask Question\"). 2.  Intercept: Monitor all <code>POST</code> requests to <code>https://notebooklm.google.com/_/BarebonesUi/data/batchexecute</code>. 3.  Extract: Decrypt the generic <code>batchexecute</code> payload to find the specific <code>rpcId</code> (e.g., <code>wXbhsf</code>) and the argument structure.</p>"},{"location":"rpc_harvesting/#1-chat-query-flow-derived-from-competitor","title":"1. Chat &amp; Query (Flow Derived from Competitor)","text":"<p>This flow is confirmed working in the competitor's codebase (<code>browser-session.ts</code>). We can use this to capture the <code>notebook_query</code> RPC.</p>"},{"location":"rpc_harvesting/#browser-sequence","title":"Browser Sequence","text":"<ol> <li>Navigate: <code>https://notebooklm.google.com/notebook/{{notebook_id}}</code></li> <li>Wait: Identify the chat input box.<ul> <li>Primary Selector: <code>textarea.query-box-input</code></li> <li>Fallback Selector: <code>textarea[aria-label=\"Feld f\u00fcr Anfragen\"]</code> (German locale in competitor code, likely <code>aria-label=\"Query box\"</code> in English).</li> </ul> </li> <li>Action:<ul> <li>Focus input.</li> <li>Type query string (e.g., \"Summarize this doc\").</li> <li>Press <code>Enter</code> key.</li> </ul> </li> <li>Wait: For response container to appear (streaming detection).</li> </ol>"},{"location":"rpc_harvesting/#rpc-capture-target","title":"RPC Capture Target","text":"<ul> <li>Look for: A <code>batchexecute</code> request initiated immediately after the <code>Enter</code> key.</li> <li>Payload Signature: The payload body will contain the exact query string \"Summarize this doc\".</li> <li>Goal: Extract the <code>rpcId</code> (likely related to <code>QUERY_NOTEBOOK</code>) and the JSON structure wrapping the query text.</li> </ul>"},{"location":"rpc_harvesting/#2-create-notebook-proposed-flow","title":"2. Create Notebook (Proposed Flow)","text":"<p>The competitor does not automate this (they use a local JSON library). We must implement this flow to capture the <code>notebook_create</code> RPC.</p>"},{"location":"rpc_harvesting/#browser-sequence_1","title":"Browser Sequence","text":"<ol> <li>Navigate: <code>https://notebooklm.google.com/</code> (Dashboard)</li> <li>Wait: Look for the \"New Notebook\" card/button.<ul> <li>Likely Selector: <code>div[role=\"button\"]</code> containing text \"New Notebook\" or similar generic tile grid element.</li> <li>Action: Click.</li> </ul> </li> <li>Action:<ul> <li>(Optional) If a modal appears asking for a title, type \"RPC Test Notebook\".</li> <li>(Optional) Click \"Save\" or \"Create\".</li> </ul> </li> <li>Wait: Redirect to <code>/notebook/{{new_notebook_id}}</code>.</li> </ol>"},{"location":"rpc_harvesting/#rpc-capture-target_1","title":"RPC Capture Target","text":"<ul> <li>Look for: <code>batchexecute</code> requests during the click.</li> <li>Payload Signature: May be empty (create default) or contain the title.</li> <li>Response Signature: The response will definitely contain the new <code>notebook_id</code> (12-char string).</li> </ul>"},{"location":"rpc_harvesting/#3-add-source-proposed-flow","title":"3. Add Source (Proposed Flow)","text":"<p>The competitor requires users to manually add sources. We will automate this to capture <code>notebook_add_url</code>, <code>notebook_add_text</code>, etc.</p>"},{"location":"rpc_harvesting/#browser-sequence_2","title":"Browser Sequence","text":"<ol> <li>Navigate: <code>https://notebooklm.google.com/notebook/{{notebook_id}}</code></li> <li>Wait: \"Add Source\" or \"+\" button in the left sidebar.<ul> <li>Action: Click \"+\" button.</li> </ul> </li> <li>Wait: Source type menu (Drive, Link, Text).<ul> <li>Action: Click \"Link\" (or \"Website\").</li> </ul> </li> <li>Action:<ul> <li>Type URL: <code>https://example.com</code></li> <li>Click \"Insert\" or \"Add\".</li> </ul> </li> </ol>"},{"location":"rpc_harvesting/#rpc-capture-target_2","title":"RPC Capture Target","text":"<ul> <li>Look for: <code>batchexecute</code> request containing <code>https://example.com</code>.</li> <li>Response: Confirmation of source addition, source ID.</li> </ul>"},{"location":"rpc_harvesting/#4-research-deep-dive-proposed-flow","title":"4. Research / Deep Dive (Proposed Flow)","text":"<p>This is a key differentiator. We assume <code>research_start</code> corresponds to a specific UI Toggle or \"Deep Dive\" button.</p>"},{"location":"rpc_harvesting/#browser-sequence_3","title":"Browser Sequence","text":"<ol> <li>Navigate: <code>https://notebooklm.google.com/notebook/{{notebook_id}}</code></li> <li>Initial Query: Type a query in the chat box.</li> <li>Action: Look for \"Deep Dive\" or \"Extended Research\" toggle/icon before or after sending.<ul> <li>(Investigation required: This might be a specific 'mode' in the chat).</li> </ul> </li> </ol>"},{"location":"rpc_harvesting/#rpc-capture-target_3","title":"RPC Capture Target","text":"<ul> <li>Compare the RPC payload of a \"Normal Query\" vs a \"Deep/Research Query\".</li> <li>Look for a boolean flag or integer (e.g., <code>1</code> vs <code>2</code>) in the payload array that toggles this mode.</li> </ul>"},{"location":"rpc_harvesting/#tooling-recommendation","title":"Tooling Recommendation","text":"<p>To execute this plan, we should build a small helper script <code>scripts/harvest_rpc.py</code> that: 1.  Accepts a <code>flow_name</code> argument (e.g., <code>chat</code>). 2.  Launches Playwright with <code>pynotebooklm</code> auth. 3.  Performs the sequence. 4.  Dumps all <code>batchexecute</code> request bodies to a JSON file for analysis.</p>"},{"location":"technical_deep_dives/","title":"Deep Dives","text":""},{"location":"technical_deep_dives/#technical-deep-dives","title":"Technical Deep Dives","text":""},{"location":"technical_deep_dives/#browser-automation-patterns","title":"Browser Automation Patterns","text":""},{"location":"technical_deep_dives/#playwright-session-management","title":"Playwright Session Management","text":"<p>We use <code>playwright.async_api</code> to manage the browser lifecycle.</p> <pre><code>class BrowserSession:\n    async def __aenter__(self):\n        # Starts Playwright, launches Chromium (headless)\n        # Injects saved cookies into the context\n        # Navigates to the base URL\n        return self\n\n    async def call_api(self, endpoint, data):\n        # Uses page.evaluate() to execute fetch() in the browser context\n        # This bypasses CORS and complex header signing requirements\n        # by reusing the browser's authenticated state.\n</code></pre>"},{"location":"technical_deep_dives/#why-pageevaluate","title":"Why page.evaluate()?","text":"<p>Instead of trying to replicate all headers and signatures in Python's <code>httpx</code>, we execute the network request inside the browser using JavaScript's <code>fetch</code>. This ensures: 1.  All cookies are attached automatically. 2.  Origin/Referer headers are correct. 3.  Google's internal request signatures are handled by their client-side scripts if necessary (though <code>batchexecute</code> usually only needs cookies + CSRF).</p>"},{"location":"technical_deep_dives/#async-polling-for-generation","title":"Async Polling for Generation","text":"<p>Content generation (podcasts, videos) takes significant time (1-5 minutes).</p>"},{"location":"technical_deep_dives/#strategy-exponential-backoff","title":"Strategy: Exponential Backoff","text":"<p>We implement a robust polling mechanism:</p> <ol> <li>Initial call: Triggers generation, returns an <code>artifact_id</code>.</li> <li>Poll Loop: Calls <code>get_status(artifact_id)</code>.</li> <li>Backoff: <code>sleep(delay)</code> where delay increases (2s -&gt; 3s -&gt; 4.5s -&gt; ... max 10s).</li> <li>Timeout: Raises <code>GenerationTimeoutError</code> if it exceeds 300s (5 mins).</li> <li>Completion: Returns the final artifact with the download URL.</li> </ol> <pre><code>async def poll_until_ready(artifact_id):\n    delay = 2.0\n    while True:\n        status = await check_status(artifact_id)\n        if status.is_ready: break\n        await asyncio.sleep(delay)\n        delay = min(delay * 1.5, 10.0)\n</code></pre>"},{"location":"tools/","title":"Tools","text":""},{"location":"tools/#tool-inventory","title":"Tool Inventory","text":"<p>This document lists all 31 tools planned for the library, categorized by their functionality and implementation phase.</p>"},{"location":"tools/#notebook-management-phase-2","title":"Notebook Management (Phase 2)","text":"<p>Tests: <code>tests/integration/test_notebooks.py</code></p> Tool ID Description <code>notebook_list</code> <code>wXbhsf</code> List all notebooks in account <code>notebook_create</code> <code>CCqFvf</code> Create new notebook with name <code>notebook_get</code> <code>rLM1Ne</code> Get notebook details by ID <code>notebook_rename</code> N/A Rename existing notebook <code>notebook_delete</code> N/A Delete notebook (requires confirmation) <code>notebook_describe</code> (Phase 4) AI summary of notebook contents"},{"location":"tools/#source-management-phase-2","title":"Source Management (Phase 2)","text":"<p>Tests: <code>tests/integration/test_sources.py</code></p> Tool ID Description <code>notebook_add_url</code> <code>izAoDd</code> Add web URL as source <code>notebook_add_text</code> <code>izAoDd</code> Add plain text as source <code>notebook_add_drive</code> <code>izAoDd</code> Add Google Drive document <code>source_list_drive</code> N/A List available Drive documents <code>source_delete</code> <code>tGMBJ</code> Remove source from notebook <code>source_check_freshness</code> <code>tGMBJ</code> Check if Drive source is up-to-date (part of list) <code>source_get_text</code> <code>tGMBJ</code> Get raw text content of source <code>source_describe</code> (Phase 4) AI summary of single source <code>source_sync_drive</code> (Phase 4) Sync/update Drive sources"},{"location":"tools/#research-discovery-phase-3","title":"Research Discovery (Phase 3) \u2705","text":"<p>Tests: <code>tests/integration/test_research.py</code></p> Tool ID Description <code>research_fast</code> <code>Ljjv0c</code> Start fast web research (param: 1) <code>research_deep</code> <code>QA9ei</code> Start deep research (param: 5) <code>research_status</code> <code>e3bVqc</code> Check research progress <code>research_import</code> <code>LBwxtb</code> Import research findings to notebook"},{"location":"tools/#notes","title":"Notes:","text":"<ul> <li>Notebook Context Required: All research operations require a <code>notebook_id</code> - research is performed and persisted within a notebook</li> <li>Drive Sync: Per-source operation, accessed via individual source context menu (not notebook-wide)</li> <li>Topic Suggestions: Appear as follow-up chips after chat responses; generated as part of chat, not a separate RPC</li> </ul>"},{"location":"tools/#mind-maps-phase-4","title":"Mind Maps (Phase 4) \u2705","text":"<p>Tests: <code>tests/integration/test_mindmaps.py</code></p> Tool Description <code>mindmap_create</code> Generate mind map from sources <code>mindmap_list</code> List existing mind maps <code>mindmap_export_xml</code> Export to FreeMind format <code>mindmap_export_opml</code> Export to OPML format"},{"location":"tools/#query-chat-phase-5","title":"Query &amp; Chat (Phase 5) \u2705","text":"<p>Tests: <code>tests/integration/test_chat.py</code></p> Tool Description <code>notebook_query</code> Ask question, get AI answer with citations <code>chat_configure</code> Set chat style, response length, goals <code>briefing_create</code> Generate briefing document"},{"location":"tools/#content-generation-phase-6","title":"Content Generation (Phase 6) \u2705","text":"<p>Tests: <code>tests/unit/test_content.py</code></p> Tool ID Description <code>audio_overview_create</code> <code>R7cb6c</code> Generate podcast (deep dive, brief, critique, debate) <code>video_overview_create</code> <code>R7cb6c</code> Generate video explainer (type=3) <code>infographic_create</code> <code>R7cb6c</code> Generate infographic image (type=7) <code>slide_deck_create</code> <code>R7cb6c</code> Generate presentation slides (type=8) <code>studio_status</code> <code>gArtLc</code> Check generation progress <code>studio_delete</code> <code>V5N4be</code> Delete generated artifact"},{"location":"tools/#study-tools-phase-7","title":"Study Tools (Phase 7) \u2705","text":"<p>Tests: <code>tests/unit/test_study.py</code></p> Tool Description <code>flashcard_create</code> Generate study flashcards <code>quiz_create</code> Generate quiz questions <code>data_table_create</code> Generate data analysis table"},{"location":"tools/#utilities","title":"Utilities","text":"Tool Description <code>save_auth_tokens</code> Explicitly save current auth state"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide covers common tasks and advanced features of PyNotebookLM.</p>"},{"location":"usage/#content-generation","title":"Content Generation","text":"<p>NotebookLM can generate various types of content based on your sources.</p>"},{"location":"usage/#audio-overviews-podcasts","title":"Audio Overviews (Podcasts)","text":"<p>Generate a \"Deep Dive\" conversation between two AI hosts:</p> <pre><code>pynotebooklm generate audio &lt;notebook_id&gt; --format deep_dive --length long\n</code></pre> <p>From Python:</p> <pre><code>result = await client.content.create_audio(\n    notebook_id=notebook_id,\n    source_ids=source_ids,\n    format=AudioFormat.DEEP_DIVE,\n    length=AudioLength.LONG\n)\n</code></pre>"},{"location":"usage/#video-overviews","title":"Video Overviews","text":"<pre><code>pynotebooklm generate video &lt;notebook_id&gt; --style anime\n</code></pre>"},{"location":"usage/#mind-maps","title":"Mind Maps","text":"<p>Generate a hierarchical visualization of your research:</p> <pre><code>pynotebooklm mindmap create &lt;notebook_id&gt; --title \"Research Landscape\"\n</code></pre> <p>Export to OPML (importable in most mind mapping tools):</p> <pre><code>pynotebooklm mindmap export &lt;notebook_id&gt; &lt;mindmap_id&gt; --format opml\n</code></pre>"},{"location":"usage/#study-tools","title":"Study Tools","text":"<p>Generate aids to help you learn from your sources.</p>"},{"location":"usage/#flashcards","title":"Flashcards","text":"<pre><code>pynotebooklm study flashcards &lt;notebook_id&gt; --difficulty hard\n</code></pre>"},{"location":"usage/#quizzes","title":"Quizzes","text":"<pre><code>pynotebooklm study quiz &lt;notebook_id&gt; --questions 5 --difficulty 3\n</code></pre>"},{"location":"usage/#source-management","title":"Source Management","text":"<p>Add different types of content to your notebooks.</p>"},{"location":"usage/#web-youtube-urls","title":"Web &amp; YouTube URLs","text":"<pre><code>pynotebooklm sources add &lt;notebook_id&gt; \"https://en.wikipedia.org/wiki/Python\"\npynotebooklm sources add &lt;notebook_id&gt; \"https://www.youtube.com/watch?v=...\"\n</code></pre>"},{"location":"usage/#plain-text","title":"Plain Text","text":"<pre><code>pynotebooklm sources add-text &lt;notebook_id&gt; \"Your research notes here...\" --title \"My Notes\"\n</code></pre>"},{"location":"usage/#google-drive","title":"Google Drive","text":"<pre><code>pynotebooklm sources add-drive &lt;notebook_id&gt; \"&lt;drive_doc_id&gt;\"\n</code></pre>"},{"location":"usage/#chat-query","title":"Chat &amp; Query","text":"<p>Interact with your sources through AI.</p>"},{"location":"usage/#asking-questions","title":"Asking Questions","text":"<pre><code>pynotebooklm query ask &lt;notebook_id&gt; \"What are the main findings?\"\n</code></pre>"},{"location":"usage/#restricting-scope","title":"Restricting Scope","text":"<p>Focus the answer on specific sources only: <pre><code>pynotebooklm query ask &lt;notebook_id&gt; \"...\" --sources \"source1,source2\"\n</code></pre></p>"},{"location":"usage/#follow-up-conversations","title":"Follow-up Conversations","text":"<pre><code>pynotebooklm query ask &lt;notebook_id&gt; \"What else?\" --conversation-id \"conv_123\"\n</code></pre>"},{"location":"usage/#research-discovery","title":"Research Discovery","text":"<p>Search the web or Google Drive for new sources related to your topic:</p> <pre><code>pynotebooklm research start &lt;notebook_id&gt; \"Quantum Computing\" --deep\n# For Google Drive research\npynotebooklm research start &lt;notebook_id&gt; \"Internal Project X\" --source drive\n</code></pre> <p>Research is asynchronous. Check the status:</p> <pre><code>pynotebooklm research poll &lt;notebook_id&gt;\n</code></pre>"},{"location":"usage/#advanced-authentication","title":"Advanced Authentication","text":"<p>If you can't use the interactive login, you can manually save tokens:</p> <pre><code>from pynotebooklm import save_auth_tokens\n\n# From a cookie string\nsave_auth_tokens(cookies=\"SID=xxx; HSID=yyy; ...\")\n\n# Or from a list of dictionaries\nsave_auth_tokens(cookies=[{\"name\": \"SID\", \"value\": \"xxx\", \"domain\": \".google.com\"}])\n</code></pre>"}]}