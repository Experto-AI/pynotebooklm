# PyNotebookLM - Original Requirements and Notes

## Executive Summary

**Goal**: Build a production-grade Python library for NotebookLM integration, then wrap it with a DeterminAgent adapter to enable deterministic content creation flows.

**Approach**: Two-phase development
1. **Phase 1**: Build `pynotebooklm` - A standalone Python library (similar to khengyun's architecture) (This project, build here)
2. **Phase 2**: Build `NotebookLMAdapter` - A DeterminAgent adapter wrapping the library (Other project, do NOT build here)

NOTE: DeterminAgent is another project that i have already build.

**Key Requirements**:
- ‚úÖ All 31 tools from jacob-bd (Content Generation, Source Management, Research, Mind Maps)
- ‚úÖ Production-grade code quality (Pydantic, type safety, comprehensive testing)
- ‚úÖ Browser automation for auth and API interaction
- ‚úÖ Deterministic behavior for DeterminAgent workflows
- ‚úÖ Clean architecture (avoid "vibe-coded" patterns)

---

## Compared MCP Projects

| Project | Repository | Language | Tools | Approach | Status |
|---------|-----------|----------|-------|----------|--------|
| **jacob-bd** | https://github.com/jacob-bd/notebooklm-mcp | Python | 31 | Browser-based (Chrome DevTools Protocol) | Active |
| **khengyun** | https://github.com/khengyun/notebooklm-mcp | Python | 8 | Browser-based (Selenium) with FastMCP v2 | Production |
| **PleasePrompto** | https://github.com/PleasePrompto/notebooklm-mcp | TypeScript | 16 | Browser-based (Playwright) + Library mgmt | Stable |

---

## ‚ö†Ô∏è CRITICAL CLARIFICATION: jacob-bd "API Reversal" vs Actual Implementation

### The Question
You correctly identified a potential contradiction: jacob-bd claims to use "API reversal" (undocumented internal APIs) rather than web browsers. Let's verify this.

### What jacob-bd Actually Claims
From their README: *"This tool uses Google's internal APIs and Chrome DevTools Protocol to interact with NotebookLM"*

### What jacob-bd Actually Does
**Browser-Based with Chrome DevTools Protocol (CDP)**:

```python
# From jacob-bd source structure:
- Uses Chrome DevTools Protocol (CDP)
- Communicates via WebSocket to Chrome
- Extracts cookies from Chrome DevTools Network tab
- Makes fetch() calls through Chrome context
- Parses responses from Chrome's JavaScript context
```

**NOT Pure HTTP API Calls**:
- ‚ùå Does NOT make raw HTTP requests to NotebookLM servers
- ‚ùå Does NOT use undocumented REST endpoints
- ‚úÖ DOES use browser automation through Chrome DevTools
- ‚úÖ DOES extract auth from Chrome cookies
- ‚úÖ DOES make API calls FROM within the browser context

### Why This Distinction Matters

**jacob-bd's "API Reversal" actually means:**
1. Open Chrome with NotebookLM
2. Log in (user provides cookies via DevTools)
3. Use Chrome's JavaScript context to make fetch() calls to NotebookLM's internal endpoints
4. These endpoints ARE real APIs but are undocumented (reverse-engineered)
5. Calls originate FROM the browser context (not direct HTTP)

**This is fundamentally Browser Automation**, not "pure API reversal"

### Verification Evidence

From the technical analysis of jacob-bd's codebase:
```python
# jacob-bd uses this pattern:
page.evaluate("""
    async () => {
        const response = await fetch('https://notebooklm.google.com/_/...',  {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(payload)
        });
        return await response.json();
    }
""")

# This is browser automation, not raw HTTP
```

### So Why Does jacob-bd Market It As "API Reversal"?

**Technical correctness**: They discovered the internal API endpoints through Chrome DevTools
**Marketing clarity**: "Browser automation" sounds more limited than "API reversal"
**Practical difference**: They don't need Selenium/Playwright overhead - Chrome DevTools Protocol is lighter
**Reality**: Still requires Chrome and cookies, still browser-dependent

### Recommended Approach for Your Project

**Choose Browser Automation (Selenium or Playwright)** over "API reversal" because:

1. **More transparent**: Explicitly browser-based, no confusion
2. **More flexible**: Can fallback if APIs change
3. **Better documented**: Selenium/Playwright have extensive docs
4. **More portable**: Works across different Chrome versions
5. **Easier to debug**: Standard browser automation tools

**Hybrid Architecture**:
```
Primary: HTTP API calls (faster, lighter)
         ‚îî‚îÄ For basic operations (list, create, query)

Fallback: Browser automation (Selenium/Playwright)
          ‚îî‚îÄ For complex operations (content generation)
          ‚îî‚îÄ For anti-bot detection handling
```

---

---

## 1. Integration Approach Analysis

### Option A: Official NotebookLM Enterprise API ‚ùå
**Verdict**: Not viable for your use case

**Pros**:
- Officially supported
- Production-ready
- No browser automation needed

**Cons**:
- ‚ùå Enterprise only (requires Google Cloud account, billing)
- ‚ùå Limited functionality (notebook CRUD only, no content generation)
- ‚ùå No free tier access to advanced features
- ‚ùå Missing 80% of jacob-bd's tools (no podcasts, videos, infographics)

### Option B: MCP Server Integration ‚ùå
**Verdict**: Adds unnecessary complexity

**Pros**:
- Protocol standardization
- Reusable across MCP clients

**Cons**:
- ‚ùå Adds latency (subprocess communication)
- ‚ùå DeterminAgent doesn't use MCP protocol
- ‚ùå Extra deployment complexity (running separate server)
- ‚ùå Doesn't fit deterministic flow model
- ‚ùå Would need adapter anyway to integrate with DeterminAgent

### Option C: A2A (Agent-to-Agent) via Agentspace ‚ùå
**Verdict**: Enterprise-only, wrong abstraction level

**Pros**:
- Google's official multi-agent protocol
- Built-in coordination

**Cons**:
- ‚ùå Requires Google Agentspace (Enterprise subscription)
- ‚ùå Not designed for deterministic workflows
- ‚ùå Overkill for content creation use case
- ‚ùå Limited control over execution order

### Option D: Python Library + DeterminAgent Adapter ‚úÖ (RECOMMENDED)
**Verdict**: Best fit for requirements

**Pros**:
- ‚úÖ Consistent with DeterminAgent architecture (follows Claude/Gemini/Copilot pattern)
- ‚úÖ Zero variable costs (browser automation, no API calls)
- ‚úÖ Full feature access (all 31 tools)
- ‚úÖ Deterministic execution control
- ‚úÖ Reusable library (can be used standalone or in other projects)
- ‚úÖ Clean separation of concerns (library logic separate from adapter integration)

**Cons**:
- ‚ö†Ô∏è Requires browser automation (Playwright/Puppeteer)
- ‚ö†Ô∏è Cookie-based auth expires every 2-4 weeks
- ‚ö†Ô∏è Depends on undocumented NotebookLM internal APIs
- ‚ö†Ô∏è May break if Google changes NotebookLM UI/API

**Mitigation**:
- Use Playwright (more stable than Puppeteer for headless)
- Implement robust error handling and retry logic
- Version lock the library, add update notifications
- Monitor NotebookLM for breaking changes

---

## Comprehensive Feature Matrix Comparison

### What Each Implementation Can Do

| **Feature Category** | **PleasePrompto** | **jacob-bd** | **khengyun** |
|---|---|---|---|
| **Total Tools/Features** | 16 | 31 | 8 |
| | | | |
| **QUERY & RESEARCH** | | | |
| Ask Questions/Query | ‚úÖ | ‚úÖ | ‚úÖ |
| Multi-turn Conversation | ‚úÖ | ‚úÖ | ‚úÖ |
| AI Research Discovery | ‚ùå | ‚úÖ Web/Drive research | ‚úÖ (basic) |
| Get Citations | ‚úÖ | ‚úÖ | ‚úÖ |
| | | | |
| **NOTEBOOK MANAGEMENT** | | | |
| Create Notebooks | ‚ùå | ‚úÖ | ‚úÖ |
| List/Browse Notebooks | ‚úÖ | ‚úÖ | ‚úÖ |
| Rename Notebooks | ‚ùå | ‚úÖ | ‚ùå |
| Delete Notebooks | ‚ùå | ‚úÖ | ‚ùå |
| Save & Tag Notebooks | ‚úÖ | ‚ùå | ‚ùå |
| Custom Notebook Library | ‚úÖ | ‚ùå | ‚ùå |
| Notebook Analytics | ‚úÖ | ‚ùå | ‚ùå |
| | | | |
| **SOURCE MANAGEMENT** | | | |
| Add URLs | ‚ùå | ‚úÖ | ‚ùå |
| Add YouTube Videos | ‚ùå | ‚úÖ | ‚ùå |
| Add Google Drive Docs | ‚ùå | ‚úÖ | ‚ùå |
| Add Text/Paste Content | ‚ùå | ‚úÖ | ‚ùå |
| PDFs | ‚ùå | ‚úÖ (via Drive) | ‚úÖ (native) |
| Web Content | ‚ùå | ‚úÖ | ‚úÖ (native) |
| Academic Papers | ‚ùå | ‚úÖ | ‚úÖ (via URL/PDF) |
| Sync/Update Sources | ‚ùå | ‚úÖ Freshness tracking | ‚ùå |
| Delete Sources | ‚ùå | ‚úÖ | ‚ùå |
| Source Summaries | ‚ùå | ‚úÖ | ‚ùå |
| | | | |
| **CONTENT GENERATION** | | | |
| üéôÔ∏è Audio Podcasts | ‚ùå | ‚úÖ Multiple formats | ‚úÖ |
| üé• Videos | ‚ùå | ‚úÖ | ‚úÖ |
| üé® Infographics | ‚ùå | ‚úÖ | ‚ùå |
| üé™ Slide Decks | ‚ùå | ‚úÖ | ‚ùå |
| üß† Mind Maps | ‚ùå | ‚úÖ | ‚ùå |
| üìá Flashcards | ‚ùå | ‚úÖ | ‚úÖ |
| üìã Briefing Documents | ‚ùå | ‚úÖ | ‚ùå |
| üìù Quiz Questions | ‚ùå | ‚ùå (implied) | ‚úÖ |
| Studio Artifact Management | ‚ùå | ‚úÖ | ‚ùå |
| | | | |
| **CONFIGURATION & CONTROL** | | | |
| Profile Switching (Minimal/Standard/Full) | ‚úÖ | ‚ùå | ‚ùå |
| Chat Goal Configuration | ‚ùå | ‚úÖ | ‚ùå |
| Response Length Control | ‚ùå | ‚úÖ | ‚ùå |
| Chat Style Configuration | ‚ùå | ‚úÖ | ‚ùå |
| | | | |
| **AUTHENTICATION & SESSION** | | | |
| Account Switching | ‚úÖ | ‚ùå | ‚úÖ |
| Session Management | ‚úÖ | ‚ùå | ‚ùå |
| Cookie-Based Auth | ‚úÖ | ‚úÖ | ‚úÖ |
| Setup/Re-auth | ‚úÖ | ‚úÖ | ‚úÖ |
| | | | |
| **DEPLOYMENT & INTEGRATION** | | | |
| STDIO Protocol | ‚úÖ | ‚úÖ | ‚úÖ |
| HTTP Protocol | ‚ùå | ‚ùå | ‚úÖ |
| SSE Protocol | ‚ùå | ‚ùå | ‚úÖ |
| Docker Support | ‚ùå | ‚ùå | ‚úÖ Docker Compose |
| LangGraph Integration | ‚ùå | ‚ùå | ‚úÖ (examples) |
| CrewAI Integration | ‚ùå | ‚ùå | ‚úÖ (examples) |
| CLI Interface | ‚úÖ | ‚úÖ | ‚úÖ |
| Programmatic API | ‚ùå | ‚úÖ | ‚úÖ |

### Quick Decision Matrix

**Choose PleasePrompto if you need:**
- ‚úÖ Simple query-focused research tool
- ‚úÖ Save and organize notebooks with metadata/tags
- ‚úÖ Quick setup with minimal configuration
- ‚ùå Content creation (no audio, video, infographics)
- ‚ùå Add sources directly (no source management)

**Choose jacob-bd if you need:**
- ‚úÖ Maximum feature breadth (31 tools)
- ‚úÖ Create audio podcasts, videos, infographics, slides, mind maps
- ‚úÖ Add YouTube videos, Google Drive docs, URLs, text
- ‚úÖ Research discovery and bulk imports
- ‚úÖ Studio artifact management
- ‚ö†Ô∏è Still in active development (may have bugs)
- ‚ö†Ô∏è Requires cookie refresh every 2-4 weeks

**Choose khengyun if you need:**
- ‚úÖ Production-ready (v2.0.11, 102 commits, mature)
- ‚úÖ Modern deployment (Docker, HTTP/SSE protocols)
- ‚úÖ Podcast and quiz generation
- ‚úÖ Clean, maintainable codebase with comprehensive tests
- ‚úÖ Framework integrations (LangGraph, CrewAI)
- ‚ùå Fewer content creation tools than jacob-bd (no video, infographics, mind maps, slides)
- ‚ùå No direct source management UI (works with NotebookLM native sources)

### Recommendation for Your Project: **Combine jacob-bd's Features with khengyun's Architecture**

- **Feature Set**: Use jacob-bd as reference for all 31 tools
- **Architecture**: Follow khengyun's production-grade patterns (FastMCP v2, Pydantic, Docker, tests)
- **Implementation**: Build a hybrid approach (browser automation + resilience)
- **Quality**: Exceed both in code quality and maintainability

---

## 2. Recommended Architecture

### 2.1 System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     DeterminAgent Workflow                       ‚îÇ
‚îÇ                          (LangGraph)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚îÇ Python API call
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              NotebookLMAdapter (DeterminAgent Layer)             ‚îÇ
‚îÇ  - Implements ProviderAdapter interface                          ‚îÇ
‚îÇ  - Maps DeterminAgent calls ‚Üí NotebookLM library                 ‚îÇ
‚îÇ  - Handles serialization/deserialization                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚îÇ Library calls
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    pynotebooklm Library                            ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  NotebookLM      ‚îÇ  ‚îÇ  Source          ‚îÇ  ‚îÇ  Content      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Client          ‚îÇ  ‚îÇ  Manager         ‚îÇ  ‚îÇ  Generator    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Core API)      ‚îÇ  ‚îÇ  (Add sources)   ‚îÇ  ‚îÇ  (Podcasts)   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Research        ‚îÇ  ‚îÇ  Mind Map        ‚îÇ  ‚îÇ  Auth         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Discovery       ‚îÇ  ‚îÇ  Generator       ‚îÇ  ‚îÇ  Manager      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚îÇ Browser automation
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Playwright/Browser                             ‚îÇ
‚îÇ  - Cookie-based authentication                                    ‚îÇ
‚îÇ  - Internal NotebookLM API calls                                  ‚îÇ
‚îÇ  - Headless Chrome session management                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Library Architecture (`pynotebooklm`)

**Technology Stack**:
- **Python**: 3.10+ (match DeterminAgent)
- **Browser Automation**: Playwright (more robust than Puppeteer)
- **Type Safety**: Pydantic v2 (schemas and validation)
- **Async**: asyncio (browser operations are async)
- **HTTP**: httpx (async HTTP client for API calls)
- **Testing**: pytest + pytest-asyncio
- **Packaging**: Poetry 

**Directory Structure**:
```
pynotebooklm/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ pynotebooklm/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py           # Public API exports
‚îÇ       ‚îú‚îÄ‚îÄ client.py             # NotebookLMClient (main entry point)
‚îÇ       ‚îú‚îÄ‚îÄ auth.py               # Authentication manager
‚îÇ       ‚îú‚îÄ‚îÄ session.py            # Browser session management
‚îÇ       ‚îú‚îÄ‚îÄ api.py                # Internal API wrapper
‚îÇ       ‚îú‚îÄ‚îÄ models.py             # Pydantic schemas
‚îÇ       ‚îú‚îÄ‚îÄ exceptions.py         # Custom exceptions
‚îÇ       ‚îú‚îÄ‚îÄ notebooks.py          # Notebook management
‚îÇ       ‚îú‚îÄ‚îÄ sources.py            # Source management
‚îÇ       ‚îú‚îÄ‚îÄ content.py            # Content generation
‚îÇ       ‚îú‚îÄ‚îÄ research.py           # Research discovery
‚îÇ       ‚îî‚îÄ‚îÄ mindmaps.py           # Mind map generation
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ examples/
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

**Core Classes**:

```python
# Main entry point
class NotebookLMClient:
    def __init__(self, auth_path: str = "~/.notebooklm/auth.json"):
        self.auth = AuthManager(auth_path)
        self.session = BrowserSession(self.auth)
        self.notebooks = NotebookManager(self.session)
        self.sources = SourceManager(self.session)
        self.content = ContentGenerator(self.session)
        self.research = ResearchDiscovery(self.session)
        self.mindmaps = MindMapGenerator(self.session)

    # High-level methods
    async def create_notebook(self, name: str) -> Notebook
    async def add_youtube_source(self, notebook_id: str, url: str) -> Source
    async def generate_podcast(self, notebook_id: str, style: str) -> Artifact
    ...

# Authentication
class AuthManager:
    async def login(self, headless: bool = False)
    async def refresh_tokens(self)
    def is_authenticated(self) -> bool

# Browser session
class BrowserSession:
    async def __aenter__(self)
    async def __aexit__(self)
    async def call_api(self, endpoint: str, method: str, data: dict) -> dict
```

**Pydantic Models**:
```python
class Notebook(BaseModel):
    id: str
    name: str
    created_at: datetime
    sources: list[Source] = []

class Source(BaseModel):
    id: str
    type: Literal["url", "youtube", "drive", "text"]
    url: Optional[str]
    title: str
    status: Literal["processing", "ready", "failed"]

class Artifact(BaseModel):
    id: str
    type: Literal["audio", "video", "infographic", "slides", "mindmap"]
    status: Literal["generating", "ready", "failed"]
    url: Optional[str]
    progress: float  # 0.0 to 1.0
```

### 2.3 DeterminAgent Adapter

**Integration Pattern**: Follow existing adapter structure

```python
# determinagent/adapters/notebooklm.py

from determinagent.adapters.base import ProviderAdapter
from notebooklm import NotebookLMClient, Notebook
import asyncio

class NotebookLMAdapter(ProviderAdapter):
    provider_name: str = "notebooklm"

    def __init__(self):
        self.client = NotebookLMClient()
        # Run async operations in sync context
        self._loop = asyncio.new_event_loop()

    def build_command(self, prompt: str, model: str, ...) -> list[str]:
        # NotebookLM doesn't use CLI, so this is a no-op
        # We'll override execute() instead
        raise NotImplementedError("NotebookLM uses direct Python API")

    def execute(self, prompt: str, tool: str, **kwargs) -> str:
        """
        Execute NotebookLM tool synchronously

        Args:
            prompt: User instruction
            tool: Tool name (e.g., "generate_podcast", "add_youtube_source")
            **kwargs: Tool-specific parameters

        Returns:
            JSON string with result
        """
        # Parse tool from prompt or kwargs
        # Map to client method
        # Execute and return result

        result = self._loop.run_until_complete(
            self._execute_async(prompt, tool, **kwargs)
        )
        return json.dumps(result)

    async def _execute_async(self, prompt: str, tool: str, **kwargs):
        # Route to appropriate client method
        if tool == "generate_podcast":
            return await self.client.content.generate_podcast(**kwargs)
        elif tool == "add_youtube_source":
            return await self.client.sources.add_youtube(**kwargs)
        # ... map all 31 tools

    def parse_output(self, raw_output: str) -> str:
        # Parse JSON response
        data = json.loads(raw_output)
        return data.get("result", str(data))

    def handle_error(self, returncode: int, stderr: str) -> Exception:
        # Map library exceptions to DeterminAgent exceptions
        return ExecutionError(f"NotebookLM error: {stderr}")
```

**Integration with DeterminAgent**:

```python
# Add to determinagent/agent.py ADAPTERS registry
ADAPTERS = {
    "claude": ClaudeAdapter,
    "copilot": CopilotAdapter,
    "gemini": GeminiAdapter,
    "codex": CodexAdapter,
    "notebooklm": NotebookLMAdapter,  # NEW
}
```

**Usage in Flows**:

```python
# flows/content_creation/main.py

from determinagent import UnifiedAgent
from langgraph.graph import StateGraph

# Initialize NotebookLM agent
notebooklm = UnifiedAgent(
    provider="notebooklm",
    role="content_generator",
    instructions="Generate high-quality content from research sources"
)

# Use in workflow
result = notebooklm.send(
    prompt="Generate a podcast from notebook 'AI Research 2026'",
    tool="generate_podcast",
    notebook_id="abc123",
    style="deep_dive"
)
```

---

## 3. Implementation Phases

### Phase 1: Foundation 

**Deliverables**:
- ‚úÖ Project setup (repo, CI/CD, dependencies)
- ‚úÖ Authentication flow (Playwright, cookie extraction)
- ‚úÖ Browser session management
- ‚úÖ Core Pydantic models
- ‚úÖ Basic NotebookLMClient structure

**Tasks**:
1. Initialize Python project with Poetry/Hatch
2. Set up Playwright for browser automation
3. Implement AuthManager with login flow
4. Implement BrowserSession with context management
5. Define core Pydantic schemas (Notebook, Source, Artifact)
6. Write unit tests for auth and session management

**Technical Focus**: Get browser automation working reliably with headless Chrome

### Phase 2: Notebook & Source Management 

**Deliverables**:
- ‚úÖ Notebook CRUD (create, list, get, rename, delete)
- ‚úÖ Source management (add URL, YouTube, Drive, text)
- ‚úÖ Source status polling (wait for processing to complete)
- ‚úÖ Error handling and retries

**Tools Implemented** (10/31):
- notebook_create
- notebook_list
- notebook_get
- notebook_rename
- notebook_delete
- notebook_add_url
- notebook_add_text
- notebook_add_drive
- source_list_drive
- source_delete

**Technical Focus**: Reverse-engineer NotebookLM's internal API endpoints

### Phase 3: Content Generation 

**Deliverables**:
- ‚úÖ Audio podcast generation
- ‚úÖ Video overview creation
- ‚úÖ Infographic generation
- ‚úÖ Slide deck creation
- ‚úÖ Async status polling for long-running operations

**Tools Implemented** (5/31):
- audio_overview_create
- video_overview_create
- infographic_create
- slide_deck_create
- studio_status

**Technical Focus**: Handle async operations (polling, progress tracking)

### Phase 4: Research & Analysis 

**Deliverables**:
- ‚úÖ Notebook query (ask questions)
- ‚úÖ Research discovery (web/Drive)
- ‚úÖ Research import
- ‚úÖ Source descriptions and summaries
- ‚úÖ Chat configuration

**Tools Implemented** (8/31):
- notebook_query
- notebook_describe
- research_start
- research_status
- research_import
- source_describe
- source_sync_drive
- chat_configure

**Technical Focus**: Implement streaming responses for queries

### Phase 5: Mind Maps & Advanced Features 

**Deliverables**:
- ‚úÖ Mind map generation
- ‚úÖ Flashcard creation
- ‚úÖ Briefing document generation
- ‚úÖ Studio artifact management
- ‚úÖ All 31 tools complete

**Tools Implemented** (8/31):
- mindmap_create
- flashcard_create
- briefing_create
- studio_delete
- save_auth_tokens
- (remaining tools as needed)

**Technical Focus**: Export formats (FreeMind, OPML, XML for mind maps)

### Phase 6: DeterminAgent Integration 

**Deliverables**:
- ‚úÖ NotebookLMAdapter implementation
- ‚úÖ Tool routing and parameter mapping
- ‚úÖ Sync/async bridge for DeterminAgent
- ‚úÖ Integration tests with DeterminAgent

**Tasks**:
1. Create NotebookLMAdapter class
2. Map all 31 tools to adapter methods
3. Implement execute() with async bridge
4. Add to DeterminAgent ADAPTERS registry
5. Write integration tests
6. Update DeterminAgent documentation

### Phase 7: Testing & Documentation 

**Deliverables**:
- ‚úÖ 90%+ test coverage
- ‚úÖ Comprehensive API documentation
- ‚úÖ Example flows (content creation workflow)
- ‚úÖ Troubleshooting guide
- ‚úÖ Migration guide from existing MCP implementations

**Tasks**:
1. Write comprehensive unit tests
2. Write integration tests with real NotebookLM
3. Generate API documentation (Sphinx/mkdocs)
4. Create example content creation flow
5. Write README and usage guides
6. Performance benchmarking

---

## 5. Combining Best Practices from Existing Projects

### From **khengyun/notebooklm-mcp** (Architecture) ‚úÖ

**Adopt**:
- ‚úÖ FastMCP v2 patterns (decorator-based, clean structure) - adapt for Python library
- ‚úÖ Pydantic v2 for all data models
- ‚úÖ Comprehensive type hints (mypy strict mode)
- ‚úÖ Docker support for deployment
- ‚úÖ Multiple transport options (adapt: sync/async API)
- ‚úÖ Testing infrastructure (pytest, coverage tracking)
- ‚úÖ CI/CD with GitHub Actions

**Code Pattern Example**:
```python
# khengyun uses FastMCP decorators, we adapt for library:

from pydantic import BaseModel, Field

class GeneratePodcastRequest(BaseModel):
    notebook_id: str = Field(..., description="Notebook ID")
    style: Literal["deep_dive", "briefing"] = Field("deep_dive")
    format: Literal["audio", "video"] = Field("audio")

class GeneratePodcastResponse(BaseModel):
    artifact_id: str
    status: str
    url: Optional[str] = None
    estimated_time_seconds: int

# Clean, typed interface
async def generate_podcast(
    self,
    request: GeneratePodcastRequest
) -> GeneratePodcastResponse:
    # Implementation
```

### From **jacob-bd/notebooklm-mcp** (Features) ‚úÖ

**Adopt**:
- ‚úÖ Complete tool inventory (all 31 tools mapped)
- ‚úÖ Multi-source support (YouTube URL parsing, Drive integration)
- ‚úÖ Studio artifact management patterns
- ‚úÖ Research discovery workflows
- ‚úÖ Cookie-based auth approach (proven to work)

**Avoid**:
- ‚ùå "Vibe-coded" structure (no clear module separation)
- ‚ùå Lack of type hints and validation
- ‚ùå Minimal error handling
- ‚ùå Hardcoded values and magic strings
- ‚ùå Insufficient testing

**Code Pattern Example** (what to adopt):
```python
# jacob-bd has good tool inventory - adopt the functionality:

TOOLS = {
    "notebook_create": {...},
    "notebook_list": {...},
    "audio_overview_create": {...},
    # ... all 31 tools
}

# But improve the implementation:

class ContentGenerator:
    """Professional content generation with proper error handling"""

    async def generate_podcast(
        self,
        notebook_id: str,
        style: PodcastStyle = PodcastStyle.DEEP_DIVE,
        timeout: int = 300
    ) -> Artifact:
        """
        Generate audio podcast from notebook sources.

        Args:
            notebook_id: ID of notebook with sources
            style: Podcast style (deep_dive, briefing, etc.)
            timeout: Max generation time in seconds

        Returns:
            Artifact: Generated podcast metadata with URL

        Raises:
            NotebookNotFoundError: Notebook doesn't exist
            InsufficientSourcesError: Need at least 1 source
            GenerationTimeoutError: Generation exceeded timeout
        """
        # Validate inputs
        if not await self._notebook_exists(notebook_id):
            raise NotebookNotFoundError(notebook_id)

        # Submit generation request
        artifact = await self._submit_generation(
            notebook_id, "audio_overview", {"style": style.value}
        )

        # Poll for completion with timeout
        return await self._poll_artifact_status(
            artifact.id,
            timeout=timeout
        )
```

### From **PleasePrompto/notebooklm-mcp** (Patterns) ‚úÖ

**Adopt**:
- ‚úÖ Library management concept (save, tag, search notebooks)
- ‚úÖ Session continuity patterns
- ‚úÖ Profile-based configuration (minimal/standard/full)

**Code Pattern Example**:
```python
# Adopt library management concept:

class NotebookLibrary:
    """Manage saved notebooks with metadata"""

    async def save(
        self,
        notebook_id: str,
        tags: list[str] = [],
        description: str = ""
    ):
        """Save notebook to library with metadata"""

    async def search(self, query: str, tags: list[str] = []) -> list[Notebook]:
        """Search library by tags or description"""

    async def get_stats(self) -> LibraryStats:
        """Get library statistics"""
```

---

## 6. Technical Deep Dives

### 6.1 Browser Automation Strategy

**Playwright vs Puppeteer vs Selenium**:

| | Playwright | Puppeteer | Selenium |
|---|---|---|---|
| Language | Python native | Node.js (pyppeteer) | Python native |
| Performance | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Headless | Excellent | Good | Fair |
| Auto-wait | Built-in | Manual | Manual |
| **Verdict** | ‚úÖ Use this | ‚ùå | ‚ùå |

**Implementation Pattern**:
```python
from playwright.async_api import async_playwright, Browser, Page

class BrowserSession:
    def __init__(self, auth: AuthManager):
        self.auth = auth
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None

    async def __aenter__(self):
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )

        # Load auth cookies
        context = await self.browser.new_context(
            cookies=self.auth.get_cookies()
        )
        self.page = await context.new_page()

        # Navigate to NotebookLM
        await self.page.goto('https://notebooklm.google.com')
        return self

    async def __aexit__(self, *args):
        await self.browser.close()

    async def call_api(
        self,
        endpoint: str,
        method: str = "POST",
        data: dict = None
    ) -> dict:
        """
        Call NotebookLM internal API via browser context
        """
        # Use page.evaluate to make fetch() calls with cookies
        result = await self.page.evaluate(f"""
            async () => {{
                const response = await fetch('{endpoint}', {{
                    method: '{method}',
                    headers: {{'Content-Type': 'application/json'}},
                    body: {json.dumps(data)}
                }});
                return await response.json();
            }}
        """)
        return result
```

### 6.2 Authentication Flow

**Cookie Extraction Strategy**:

1. **Initial Setup**: Launch browser with GUI for user login
2. **Cookie Storage**: Save cookies to `~/.notebooklm/auth.json`
3. **Reuse**: Load cookies for subsequent headless sessions
4. **Refresh**: Detect expiry (401 responses), prompt re-auth

```python
class AuthManager:
    def __init__(self, auth_path: str = "~/.notebooklm/auth.json"):
        self.auth_path = Path(auth_path).expanduser()
        self.auth_path.parent.mkdir(parents=True, exist_ok=True)

    async def login(self, headless: bool = False):
        """
        Perform initial login and save cookies

        Args:
            headless: If False, launch GUI browser for user to login
        """
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=headless)
            context = await browser.new_context()
            page = await context.new_page()

            # Navigate to NotebookLM
            await page.goto('https://notebooklm.google.com')

            if not headless:
                # Wait for user to complete login
                print("Please log in to NotebookLM in the browser window...")
                await page.wait_for_url('**/notebooks**', timeout=300000)

            # Extract cookies
            cookies = await context.cookies()
            self._save_cookies(cookies)

            await browser.close()

    def is_authenticated(self) -> bool:
        """Check if auth.json exists and is not expired"""
        if not self.auth_path.exists():
            return False

        # Check expiry (cookies typically last 2-4 weeks)
        auth_data = self._load_cookies()
        # ... expiry logic
        return True

    def get_cookies(self) -> list[dict]:
        """Load cookies for browser context"""
        return self._load_cookies()
```

### 6.3 Internal API Discovery

**Reverse Engineering Approach**:

1. Open Chrome DevTools Network tab
2. Perform actions in NotebookLM UI
3. Capture XHR/Fetch requests
4. Identify API endpoints and payloads

**Example Endpoints** (discovered from jacob-bd):
```
POST /api/notebooks/create
  Body: {"name": "My Notebook"}

POST /api/notebooks/{id}/sources/add
  Body: {"type": "url", "url": "https://..."}

POST /api/notebooks/{id}/studio/audio
  Body: {"style": "deep_dive"}

GET /api/notebooks/{id}/studio/status/{artifact_id}
```

**API Wrapper Pattern**:
```python
class NotebookLMAPI:
    """Low-level API wrapper"""

    BASE_URL = "https://notebooklm.google.com"

    def __init__(self, session: BrowserSession):
        self.session = session

    async def create_notebook(self, name: str) -> dict:
        """Raw API call to create notebook"""
        return await self.session.call_api(
            f"{self.BASE_URL}/api/notebooks/create",
            method="POST",
            data={"name": name}
        )

    async def generate_audio(
        self,
        notebook_id: str,
        style: str
    ) -> dict:
        """Raw API call to generate audio"""
        return await self.session.call_api(
            f"{self.BASE_URL}/api/notebooks/{notebook_id}/studio/audio",
            method="POST",
            data={"style": style}
        )
```

### 6.4 Async Operations & Polling

**Challenge**: Content generation (podcasts, videos) takes 1-5 minutes

**Solution**: Polling with exponential backoff

```python
async def _poll_artifact_status(
    self,
    artifact_id: str,
    timeout: int = 300,
    initial_delay: float = 2.0,
    max_delay: float = 10.0,
    backoff_factor: float = 1.5
) -> Artifact:
    """
    Poll artifact status until complete or timeout

    Strategy: Exponential backoff (2s ‚Üí 3s ‚Üí 4.5s ‚Üí 6.75s ‚Üí 10s max)
    """
    start_time = asyncio.get_event_loop().time()
    delay = initial_delay

    while True:
        # Check timeout
        elapsed = asyncio.get_event_loop().time() - start_time
        if elapsed > timeout:
            raise GenerationTimeoutError(
                f"Artifact {artifact_id} generation exceeded {timeout}s"
            )

        # Poll status
        status = await self.api.get_artifact_status(artifact_id)

        if status["status"] == "ready":
            return Artifact(**status)
        elif status["status"] == "failed":
            raise GenerationFailedError(status.get("error", "Unknown"))

        # Wait with exponential backoff
        await asyncio.sleep(delay)
        delay = min(delay * backoff_factor, max_delay)
```

---

## 7. Risk Mitigation

### Risk 1: NotebookLM API Changes
**Impact**: High (breaks integration)
**Probability**: Medium (Google iterates frequently)

**Mitigation**:
- Version lock library releases
- Add automated integration tests (daily CI runs against real NotebookLM)
- Implement API change detection (monitor response schemas)
- Maintain changelog of known working versions
- Create fallback mechanisms for critical tools

### Risk 2: Authentication Expiry
**Impact**: Medium (interrupts workflows)
**Probability**: High (cookies expire every 2-4 weeks)

**Mitigation**:
- Implement auth health checks before operations
- Provide clear error messages prompting re-auth
- Add `--reauth` CLI flag for quick refresh
- Consider automated cookie refresh (risky, may violate ToS)

### Risk 3: Browser Automation Failures
**Impact**: High (no fallback)
**Probability**: Low-Medium (headless Chrome issues)

**Mitigation**:
- Comprehensive error handling with retries
- Support multiple browser engines (Chromium, Firefox)
- Implement logging for debugging
- Test on multiple platforms (Linux, macOS, Windows)

### Risk 4: Rate Limiting
**Impact**: Medium (slows workflows)
**Probability**: Medium (NotebookLM has daily limits)

**Mitigation**:
- Implement rate limit detection (HTTP 429 responses)
- Add exponential backoff retry logic
- Cache notebook/source metadata to reduce API calls
- Document known rate limits in user guide

### Risk 5: Development Effort Overrun
**Impact**: Medium (delays timeline)
**Probability**: High (420h is aggressive)

**Mitigation**:
- **Phase 1-2 validation sprint** (4 weeks, 140h) - Prove core concepts
- Prioritize features: Start with notebooks, sources, podcasts (80% value)
- Defer advanced features (mind maps, research discovery) to Phase 5
- Option to wrap jacob-bd if API reverse engineering blocks progress

---

## 8. Success Criteria

### Phase 1-2 (Foundation + Notebooks) Success:
- ‚úÖ Can authenticate headlessly with saved cookies
- ‚úÖ Can create, list, and delete notebooks
- ‚úÖ Can add URL and YouTube sources
- ‚úÖ 90%+ test coverage for implemented features
- ‚úÖ < 2 second latency for notebook operations

### Phase 3 (Content Generation) Success:
- ‚úÖ Can generate audio podcasts (end-to-end)
- ‚úÖ Can poll status with proper timeout handling
- ‚úÖ Generated artifacts have valid download URLs
- ‚úÖ < 5 minute generation time for standard podcasts

### Phase 6 (DeterminAgent Integration) Success:
- ‚úÖ NotebookLMAdapter works in DeterminAgent workflows
- ‚úÖ Can use NotebookLM in LangGraph flows
- ‚úÖ Example content creation flow works end-to-end
- ‚úÖ Documented in DeterminAgent CLI-REFERENCE.md

### Overall Project Success:
- ‚úÖ All 31 tools implemented and tested
- ‚úÖ 90%+ test coverage
- ‚úÖ Comprehensive documentation
- ‚úÖ Production-ready code quality (Pydantic, type hints, error handling)
- ‚úÖ Can create deterministic content workflows in DeterminAgent

---

## 9. Next Steps

### Immediate 
1. **Validate approach**: Review this plan, ask clarifying questions
2. **Set up environment**: Create GitHub repo, initialize Python project
3. **Proof of concept**: Implement basic Playwright auth flow 

### Short Term 
1. **Phase 1**: Foundation (authentication, session management)
2. **Phase 2**: Notebook & source management
3. **Checkpoint**: Review progress, decide continue vs pivot

### Medium Term 
1. **Phase 3**: Content generation (podcasts, videos, infographics)
2. **Phase 4**: Research & analysis tools

### Long Term 
1. **Phase 5**: Mind maps & advanced features
2. **Phase 6**: DeterminAgent integration
3. **Phase 7**: Testing & documentation
4. **Release**: v1.0.0 of pynotebooklm library

---

## 10. Alternative: Hybrid Approach

If full custom implementation proves too ambitious:

**Plan B: Wrapper + Refactor Strategy**
1. Fork jacob-bd/notebooklm-mcp
2. Refactor with clean architecture (Pydantic, type hints, tests)
3. Extract core functionality into library layer
4. Build DeterminAgent adapter on top
5. Contribute improvements back to jacob-bd

**Tradeoff**: Inherit some technical debt, but faster to production

---

## Summary

**Recommended Path**: Build custom Python library (`pynotebooklm`) with production-grade architecture, then wrap with DeterminAgent adapter.

**Key Technologies**: Playwright, Pydantic, asyncio, httpx, pytest
**Critical Success Factor**: API reverse engineering in Phases 1-2

**Decision Point**: After Phase 2, evaluate progress:
- ‚úÖ On track ‚Üí Continue with Phases 3-7
- ‚ö†Ô∏è Struggling ‚Üí Pivot to Plan B (wrap jacob-bd)

---

---

## 11. APPENDIX: Technical Implementation Details

### 11.1 NotebookLM Internal API Endpoints (from jacob-bd)

**Base URL**: `https://notebooklm.google.com/_/LabsTailwindUi/data/batchexecute`

**Request Format** (RPC Protocol):
```python
# URL-encoded payload
body = f"f.req={urllib.parse.quote(json_payload)}&at={csrf_token}&"

# JSON payload structure
json_payload = json.dumps([
    [[rpc_id, params, None, "generic"]]
], separators=(',', ':'))
```

**Key RPC Endpoints** (Discovered from jacob-bd):

| Operation | RPC ID | Parameters | Response |
|-----------|--------|------------|----------|
| List Notebooks | `wXbhsf` | `[null, 1, null, [2]]` | Array of notebooks |
| Create Notebook | `CCqFvf` | `[title, null, null, [2], [...]]` | Created notebook |
| Query/Chat | Streaming | `[sources, query, history, [2], conv_id]` | Streaming text chunks |
| Add URL Source | `izAoDd` | `[[source_data], notebook_id, [2]]` | Source object |
| Create Audio Podcast | `R7cb6c` | `[notebook_id, style_params, [...]]` | Artifact ID |
| Poll Generation Status | `gArtLc` | `[notebook_id, artifact_id]` | Status + download URL |

**Response Parsing Pattern**:
```python
# 1. Remove anti-XSSI prefix
content = response.text.removeprefix(")]}'")

# 2. Split byte-delimited lines
lines = content.strip().split('\n')

# 3. Extract data (skip byte count line)
data = json.loads(lines[1])

# 4. Navigate nested structure
result = data[0][2]  # Actual response is nested
```

### 11.2 Authentication Implementation

**Essential Cookies to Extract**:
- `SID`, `HSID`, `SSID` - Google authentication tokens
- `APISID`, `SAPISID` - API-specific tokens
- `__Secure-*PSID` - Secure persistent session ID

**Additional Tokens from Page HTML**:
```javascript
// Extract via page.evaluate() or Selenium
const snlm0e = document.querySelector('script')?.textContent?.match(/SNlM0e":"([^"]+)/)?.[1];
const fdrfje = document.querySelector('script')?.textContent?.match(/FdrFJe":"([^"]+)/)?.[1];

// Cookie header format
Cookie: SID=...; HSID=...; SSID=...; APISID=...; SAPISID=...; __Secure-1PSID=...; __Secure-3PSID=...
```

**Cookie Lifespan**: 2-4 weeks (requires re-extraction after expiry)

### 11.3 Browser Automation Patterns (from khengyun)

**Anti-Detection Setup** (Selenium):
```python
import undetected_chromedriver as uc

options = uc.ChromeOptions()
options.add_argument(f"--user-data-dir={profile_path}")
options.add_argument("--no-first-run")
options.add_argument("--no-default-browser-check")
options.add_argument("--headless=new")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option("useAutomationExtension", False)

driver = uc.Chrome(options=options, version_main=None)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
```

**Element Selectors with Fallbacks**:
```python
# Chat input - try multiple selectors
selectors = [
    "textarea[placeholder*='Ask']",
    "textarea[data-testid*='chat']",
    "[contenteditable='true'][role='textbox']",
]

for selector in selectors:
    try:
        element = WebDriverWait(driver, 2).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
        )
        break
    except TimeoutException:
        continue
```

### 11.4 Comprehensive Tool Catalog (31 Tools)

**Category Breakdown**:

**Notebooks (6)**:
- `notebook_list`, `notebook_create`, `notebook_get`, `notebook_describe`, `notebook_rename`, `notebook_delete`

**Sources (7)**:
- `notebook_add_url`, `notebook_add_text`, `notebook_add_drive`, `source_describe`, `source_list_drive`, `source_sync_drive`, `source_delete`

**Query & Analysis (2)**:
- `notebook_query`, `chat_configure`

**Research (3)**:
- `research_start`, `research_status`, `research_import`

**Studio Content Generation (13)**:
- Audio: `audio_overview_create`
- Video: `video_overview_create`
- Visual: `infographic_create`, `slide_deck_create`
- Documents: `briefing_create`
- Study: `flashcard_create`, `quiz_create`
- Analysis: `data_table_create`
- Knowledge: `mindmap_create`, `mindmap_list`
- Metadata: `studio_status`, `studio_delete`
- Auth: `save_auth_tokens`

### 11.5 Error Response Patterns

**Consistent Response Format**:
```python
# Success
{
    "status": "success",
    "data": {...},
    "metadata": {...}
}

# Error
{
    "status": "error",
    "error": "Human-readable message",
    "error_type": "AuthenticationError|APIError|ValidationError|RateLimitError",
    "details": {...}
}

# Confirmation Required
{
    "status": "error",
    "error": "Action requires confirmation",
    "warning": "This action is IRREVERSIBLE",
    "required_parameter": "confirm=True"
}
```

### 11.6 Testing Infrastructure (from khengyun)

**Fixture Pattern**:
```python
@pytest.fixture
def mock_auth_tokens():
    return {
        "cookies": {
            "SID": "mock_sid",
            "HSID": "mock_hsid",
            # ... other cookies
        },
        "csrf_token": "mock_csrf",
        "session_id": "mock_session"
    }

@pytest.fixture
async def async_client(mock_auth_tokens):
    client = AsyncMock(spec=NotebookLMClient)
    await client.start()
    yield client
    await client.close()
```

**Mock API Responses**:
```python
# Real response format with anti-XSSI prefix
response_text = """)]}'
6
[[[\"wrb.fr\",null,\"[[\\\"nb1\\\",\\\"Test\\\"]]\"]]
"""
```

### 11.7 Deployment Architecture

**Docker Prerequisites**:
- Python 3.11+
- Chrome/Chromium browser
- Chrome profile directory (persistent across restarts)

**Production Requirements**:
- Health check endpoint
- Rate limiter with persistent state
- Auth token cache with expiry detection
- Logging to files (not just stdout)
- Signal handling for graceful shutdown

### 11.8 Technical Complexity Assessment

**High Complexity**:
- API protocol reverse engineering (RPC structure, response parsing)
- Browser automation setup (anti-detection, element selectors)
- Authentication flow (cookie extraction, token management)

**Medium Complexity**:
- Tool implementations (31 different operations)
- Async polling for content generation
- Error handling and retries

**Low Complexity*:
- MCP server integration (FastMCP is well-documented)
- Configuration management (Pydantic)
- Testing infrastructure (standard pytest patterns)

---

## 12. Reverse‚ÄëEngineering Notebook‚ÄØLM API ‚Äì Difficulty & Recommendations

### 12.1 Difficulty Assessment

| Aspect | Difficulty | Why? | Typical effort |
|--------|------------|------|----------------|
| **Understanding the authentication flow** | ‚òÖ‚òÖ‚òÖ‚òÖ (hard) | Requires extracting Chrome cookies, handling token refresh, and sometimes solving re‚ÄëCAPTCHA or multi‚Äëfactor prompts. | 1‚Äë2‚ÄØdays of trial & error; stable solution needs robust cookie‚Äëmanagement code. |
| **Locating internal endpoints** | ‚òÖ‚òÖ‚òÖ‚òÖ (hard) | Endpoints are hidden in the web UI JavaScript; they can change with each UI release. | Ongoing research; a few weeks to map the most common calls (list notebooks, add source, generate content). |
| **Stability / maintenance** | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (very hard) | Google can change the UI or the internal API at any time, breaking the connector. | Continuous monitoring; expect breakages roughly every 2‚Äë4‚ÄØweeks (when cookies expire or UI updates). |
| **Automation tooling** | ‚òÖ‚òÖ (moderate) | Playwright/Chrome‚ÄØCDP are well‚Äëdocumented; the code to drive them is straightforward once the endpoints are known. | A few hours to set up a reliable Playwright wrapper. |
| **Legal / policy considerations** | ‚òÖ‚òÖ (moderate) | Reverse‚Äëengineering a Google product may violate terms of service. | Review Google‚Äôs policies; consider using the **Enterprise API** if you need a supported solution. |

**Overall rating:** **Hard / Semi‚Äëautomatic** ‚Äì you can automate the workflow **once** the endpoints are discovered, but the discovery and long‚Äëterm maintenance require significant manual effort.

### 12.2 What Can Be Automated?

| Task | Automation level |
|------|------------------|
| **Browser launch & login (or cookie injection)** | Fully automatable with Playwright (headless or headed). |
| **Calling internal endpoints** | Fully automatable **once** you know the URL, method, and payload schema. |
| **Polling for async generation (e.g., podcast, video)** | Fully automatable ‚Äì just repeat the same `fetch` call until `status === "ready"` or timeout. |
| **Error handling & retries** | Automatable, but you need to anticipate the error shapes (e.g., 401, 429, ‚Äúsession expired‚Äù). |
| **Detecting API changes** | Semi‚Äëautomatic ‚Äì you can write a health‚Äëcheck that validates a known endpoint and alerts you if the response shape changes. |

### 12.3 Recommendations

1. **Start with Playwright** and build a thin wrapper that loads saved cookies and provides a generic `call_api(endpoint, method, payload)` helper.
2. **Document each discovered endpoint** (URL, method, request/response schema) in a markdown file inside the repo ‚Äì this will be your ‚ÄúAPI spec‚Äù.
3. **Add health‚Äëcheck tests** that run nightly and alert you if any endpoint returns an unexpected status or schema.
4. **Consider a fallback** to UI‚Äëonly automation if a critical endpoint breaks.
5. **If you need a guaranteed SLA**, evaluate the **Enterprise Notebook‚ÄØLM API** or an alternative open‚Äësource solution like **Open Notebook**.

---

## Resources & References

- **Official Notebook‚ÄØLM Enterprise API** ‚Äì https://cloud.google.com/notebooklm
- **jacob‚Äëbd notebooklm‚Äëmcp** ‚Äì https://github.com/jacob-bd/notebooklm-mcp
- **khengyun notebooklm‚Äëmcp** ‚Äì https://github.com/khengyun/notebooklm-mcp
- **PleasePrompto notebooklm‚Äëmcp** ‚Äì https://github.com/PleasePrompto/notebooklm-mcp
- **AutoContent API (unofficial)** ‚Äì https://autocontentapi.com
- **notebooklm‚Äëkit (TypeScript SDK)** ‚Äì https://github.com/notebooklm-kit/notebooklm-kit
- **Apify ‚ÄúTo NotebookLM‚Äù API** ‚Äì https://apify.com/notebooklm
- **Open Notebook (open‚Äësource alternative)** ‚Äì https://github.com/open-notebook/open-notebook
- **Google Gemini documentation** ‚Äì https://developers.google.com/gemini
- **Playwright documentation** ‚Äì https://playwright.dev/python/docs/intro

---

**Questions for Review**:
2. Any specific tools from jacob-bd's 31 that are "must-haves" for MVP?
3. Should we prioritize DeterminAgent integration earlier (swap Phase 4 and 6)?
4. Preference for async-first API or sync wrapper with async internals?
